{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practica Guillermo Pedernal.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "mqFncd0oxSOc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "En primer lugar vamos a preparar los datos (imagenes y descripciones) de una forma similar a la vista en clase. \n",
        "\n",
        "Lo intentaremos cambiando el dataset tespecto al que vimos en el ejemplo."
      ]
    },
    {
      "metadata": {
        "id": "GVrEM8YhrQTb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "1.En primer lugar he intentado preparar un modelo con el dataset flickr 30k. Me he encontrado con las siguientes dificultades:\n",
        "\n",
        "    -En este dataset no se incluían archivos con los títulos como el que utilizamos en el ejemplo de flickr8k. Para ello he adaptado dos nuevas funciones \"load_titles\" y \"save_doc2\" que permitieran crear una lista con los títulos de las fotos y grabarlas en un archivo de texto.\n",
        "\n",
        "    -Finalmente, google colab no es capaz de escribir el archivo features.pkl para las 31.000 fotografías. He intentado jugar con el dataset parcialmente, añadiendo una instrucción de break en el loop de la VGG. Esta idea no ha resultado dado que al intentar asociar las caracteristicas a una foto mediante la funcion \"load_photo_features\" termina por dar error al llegar a una clave para la cual no tenemos sus características. \n",
        "    \n",
        "    -Por estos motivos he tenido que abandonar el dataset flickr30k (después de un penoso intento con la CPU)\n",
        "    "
      ]
    },
    {
      "metadata": {
        "id": "utJAgNcwyALe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "2.Una vez descartado flickr 30k y con idea de utilizar un dataset distinto al utilizado en clase, vamos a probar con el dataset Pascal Sentence.\n",
        "\n",
        "[http://vision.cs.uiuc.edu/pascal-sentences/](http://vision.cs.uiuc.edu/pascal-sentences/)\n",
        "\n",
        "    -Este dataset no tiene un enlace de descarga directa y por lo tanto hay que extraer las fotos y descripciones mediante web scrapping. Para ello utilizaremos el trabajo de un usuario de github.\n",
        "    \n",
        "    -Finalmente, después de asemejar todo al ejemplo de clase para utilizar el modelo los resultados no son satisfactorios, llegando a predicciones vacías \"startseq -> endseq\".\n",
        "    \n",
        "    -Al pelearme con las funciones del ejemplo de clase para que medio funcione todo al menos entiendo el proceso paso a paso mejor que al verlo en la sesión.\n",
        "    \n",
        "    -Dejo el codigo para que se vea el trabajo realizado ya que al menos he llegado a utilizar la LSTM y sacado un resultado. Sigo más abajo, ya con la flickr 8k como en clase."
      ]
    },
    {
      "metadata": {
        "id": "cPh49SXR5H-t",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "9107b19b-f870-435e-ff88-2790c38b09d3",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530264863196,
          "user_tz": -120,
          "elapsed": 4103,
          "user": {
            "displayName": "Guillermo Pedernal",
            "photoUrl": "//lh4.googleusercontent.com/-c67Vnm1lekk/AAAAAAAAAAI/AAAAAAAAAD4/_p61UmeZ47E/s50-c-k-no/photo.jpg",
            "userId": "101927487601652154517"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install pyquery"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyquery\r\n",
            "  Using cached https://files.pythonhosted.org/packages/09/c7/ce8c9c37ab8ff8337faad3335c088d60bed4a35a4bed33a64f0e64fbcf29/pyquery-1.4.0-py2.py3-none-any.whl\n",
            "Collecting cssselect>0.7.9 (from pyquery)\n",
            "  Downloading https://files.pythonhosted.org/packages/7b/44/25b7283e50585f0b4156960691d951b05d061abf4a714078393e51929b30/cssselect-1.0.3-py2.py3-none-any.whl\n",
            "Collecting lxml>=2.1 (from pyquery)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/81/5a3e70c8adc20fb295a2f4c9fdf09af8295c7a00ccec6ee3d31084cbf272/lxml-4.2.3-cp36-cp36m-manylinux1_x86_64.whl (5.9MB)\n",
            "\u001b[K    100% |████████████████████████████████| 5.9MB 4.7MB/s \n",
            "\u001b[?25hInstalling collected packages: cssselect, lxml, pyquery\n",
            "Successfully installed cssselect-1.0.3 lxml-4.2.3 pyquery-1.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bGMQALk75NRG",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "00c6005d-c83b-448a-cdbd-43e33ff294a3",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530264886949,
          "user_tz": -120,
          "elapsed": 2547,
          "user": {
            "displayName": "Guillermo Pedernal",
            "photoUrl": "//lh4.googleusercontent.com/-c67Vnm1lekk/AAAAAAAAAAI/AAAAAAAAAD4/_p61UmeZ47E/s50-c-k-no/photo.jpg",
            "userId": "101927487601652154517"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install requests"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (2.18.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests) (2018.4.16)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests) (1.22)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests) (2.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yEqD-Q2m6PKL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "6b59b957-d5ed-45bc-b8f9-7c252d45d3bb",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530265146300,
          "user_tz": -120,
          "elapsed": 2471,
          "user": {
            "displayName": "Guillermo Pedernal",
            "photoUrl": "//lh4.googleusercontent.com/-c67Vnm1lekk/AAAAAAAAAAI/AAAAAAAAAD4/_p61UmeZ47E/s50-c-k-no/photo.jpg",
            "userId": "101927487601652154517"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install urlparse"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting urlparse\n",
            "\u001b[31m  Could not find a version that satisfies the requirement urlparse (from versions: )\u001b[0m\n",
            "\u001b[31mNo matching distribution found for urlparse\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KzO7Y7zP7Sk1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "f7aa0c16-b6bc-42fa-fe97-d0a1d6456eaf",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530265886479,
          "user_tz": -120,
          "elapsed": 2677,
          "user": {
            "displayName": "Guillermo Pedernal",
            "photoUrl": "//lh4.googleusercontent.com/-c67Vnm1lekk/AAAAAAAAAAI/AAAAAAAAAD4/_p61UmeZ47E/s50-c-k-no/photo.jpg",
            "userId": "101927487601652154517"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#!mkdir PascalSentenceDataSetOutput\n",
        "#!mkdir PascalSentenceDataSetText\n",
        "!ls -la"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 80\r\n",
            "drwxr-xr-x 1 root root  4096 Jun 29 09:51 .\r\n",
            "drwxr-xr-x 1 root root  4096 Jun 29 09:26 ..\r\n",
            "drwx------ 4 root root  4096 Jun 29 09:33 .cache\r\n",
            "drwxr-xr-x 3 root root  4096 Jun 29 09:33 .config\r\n",
            "drwxr-xr-x 3 root root  4096 Jun 25 16:59 datalab\r\n",
            "drwxr-xr-x 4 root root  4096 Jun 29 09:27 .forever\r\n",
            "drwxr-xr-x 5 root root  4096 Jun 29 09:33 .ipython\r\n",
            "drwx------ 3 root root  4096 Jun 29 09:27 .local\r\n",
            "drwxr-xr-x 5 root root  4096 Jun 29 09:33 PascalSentenceDataset\r\n",
            "drwxr-xr-x 2 root root 36864 Jun 29 09:48 PascalSentenceDataSetOutput\r\n",
            "drwxr-xr-x 2 root root  4096 Jun 29 09:51 PascalSentenceDataSetText\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YjRB7Ahr5eHk",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#Codigo de github con algun cambio para que funcione como queremos y actualizado a py3\n",
        "\n",
        "from urllib.parse import urljoin\n",
        "from pyquery import PyQuery\n",
        "import os\n",
        "import requests\n",
        "import csv\n",
        "\n",
        "__author__ = 'rupy'\n",
        "\n",
        "class PascalSentenceDataSet():\n",
        "\n",
        "    DATASET_DIR = 'dataset/'\n",
        "    SENTENCE_DIR = 'sentence/'\n",
        "    PASCAL_SENTENCE_DATASET_URL = 'http://vision.cs.uiuc.edu/pascal-sentences/'\n",
        "\n",
        "    def __init__(self):\n",
        "        self.url = PascalSentenceDataSet.PASCAL_SENTENCE_DATASET_URL\n",
        "\n",
        "    def download_images(self):\n",
        "        dom = PyQuery(self.url)\n",
        "        for img in dom('img').items():\n",
        "            img_src = img.attr['src']\n",
        "            category, img_file_name = os.path.split(img_src)\n",
        "\n",
        "            # make category directories\n",
        "            output_dir = \"PascalSentenceDataSetOutput\"\n",
        "            #if not os.path.isdir(output_dir):\n",
        "            #    os.mkdir(output_dir)\n",
        "\n",
        "            # download image\n",
        "            output = os.path.join(output_dir, img_file_name)\n",
        "            print (output)\n",
        "            if img_src.startswith('http'):\n",
        "                img_url = img_src\n",
        "            else:\n",
        "                img_url = urljoin(self.url, img_src)\n",
        "            if os.path.isfile(output):\n",
        "                print (\"Already downloaded, Skipping: %s\" % output)\n",
        "                continue\n",
        "            print (\"Downloading: %s\" % output)\n",
        "            with open(output,'wb') as f:\n",
        "\n",
        "                while True:\n",
        "                    result = requests.get(img_url)\n",
        "                    raw = result.content\n",
        "                    if result.status_code == 200:\n",
        "                        f.write(raw)\n",
        "                        break\n",
        "                    print (\"error occurred while fetching img\")\n",
        "                    print (\"retry...\")\n",
        "\n",
        "\n",
        "    def download_sentences(self):\n",
        "        dom = PyQuery(self.url)\n",
        "        # tbody disappears in pyquery DOM\n",
        "        for tr in dom('body>table>tr').items():\n",
        "            img_src = tr('img').attr['src']\n",
        "            category, img_file_name = os.path.split(img_src)\n",
        "\n",
        "            # make category directories\n",
        "            output_dir = \"PascalSentenceDataSetText\"\n",
        "            #if not os.path.isdir(output_dir):\n",
        "            #    os.mkdir(output_dir)\n",
        "\n",
        "            # dowonload sentences\n",
        "            head, tail = os.path.splitext(img_file_name)\n",
        "            sentence_file_name = head + \"txt\"\n",
        "            output = os.path.join(output_dir, sentence_file_name)\n",
        "            if os.path.isfile(output):\n",
        "                print (\"Already downloaded, Skipping: %s\" % output)\n",
        "                continue\n",
        "            print (\"Downloading: %s\" % output)\n",
        "            with open(output,'w') as f:\n",
        "                for td in tr('table tr td').items():\n",
        "                    f.write(td.text() + \"\\n\")\n",
        "\n",
        "    def create_correspondence_data(self):\n",
        "        dom = PyQuery(self.url)\n",
        "        writer = csv.writer(open('correspondence.csv', 'wb'))\n",
        "        for i, img in enumerate(dom('img').items()):\n",
        "            img_src = img.attr['src']\n",
        "            print (\"%d => %s\" % (i + 1, img_src))\n",
        "            writer.writerow([i + 1, img_src])\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "\n",
        "    # create instance\n",
        "    dataset = PascalSentenceDataSet()\n",
        "    # download images\n",
        "    dataset.download_images()\n",
        "    # download sentences\n",
        "    dataset.download_sentences()\n",
        "    # create correspondence data by dataset\n",
        "    #dataset.create_correspondence_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AkeKhH-fBIMk",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "7a58f7be-b67f-4429-ad1f-802c6a0c91c6",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530440372006,
          "user_tz": -120,
          "elapsed": 3036,
          "user": {
            "displayName": "Guillermo Pedernal",
            "photoUrl": "//lh4.googleusercontent.com/-c67Vnm1lekk/AAAAAAAAAAI/AAAAAAAAAD4/_p61UmeZ47E/s50-c-k-no/photo.jpg",
            "userId": "101927487601652154517"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install tqdm"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tqdm\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/24/6ab1df969db228aed36a648a8959d1027099ce45fad67532b9673d533318/tqdm-4.23.4-py2.py3-none-any.whl (42kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 2.1MB/s \n",
            "\u001b[?25hInstalling collected packages: tqdm\n",
            "Successfully installed tqdm-4.23.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0Vko7xTEB2YO",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!rm -rf titles.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bhcX7aMr-v_h",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5976716e-6bbb-4348-f1e8-ce972bb78681",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530267924225,
          "user_tz": -120,
          "elapsed": 714,
          "user": {
            "displayName": "Guillermo Pedernal",
            "photoUrl": "//lh4.googleusercontent.com/-c67Vnm1lekk/AAAAAAAAAAI/AAAAAAAAAD4/_p61UmeZ47E/s50-c-k-no/photo.jpg",
            "userId": "101927487601652154517"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#Necesitamos una funcion par crear un txt con los nombres de las imagenes\n",
        "from os import listdir\n",
        "from tqdm import tqdm\n",
        "\n",
        "def extract_titles(directory, filename):\n",
        "  \n",
        "  files_in_directory = listdir(directory)\n",
        "  #n_titles = len(files_in_directory)\n",
        "  for i, name in enumerate(tqdm(files_in_directory)):\n",
        "    \n",
        "    data = name.split('t')[0] + '.jpg' + '\\n'\n",
        "    file = open(filename, 'a')\n",
        "    file.write(data)\n",
        "    file.close()\n",
        "      \n",
        "extract_titles('PascalSentenceDataSetText', 'titles.txt')\n"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:00<00:00, 17930.12it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "iv530JHnBLyj",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "9c774a53-bfd9-4c24-b4a5-cb86dd100e8c",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530268087403,
          "user_tz": -120,
          "elapsed": 1865,
          "user": {
            "displayName": "Guillermo Pedernal",
            "photoUrl": "//lh4.googleusercontent.com/-c67Vnm1lekk/AAAAAAAAAAI/AAAAAAAAAD4/_p61UmeZ47E/s50-c-k-no/photo.jpg",
            "userId": "101927487601652154517"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!cat PascalSentenceDataSetText/2008_003607txt"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A blonde dog and a black and gray dog sitting on opposite ends of a beige sofa, with a gray cat sleeping between them\r\n",
            "A white dog, a black dog, and a gray cat lay on a white couch together near a window.\r\n",
            "Cats and dogs getting along while sleeping on the couch.\r\n",
            "Two dogs and a cat resting on a couch.\r\n",
            "Two dogs and one cat sitting on couch.\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PVoHnoF6IoBB",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!rm -rf descriptions.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EHdfNGbuFjZP",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a106c74e-53f8-4207-dfc8-703f2cad52c0",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530271749109,
          "user_tz": -120,
          "elapsed": 672,
          "user": {
            "displayName": "Guillermo Pedernal",
            "photoUrl": "//lh4.googleusercontent.com/-c67Vnm1lekk/AAAAAAAAAAI/AAAAAAAAAD4/_p61UmeZ47E/s50-c-k-no/photo.jpg",
            "userId": "101927487601652154517"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#Vamos a crear un nuevo load_descriptions que coja la primera descripcion de cada uno de estos txt\n",
        "\n",
        "import string\n",
        "import re\n",
        "\n",
        "def load_descriptions(directory, filename):\n",
        "\t  \n",
        "  files_in_directory = listdir(directory)\n",
        "  #n_titles = len(files_in_directory)\n",
        "  #table = str.maketrans('', '', string.punctuation)\n",
        "  for i, name in enumerate(tqdm(files_in_directory)):\n",
        "   \n",
        "    file = open(directory + '/' + name, 'r')\n",
        "    data = file.read().split('\\n')[0].lower()\n",
        "    data = re.sub(r'[^\\w\\s]','',data)\n",
        "    data = re.sub(r'\\b\\w{1,1}\\b', '', data)\n",
        "    file.close()\n",
        "    \n",
        "    file2 = open(filename, 'a')\n",
        "    file2.write(name.split('t')[0] + ' '+ data + '\\n')\n",
        "    file2.close \n",
        "    \n",
        "load_descriptions('PascalSentenceDataSetText', 'descriptions.txt')"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:00<00:00, 7151.07it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "jtg1DFtrOL3s",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cfde7655-aa7e-4a40-d8bb-7e975e9968f9",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530281802843,
          "user_tz": -120,
          "elapsed": 774,
          "user": {
            "displayName": "Guillermo Pedernal",
            "photoUrl": "//lh4.googleusercontent.com/-c67Vnm1lekk/AAAAAAAAAAI/AAAAAAAAAD4/_p61UmeZ47E/s50-c-k-no/photo.jpg",
            "userId": "101927487601652154517"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def descDict (directory):\n",
        "  \n",
        "  mapping = dict()\n",
        "  files_in_directory = listdir(directory)\n",
        "  #n_titles = len(files_in_directory)\n",
        "  for i, name in enumerate(tqdm(files_in_directory)):\n",
        "   \n",
        "    file = open(directory + '/' + name, 'r')\n",
        "    data = file.read().split('\\n')[0].lower()\n",
        "    data = re.sub(r'[^\\w\\s]','',data)\n",
        "    data = re.sub(r'\\b\\w{1,1}\\b', '', data)\n",
        "    file.close()\n",
        "    \n",
        "    if name.split('t')[0] not in mapping:\n",
        "      mapping[name.split('t')[0]] = data\n",
        "  return mapping\n",
        "\n",
        "descriptions = descDict('PascalSentenceDataSetText')\n",
        "  "
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:00<00:00, 14304.29it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "ScTGqhj_SOQg",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 17017
        },
        "outputId": "83fce9f3-cd19-46eb-a772-61e595b6d4db",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530281810644,
          "user_tz": -120,
          "elapsed": 760,
          "user": {
            "displayName": "Guillermo Pedernal",
            "photoUrl": "//lh4.googleusercontent.com/-c67Vnm1lekk/AAAAAAAAAAI/AAAAAAAAAD4/_p61UmeZ47E/s50-c-k-no/photo.jpg",
            "userId": "101927487601652154517"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "descriptions"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'2008_003607': ' blonde dog and  black and gray dog sitting on opposite ends of  beige sofa with  gray cat sleeping between them',\n",
              " '2008_001479': ' brown dachshund beside the door',\n",
              " '2008_007317': ' black bird sits on the edge of  piece of pavement looking to the side',\n",
              " '2008_004995': ' bicycle is parked by  shop',\n",
              " '2008_008538': ' decorated room with blue carpeting  cream sofa and chair and  patio door',\n",
              " '2008_007095': 'an airplane flies against  colorful sky with the sun rising',\n",
              " '2008_005831': ' white animal running through snow covered woods',\n",
              " '2008_007415': ' chair as the central item in the picture',\n",
              " '2008_000817': ' kitchen dinette set sits on  backyard deck',\n",
              " '2008_007693': 'lambs stand behind  barbed wire fence',\n",
              " '2008_003805': ' brown race horse jockey in green and handler',\n",
              " '2008_004363': ' bicycle on display with  shade attached',\n",
              " '2008_004176': ' group of girls are posing with two',\n",
              " '2008_001920': ' closeup picture of  desk with  computer and papers on it',\n",
              " '2008_006014': ' dilapidated pier and  boat in the water with several people on it',\n",
              " '2008_006076': ' woman poses while wearing  helmet with horns',\n",
              " '2008_001971': 'an airplane approaches  runway',\n",
              " '2008_003063': 'two cats are looking at  window',\n",
              " '2008_001155': ' kitchen with pine doors and  table and chairs',\n",
              " '2008_007286': ' dog looks into refrigerator while  person looks on',\n",
              " '2008_007042': ' plant growing in  pot',\n",
              " '2008_007478': ' man sitting on  bench looking at  dog on  leash sitting on sidewalk',\n",
              " '2008_006939': ' young sheep with tags on its ears',\n",
              " '2008_003575': ' fighter jet with missiles on  runway',\n",
              " '2008_007524': ' boy and his mom feeding ponies through the fence',\n",
              " '2008_006096': 'girls ridinghorses',\n",
              " '2008_008194': ' bird with bright colors',\n",
              " '2008_001869': ' black and white photo of  living room with  large window sofa and chair',\n",
              " '2008_006234': ' black and white photo of  bicycle',\n",
              " '2008_003826': ' london underground train in  siding next to  london overground train',\n",
              " '2008_002864': ' bald man is explaining the rules of  card game to  fat man',\n",
              " '2008_003753': ' kitchendining room with  computer workstation',\n",
              " '2008_004844': ' bus at  bus stop',\n",
              " '2008_001660': ' guy and girl pose on  sofa with  tiny dog',\n",
              " '2008_001320': ' man in  blue shirt is standing beside  table with  birthday cake',\n",
              " '2008_008001': ' car parked in front of train tracks',\n",
              " '2008_006667': ' black bird with white chest resting on  tree limb with  bright blue sky in the background',\n",
              " '2008_008363': ' brown formal dining table with four chairs underneath  crystal chandelier',\n",
              " '2008_004457': ' couple enjoying  sunny day on the top deck of  cruise ship',\n",
              " '2008_008432': ' grounded plane',\n",
              " '2008_007888': ' cat laying on  surface upside down looks at the camera',\n",
              " '2008_001932': ' closeup headshot of two women with one sticking out her tongue',\n",
              " '2008_005549': ' bearded man is holding  child in  sling',\n",
              " '2008_008461': ' bird in the tree is shaking its feathers',\n",
              " '2008_002897': ' man in  black hat is sitting on  chair on  patio playing guitar',\n",
              " '2008_002451': ' group of teenagers dancing near  bus',\n",
              " '2008_008541': ' black and white cow looking through the fence',\n",
              " '2008_007280': ' commuter train pulling into  platform at night',\n",
              " '2008_001335': ' close up of  gray cat with  yellow collar',\n",
              " '2008_001866': 'an amtrak passenger train waiting at  station',\n",
              " '2008_006488': ' fisherman in  small boat in the middle of  peaceful lake',\n",
              " '2008_008654': ' black and white cow in  pen with hay',\n",
              " '2008_006038': ' brown dog resting on  white sofa cushion',\n",
              " '2008_004453': 'the lamb is looking at the camera',\n",
              " '2008_007969': ' multicolored open air bus with  yellow flag',\n",
              " '2008_008103': ' blue couch with power puff girls cushions with  brown coffee table in front',\n",
              " '2008_008617': ' black calf drinks milk near the road',\n",
              " '2008_007054': ' black and white photo of  motorcycle laying on the ground',\n",
              " '2008_005186': 'an american eagle standing on  post with its wing down',\n",
              " '2008_003477': ' close up of the center of  dining room table with  wine glass and silver kettle',\n",
              " '2008_003147': ' adult and two young sheep in  field',\n",
              " '2008_006356': ' brown and white dog standing on hind legs looking out  window',\n",
              " '2008_007476': ' man is watching tv on the foot of his bed',\n",
              " '2008_005933': ' park garden in front of red trolleys and  large building',\n",
              " '2008_006327': 'four goat kids laying on hay',\n",
              " '2008_005081': ' black table with white fuzzy chair',\n",
              " '2008_008526': ' bald man lounging on  couch with  young girl and  40 oz beer and playing cards in his hand',\n",
              " '2008_004950': ' young boy holds  puppy up in front of  spiderman poster',\n",
              " '2008_007544': ' black and brown cow walking through the grass field',\n",
              " '2008_003655': 'an airliner is loaded with supplies for its next flight',\n",
              " '2008_001842': ' black and white photo of  man standing next to  bus',\n",
              " '2008_000806': ' man driving an orange scooter through  tunnel',\n",
              " '2008_005752': ' black and white photo of  bottle sitting atop  rock carving in front of  line of bushes',\n",
              " '2008_008739': 'an old wooden train heading toward an old station',\n",
              " '2008_007854': 'one white bird and  black and white bird on  grassy plain',\n",
              " '2008_007507': ' biplane performing aerobatics',\n",
              " '2008_006732': ' baby sits in  car seat looking upward',\n",
              " '2008_008662': 'the trains sit idly in the yard',\n",
              " '2008_003087': ' brown and white duck in  pond',\n",
              " '2008_006087': ' boy sits on  horse near  group of people and another horse',\n",
              " '2008_003852': ' black dog in  grass field',\n",
              " '2008_008714': ' group of sheep and  sheep dog in  large field',\n",
              " '2008_000032': ' city bus driving past  building',\n",
              " '2008_000911': 'an empty glass vase and  colorful vase with paper flowers behind it made from  bottle',\n",
              " '2008_001208': ' white car driving past two domed buildings',\n",
              " '2008_005074': ' car and three buses in  rearview mirror',\n",
              " '2008_002776': ' hotel room with  flat panel on the wall and  wet bar',\n",
              " '2008_008755': ' couple posing for  photo under  large sign',\n",
              " '2008_002892': ' group of five people sitting at  table with water glasses on it',\n",
              " '2008_005923': ' photo from the air of four people in  thin canoe',\n",
              " '2008_000345': ' brown cat sits by  window',\n",
              " '2008_007746': ' row of brightly colored motorcycles',\n",
              " '2008_005926': ' blue couch with sparse surroundings',\n",
              " '2008_000202': ' 4h booth with posters television and three people presenting near  laptop',\n",
              " '2008_002442': ' close up of  woman holding  white puppy',\n",
              " '2008_008266': ' middleaged woman poses for the camera at  steakhouse',\n",
              " '2008_006624': ' large tv rests in the center of the room against  brick wall',\n",
              " '2008_003415': ' nice silver toyota faces me on  brick driveway with its two front doors open',\n",
              " '2008_008162': ' couple holds  baby',\n",
              " '2008_005968': ' black steam engine with yellow stars on it',\n",
              " '2008_000219': ' brown horse and  tan calf in  pasture',\n",
              " '2008_002931': 'two girls posing in front of  waterfall',\n",
              " '2008_001203': ' closeup of bright colored houses',\n",
              " '2008_006748': ' large yellow bus is parked next to  building by  field',\n",
              " '2008_001135': ' big ship sails in front of  mountain village',\n",
              " '2008_007282': ' cozy woodpaneled living room with  wood burning stove welcomes you',\n",
              " '2008_006944': ' man stands beside  person on  black motorcycle in  parking lot',\n",
              " '2008_006762': ' silver car parked in  suburban neighborhood',\n",
              " '2008_000270': ' mother reading with her daughter and dog',\n",
              " '2008_002362': 'girls at atable',\n",
              " '2008_001673': ' woman has  bird on her shoulder and another bird on her head',\n",
              " '2008_003924': ' black and cream bus is parked near other buses',\n",
              " '2008_000305': ' hotel room contains  flatscreen tv and sparse but adequate furnishings',\n",
              " '2008_006064': ' man and his bicycle laying down on the green grass',\n",
              " '2008_003062': ' darkhaired man with  mustache is behind  redhaired man on  boat',\n",
              " '2008_008753': ' bicycle is scaling the stone wall',\n",
              " '2008_005414': ' group of people sitting around  table on  porch',\n",
              " '2008_007138': ' man in jeans and  black tshirt sits astride  motorcycle',\n",
              " '2008_006186': ' bird is perched on  persons gloved hand',\n",
              " '2008_005160': ' chihuahua is standing on the ground looking up at the camera',\n",
              " '2008_004550': ' bathtub under stained glass windows',\n",
              " '2008_004588': ' room with  red ottoman overlooking  window',\n",
              " '2008_008177': 'motorcycles withjackets',\n",
              " '2008_001632': ' motion shot of the right side of  red ferrari',\n",
              " '2008_000564': ' girl and three tents are outside  house with  flag',\n",
              " '2008_008223': ' passenger train waiting in  station',\n",
              " '2008_005375': 'two black and white cows drinking out of  pond',\n",
              " '2008_003533': 'children playing catch with baseball',\n",
              " '2008_006441': ' grey haired man inspects  red suzuki motorcycle',\n",
              " '2008_001448': ' larger plane in flying above  smaller plane',\n",
              " '2008_006008': ' table and three chairs with  large wall cupboard above',\n",
              " '2008_003997': ' black and white photo of  seagull flying in front of the golden gate bridge',\n",
              " '2008_000493': ' women holds  baby on  sofa with  small boy sitting next to her',\n",
              " '2008_005348': ' dinner table set for three people',\n",
              " '2008_007363': ' ginger and white cat curled up and asleep on  leather chair',\n",
              " '2008_000834': 'two men paddle  red kayak',\n",
              " '2008_002749': ' cat lays on  white towel',\n",
              " '2008_003819': ' bicycle race in  suburban neighborhood with  crowd watching',\n",
              " '2008_005660': 'duel monitors is now the norm in most home office set ups',\n",
              " '2008_000335': 'black and white cows behind  fence',\n",
              " '2008_002329': ' cat playing with  feather',\n",
              " '2008_004330': ' child in pajamas opens  wrapped gift in front of  christmas tree',\n",
              " '2008_008132': ' hairless white cow',\n",
              " '2008_005105': ' dark brown and black bull in front of  wire fence',\n",
              " '2008_008748': ' red and white double decker bus is parked',\n",
              " '2008_005065': 'two dogs playing in the water',\n",
              " '2008_006887': ' mickey mouse figurine is sitting next to  toy hippo',\n",
              " '2008_000376': ' close up of  man on  passenger plane',\n",
              " '2008_008241': ' cow drinking out of  water trough',\n",
              " '2008_001601': ' sheep',\n",
              " '2008_005593': ' car with  canoe on top is parked on the street near  moped',\n",
              " '2008_004097': ' cluttered living space is typical of  small apartment',\n",
              " '2008_003297': ' brown and white cow standing in  grassy area with trees behind',\n",
              " '2008_000085': ' black car with damage in the back',\n",
              " '2008_002547': ' black flat screen television placed on the floor',\n",
              " '2008_008668': 'distant view of two lambs perched on top of  rocky plain',\n",
              " '2008_002521': ' desk and chair are illuminated and near  laundry closet',\n",
              " '2008_006526': ' man sitting on  porch with two motor scooters parked outside',\n",
              " '2008_007584': ' group of people sitting on  small sofa next to  kitchen',\n",
              " '2008_000421': ' woman is lying across the laps of two men sitting on  couch',\n",
              " '2008_006517': ' close up of the front end of  purple and white motor cycle',\n",
              " '2008_000132': 'advertisement sign on top of yellow school bus',\n",
              " '2008_005140': ' bottle of beer and its cap',\n",
              " '2008_008040': ' brown horse and rider jumping over hay bales',\n",
              " '2008_005625': ' group of people with  women holding  small child and  birthday cake',\n",
              " '2008_008528': ' crowd of bicycle rides ride down the street',\n",
              " '2008_008269': ' computer on the floor',\n",
              " '2008_007855': ' cat laying on its side with  light source to its backside',\n",
              " '2008_008671': ' man is alone on the back of  tandem bicycle',\n",
              " '2008_001333': ' father napping in  chair with  baby on his lap',\n",
              " '2008_003321': ' graffiticovered school bus sits under  highway overpass',\n",
              " '2008_001541': ' small street in an urban area',\n",
              " '2008_003821': ' black and white bench next to  window',\n",
              " '2008_004289': ' naturally stained wooden table with four chairs',\n",
              " '2008_007621': ' brown and white dog poses near  fruit tree in  container pot',\n",
              " '2008_005097': ' group of cows in  field with yellow tags in their ears',\n",
              " '2008_006835': ' white sheep and  black sheep in  field',\n",
              " '2008_008674': ' school bus driving down  remote dirt road',\n",
              " '2008_008431': ' closeup view of  little girl riding  horse',\n",
              " '2008_004689': ' blue bird standing on  lawn',\n",
              " '2008_007909': ' closeup of an animal with curved horns',\n",
              " '2008_004850': ' stretched view of  blue car going to the right on the bottom and  beige car going toward the left',\n",
              " '2008_007026': 'brown and white cows are looking ahead',\n",
              " '2008_002567': ' group of people sitting around  dining table the men dressed in military dress',\n",
              " '2008_006649': ' gray car has fire painted on it',\n",
              " '2008_004452': ' bird is pecking at  log in amarsh',\n",
              " '2008_001041': ' caravel towing  fiberglass boat',\n",
              " '2008_007241': ' motorcycle parked next to  car',\n",
              " '2008_005757': ' beautiful striped bird on  barren limb',\n",
              " '2008_003814': ' small efficiency apartment complete with twin bed soda and entertainment center',\n",
              " '2008_003100': ' man stands while paddling  small canoe',\n",
              " '2008_001160': ' cruise ship docked at  coast',\n",
              " '2008_002666': ' girl riding  brown horse',\n",
              " '2008_000346': ' man is standing next to  yellow sports car',\n",
              " '2008_005758': ' guy wearing  cap backwards and standing between two large cocacola bottles that are taller than he is',\n",
              " '2008_005812': ' man is reading the label on  beverage bottle',\n",
              " '2008_007739': ' bmw motorcycle parked between two cars',\n",
              " '2008_004862': ' line of parked cars and people fixing bicycles',\n",
              " '2008_006841': ' child dressed in pink with  purse over her shoulder walks through  kitchen',\n",
              " '2008_001941': ' clean shiny black tire in the rear of  truck',\n",
              " '2008_000547': ' person jumping  dirt bike with  boy watching',\n",
              " '2008_008252': ' blue party bus',\n",
              " '2008_000748': ' guy in  sports jersey poses with  girl in  kitchen',\n",
              " '2008_002410': 'cats on abed',\n",
              " '2008_000448': ' woman holding  baby wearing  yellow hat',\n",
              " '2008_001078': ' black and white cat gets into  basket of yarn',\n",
              " '2008_002686': ' brown and white horse with its eyes closed with  barn in the background',\n",
              " '2008_005916': ' grounded passage plane in  terminal',\n",
              " '2008_006081': ' black and white cat laying on  cat bed',\n",
              " '2008_007348': ' motocross rider and bike flying over  dirt track',\n",
              " '2008_001318': ' girl wearing black',\n",
              " '2008_008373': ' large passenger jet flying close to the ground',\n",
              " '2008_000413': ' dark haired woman with green eyes and  blue sweater is smiling',\n",
              " '2008_002679': ' boy doing  wheelie on  plank with the beach in the background',\n",
              " '2008_001020': ' white bird is steering  shopping cart',\n",
              " '2008_001586': ' banner that says borkop rocker hangs over the sidewalk entry to the parking lot of  manywindowed building',\n",
              " '2008_001704': ' laptop and  pc at  workstation',\n",
              " '2008_005536': 'black and white picture of two old cruise liners',\n",
              " '2008_004990': ' brown and orange cat eating from  bowl',\n",
              " '2008_007871': ' black dog is standing near some scaffolding with some plywood in front of it',\n",
              " '2008_007521': ' picture of an old train on the tracks',\n",
              " '2008_004441': ' man knees on the ground while talking on his cell phone next to  bike and car',\n",
              " '2008_005924': ' flock of birds flying over  body of water',\n",
              " '2008_007103': ' black and white image of  cyclist riding in the bike lane',\n",
              " '2008_008635': ' group of black cows grazing in  field with  large tree behind',\n",
              " '2008_004367': ' cn freight engine passes by  larger freight train',\n",
              " '2008_001758': 'friends atdinner',\n",
              " '2008_005277': ' city street with  red double decker bus passing by',\n",
              " '2008_007823': ' close up of  potted plant',\n",
              " '2008_003788': ' das air cargo plane sits on the runway',\n",
              " '2008_001985': 'fighter jet formation flying over lake',\n",
              " '2008_007488': ' side view of  red double decker bus on  busy street',\n",
              " '2008_002201': ' gray and white cat laying down looking through  white fence',\n",
              " '2008_004113': 'cyclists crossing  metal bridge',\n",
              " '2008_000075': ' large white victory liner bus with red and yellow trim is in  parking lot',\n",
              " '2008_008322': 'three sheep are in the road as  car approaches',\n",
              " '2008_008066': 'an old red london double decker bus with its hood raised',\n",
              " '2008_008572': ' mountain biker is caught in mid jump with his bike on  dirt hill',\n",
              " '2008_008271': ' black and wooden seating area',\n",
              " '2008_002278': 'cattle grazing on  snowy field',\n",
              " '2008_003580': ' close up of  seagull with others in the background',\n",
              " '2008_001784': ' bride and groom along with other family members in  church',\n",
              " '2008_005975': ' bronze statue of  buddy holding  candle sitting on  white table and runner with leaves',\n",
              " '2008_001688': ' television and entertainment center',\n",
              " '2008_008370': ' cow walking through  field',\n",
              " '2008_007485': ' man is making  jump on  bicycle',\n",
              " '2008_006181': ' man jogging in  race',\n",
              " '2008_008227': ' motorcycle and passenger car on  dirt trail',\n",
              " '2008_004166': ' brown horse and  brown pony walking through  grassy field seen through wooden fencepost',\n",
              " '2008_008549': ' crowded doubledecker bus station in the city',\n",
              " '2008_007804': ' busy street in front of  kfc restaurant',\n",
              " '2008_001062': 'five cows are grazing beside the road',\n",
              " '2008_007576': ' man in  tux on  white horse',\n",
              " '2008_005282': 'an indoor train depot with trains on both sides of the walkway',\n",
              " '2008_007184': 'two dirt bikers riding over dirt hill',\n",
              " '2008_004501': ' man sitting at an office desk with his computer on',\n",
              " '2008_004629': ' domestic animal stands in  pen',\n",
              " '2008_006654': ' distant view of  sailboat surrounded by the calm blue sea',\n",
              " '2008_003393': ' girl on  couch looking to the woman sitting next to her',\n",
              " '2008_003775': 'one man has  hold of another man from behind while  third man watches',\n",
              " '2008_004854': ' black sheep and  white sheep stand on grass but the white one has blue earphones and an spot',\n",
              " '2008_001830': ' red dodge ram spinning its rear tires and  black truck whom appear to be racing',\n",
              " '2008_005023': ' crowded refrigerator with four levels contains blue lunch bags yogurt apples rolls leftover containers and more',\n",
              " '2008_004007': ' baby white sheep in  wooden enclosure',\n",
              " '2008_007757': ' blonde in  polkadot bikini poses in front of an orange convertible car',\n",
              " '2008_003447': ' horse galloping while wearing the number ',\n",
              " '2008_008404': ' brown white and black spotted owl',\n",
              " '2008_000138': ' few people and  dog are inside  leanto type structure',\n",
              " '2008_008649': ' large white living room with  fireplace and large tv',\n",
              " '2008_008619': 'two african men carry  tied up animal in the basket of their bicycles',\n",
              " '2008_001809': ' black and wood colored dining room set in  small apartment',\n",
              " '2008_007759': ' man walking past the red and yellow train',\n",
              " '2008_004930': ' closeup of  television monitor with  man on tv',\n",
              " '2008_007839': ' hummingbird landing on  selection of glassware outside',\n",
              " '2008_008146': ' jet flies high in the blue sky',\n",
              " '2008_002948': ' blue tan and black leather sofa on the sidewalk between bicycles',\n",
              " '2008_000109': ' woman wearing shorts and  desktop poses on the hood of  white car',\n",
              " '2008_002850': ' cruiseliner docked at  port',\n",
              " '2008_004938': 'an overweight woman in pajamas and bunny slippers is sitting on  green couch',\n",
              " '2008_008098': ' mother and her child',\n",
              " '2008_006182': ' figurine of  man next to  bottle of liquor',\n",
              " '2008_004858': ' hand painted volkswagon bug',\n",
              " '2008_008622': ' dark brown dog on  blue loveseat and  light brown puppy on  cream rug',\n",
              " '2008_004615': ' helmet is on  parked motorcycle next to another parked motorcycle',\n",
              " '2008_006010': ' train car at  large group of railroad tracks',\n",
              " '2008_007067': 'an adult rides  childs bike',\n",
              " '2008_004760': ' dog lies down with its mouth open',\n",
              " '2008_008131': ' blue bicycle parked beside the tree',\n",
              " '2008_008113': ' bus',\n",
              " '2008_007498': ' bird eating from  bird feeder',\n",
              " '2008_007831': 'assorted small potted plants labeled on shelves',\n",
              " '2008_005817': ' flat screen with all sorts of wires and electronics in front of it',\n",
              " '2008_006483': ' bus and two cars driving during  snowstorm',\n",
              " '2008_001501': ' group of children jump on the beach',\n",
              " '2008_008613': ' field of black faced sheep',\n",
              " '2008_003709': ' white colored room with closed blinds and two dark sofas',\n",
              " '2008_002817': ' computer and collection of gadgets including pop cell phone pot and game advance',\n",
              " '2008_007953': ' fairy tour boat is docked near  city with some flowers in the foreground',\n",
              " '2008_008034': ' jockey riding  horse',\n",
              " '2008_005175': ' building is surrounded by wide attractions such as  horse statue and  statue of  giant hand and wrist with  picnic table next to them',\n",
              " '2008_004171': ' closeup of  plant in  terra cotta plant pot',\n",
              " '2008_007948': 'birds sitting on abar',\n",
              " '2008_005954': ' unique living room with tv brown table green and brown walls and white chairs',\n",
              " '2008_002697': ' brown horse about to start his run',\n",
              " '2008_007196': 'several televisions are on the floor and stacked up on top of one another',\n",
              " '2008_002179': ' red and white bus drives down an england street',\n",
              " '2008_008632': 'an american flag and another flag fly above  yellow train engine and snow',\n",
              " '2008_005427': ' man does  trick by standing on the seat of  moving motorcycle',\n",
              " '2008_000195': ' family getting ready to go canoe on  small lake',\n",
              " '2008_002653': ' little darkhaired girl in  blue dress and boots sits on  concrete pedestal surrounded by plants and flowers',\n",
              " '2008_008296': ' pitched tent with  horse in the background',\n",
              " '2008_006890': ' boy holding  beer',\n",
              " '2008_007346': 'four people are rowing  boat near the shore',\n",
              " '2008_004528': ' brown and white dog sits on  floralpatterned chair',\n",
              " '2008_003622': ' cat is petted by someone',\n",
              " '2008_007168': ' woman opens gifts on  food covered table while another women photographs her',\n",
              " '2008_003351': ' man parking his bike near  building',\n",
              " '2008_008666': ' sheep with  tree in the foreground',\n",
              " '2008_005214': ' row of brightly colored plant pots under  blue sky',\n",
              " '2008_008341': ' metallic and ceramic dolphin sculpture in  mall',\n",
              " '2008_002384': ' man in  white shirt sitting at  small cluttered table',\n",
              " '2008_005902': ' blue moped parked on the sidewalk',\n",
              " '2008_000912': ' closeup of  brown horse',\n",
              " '2008_008521': 'about nine cows are laying on some mulch in  stable area',\n",
              " '2008_002066': ' computer monitor has  picture of  cat in  pumpkin',\n",
              " '2008_003673': ' continental air liner parked at an airport',\n",
              " '2008_005938': ' sheep in  patch of green grass',\n",
              " '2008_003988': ' channel of water runs through  city with boats and fairies as seen over  rail',\n",
              " '2008_007446': ' man in  ninja turtles tshirt repairs televisions',\n",
              " '2008_003939': ' bicycle in front of some ruins',\n",
              " '2008_006458': ' closeup of  woman with black boots next to  blue motorcycle',\n",
              " '2008_008199': ' black and white photo of cattle at  trough',\n",
              " '2008_004635': ' closeup of  cat on  cream sofa',\n",
              " '2008_008313': ' bag of cotton in front of  couch',\n",
              " '2008_008517': ' woman and elderly woman sitting together posing on  couch',\n",
              " '2008_007394': ' bottle of conti zecca cantalupi',\n",
              " '2008_002845': ' black and white cat standing in front of  window',\n",
              " '2008_002026': ' beige living room has  chair lamp table and other furniture',\n",
              " '2008_004291': 'aircraft carrier floating in middle of ocean',\n",
              " '2008_001523': ' person rides  bicycle on concrete',\n",
              " '2008_004450': 'farmyard animals sitting under  group of trees and bushes while grazing',\n",
              " '2008_007254': ' female in jeans and  pink shirt is standing next to  bus wait its doors open',\n",
              " '2008_006655': ' blue and yellow train crosses  river near  waterfall',\n",
              " '2008_006210': ' brown and white cow in  field looking into the camera',\n",
              " '2008_007987': ' computer desk displays elvis memorabilia',\n",
              " '2008_002672': ' liquor store alongside  laundrette with  parking lot out front',\n",
              " '2008_004008': ' green lamp sits beside  television on  dresser in  bedroom with white furniture',\n",
              " '2008_001850': ' close up of  silver train',\n",
              " '2008_004973': ' black and white bird sitting on the water looking down',\n",
              " '2008_006192': ' country dinner setting with  bounty of food such as steak fruit salad and coffee',\n",
              " '2008_007402': ' woman in  blue dress cuts  cake',\n",
              " '2008_002119': ' bright red couch in  room with mostly wooden furniture',\n",
              " '2008_006992': ' black and white photo of  dilapidated wooden fence',\n",
              " '2008_001164': ' colorful train',\n",
              " '2008_004983': ' man is rowing  gondola through  city waterway',\n",
              " '2008_004004': '',\n",
              " '2008_003576': ' small white dog standing wearing some dogclothing',\n",
              " '2008_002222': ' man waits on the platform as the light rail train approaches',\n",
              " '2008_004130': ' main standing under  road bridge',\n",
              " '2008_007599': ' cruise ship coming into port',\n",
              " '2008_006467': ' bicyclist in black on  black and red racing bike',\n",
              " '2008_008718': 'bikers lean into  turn during  race',\n",
              " '2008_004873': ' black and brown cat looks up with green eyes',\n",
              " '2008_003951': 'two men on  pebble beach near the edge of the water are posing on  cloudy day',\n",
              " '2008_005774': ' black and white scene of birds eating at bird feeder',\n",
              " '2008_007313': ' moped is parked at  metal bike rack in front of  chain link fence in an urban area',\n",
              " '2008_007231': ' large yellow locomotive showing the number 8300 with  bright blue sky above',\n",
              " '2008_000393': ' group of african men women and children around three scooters',\n",
              " '2008_006290': 'two cows facing the camera in  field of grass',\n",
              " '2008_000252': 'gentleman with one glove posing for winter photo',\n",
              " '2008_008402': ' living with pink walls',\n",
              " '2008_008744': ' boy is sniffed through  fence by  black sheep',\n",
              " '2008_007837': ' man and two women smiling at the camera while sitting on  blue sofa',\n",
              " '2008_000275': ' line outside of  bookstore on  street',\n",
              " '2008_005914': ' small house with  broken door and windows',\n",
              " '2008_003466': ' silver television on  silver stand with visible wires',\n",
              " '2008_006070': ' black sheep in front of  gray sheep in front of  fence and  white sheep',\n",
              " '2008_006112': ' small tree and  plant inside  pot',\n",
              " '2008_006912': ' horse rider is riding  white horse',\n",
              " '2008_005429': ' customer inspects  new scooter',\n",
              " '2008_004214': ' bnsf railroad train on  track by water',\n",
              " '2008_000099': ' black and tan dog looks at  black sheep',\n",
              " '2008_006102': ' man sitting cross legged on the grass with  tree in the background',\n",
              " '2008_008109': ' large sheep standing between large trees in  rural area',\n",
              " '2008_004745': ' girl and dog pose before  christmas tree with  train track circling it',\n",
              " '2008_005570': ' group of people sit at  table in an italian restaurant',\n",
              " '2008_007459': ' couple posing on  red and yellow motorcycle',\n",
              " '2008_003290': ' black and white photo of two men drinking alcohol and one holding  guitar',\n",
              " '2008_002988': ' little girl in  pink and white floral dress',\n",
              " '2008_005386': ' gray and white cat sits on  table',\n",
              " '2008_006877': ' boat is going down  river in  city',\n",
              " '2008_004795': ' black and white picture of  kitchen shelf with  lamp overhead',\n",
              " '2008_006554': ' large white bus parked next to  blue truck with officers nearby',\n",
              " '2008_007039': ' cat stretching by  wall on patterned fabric',\n",
              " '2008_004380': ' black and white photo of four people playing scrabble',\n",
              " '2008_008106': ' bright blue couch sits near  overturned chaise lounge and bench',\n",
              " '2008_003998': ' plate of food is laying on  pink tablecloth',\n",
              " '2008_008115': 'bony cows stand in grass with mountains in the background',\n",
              " '2008_005181': ' black dog laying on the deck',\n",
              " '2008_003283': ' girl is seated on  donkey and an older woman stands to her right',\n",
              " '2008_002338': 'two brown horses in  pasture',\n",
              " '2008_007226': ' potted plant with only two leaves sprouted',\n",
              " '2008_008231': ' beautiful view in the mountains is taken in by  man wearing shorts',\n",
              " '2008_007378': ' dog on the deck chewing on  twig',\n",
              " '2008_000670': ' brown cat sleeping on  sofa',\n",
              " '2008_004347': ' cat looking at the camera',\n",
              " '2008_003037': ' messy bedroom',\n",
              " '2008_000706': 'an old black woman wearing  turban and  headdress and  dog next to her wearing the same red headdress',\n",
              " '2008_000257': ' large field containing  group of sheep with trees in the distance',\n",
              " '2008_007949': ' carpeted kitchen with the dining room in the foreground',\n",
              " '2008_004014': ' small yellow boat is beached on the shore near the ocean',\n",
              " '2008_007050': ' living room with wooden floors and patterned sofas',\n",
              " '2008_001290': ' black stripped cat',\n",
              " '2008_000964': 'animals find things to eat and drink on the river bed',\n",
              " '2008_005641': ' race care driving along  dirt road',\n",
              " '2008_004123': ' small boy with curly black hair sits at  table to color',\n",
              " '2008_008593': ' man is laying on the floor holding  baby up above him',\n",
              " '2008_005945': ' dish of pasta being devoured off  paper plate',\n",
              " '2008_002202': ' black harleydavidson motorcycle parked in  parking lot',\n",
              " '2008_008628': ' broken sofa sits beneath  concrete structure with graffiti',\n",
              " '2008_007629': ' grounded passenger plane at an airport',\n",
              " '2008_001301': ' guy is having  drink and smiling and another guy is looking at him while laughing',\n",
              " '2008_001077': ' candle lit dinner set for two each with  glass of wine',\n",
              " '2008_006355': ' black and white cow standing in the field',\n",
              " '2008_004665': ' man sitting in  chair with  laptop on his lap watching  tv set in the corner',\n",
              " '2008_006807': 'the two men are standing next to their bicycles in front of the building',\n",
              " '2008_006956': ' black and white cat lying on  blanket',\n",
              " '2008_005008': ' home office set up complete with  can of soda',\n",
              " '2008_008589': ' clear plastic chair',\n",
              " '2008_005695': ' three masted schooner lying at anchor',\n",
              " '2008_002870': ' darkskinned man in  green jacket holds up  bottle of beer toward me',\n",
              " '2008_008708': ' boy with  helmet on  bicycle',\n",
              " '2008_002970': ' red and brown bird is perched on branches',\n",
              " '2008_004654': ' girl performing  trick on her bicycle',\n",
              " '2008_008246': 'african man on blue bike posing with  friends',\n",
              " '2008_004619': ' loft with  black bookcase beneath it',\n",
              " '2008_008123': 'an electric train on tracks under an overpass',\n",
              " '2008_008490': 'the two birds are standing on the ground',\n",
              " '2008_003178': ' group of red plastic chairs in  hall',\n",
              " '2008_001380': ' derfw6 in flight',\n",
              " '2008_001021': ' man pressing  button on  television',\n",
              " '2008_005010': ' field with many black cows in it',\n",
              " '2008_006254': ' bicycle racer in front of  car which has two bikes on top of it',\n",
              " '2008_007245': ' large ram at the top of  hill',\n",
              " '2008_004908': ' computer with two monitors on  white desk',\n",
              " '2008_001862': ' black dog approaches the potted plants in the foreground',\n",
              " '2008_003986': ' cute green jeep',\n",
              " '2008_008097': ' man in  street cleaning tricycle in china',\n",
              " '2008_006336': ' car is parked by the side of the road near mountains',\n",
              " '2008_002903': ' dining table in front of  window with two sofas in the fore ground',\n",
              " '2008_003617': ' distorted photo of  man cutting up  large cut of meat in  garage',\n",
              " '2008_008072': ' baby in  red sox sweatshirt and  dirty face prepares to eat  lemon',\n",
              " '2008_001772': ' green painted office with  buster eaten poster and  soda bottle on the wall',\n",
              " '2008_004911': ' foal frolicking in  grassy field',\n",
              " '2008_000904': ' happy mother dotes on her children',\n",
              " '2008_006611': ' boy pointing at another boy at the table',\n",
              " '2008_001928': ' couple wearing black sits in  restaurant with  log cabin decor',\n",
              " '2008_000691': ' mother prepares to feed her infant son',\n",
              " '2008_005639': ' bookcase with entertainment center and tv',\n",
              " '2008_008450': ' row of motorbikes parked in front of  store',\n",
              " '2008_002452': ' small train stopped on the tracks in  park',\n",
              " '2008_000163': ' white limo is parked on the side of  street',\n",
              " '2008_003264': ' kitchen table in  room with white drapes and  china cabinet',\n",
              " '2008_001682': ' brown horse in  green field',\n",
              " '2008_005094': ' man laying on  bed with beer cans on  nearby table',\n",
              " '2008_006429': ' beige horse poses for the camera with her foal',\n",
              " '2008_007497': ' goat stands on  rock with trees in the background',\n",
              " '2008_003067': ' double decker bus on  city street',\n",
              " '2008_007176': ' ginger kitten asleep on  brown leather sofa',\n",
              " '2008_003245': 'an smiling asian child sits beside  young women near  blue mosaic table',\n",
              " '2008_002773': 'airplanes flying in formation over boats in  body of water',\n",
              " '2008_007390': ' closeup of  house with yellow siding shutters and flowers',\n",
              " '2008_005090': 'there are two people sitting on  purple couch while smoking',\n",
              " '2008_002358': ' green and gray plane is taking off from the runway',\n",
              " '2008_001220': ' small tan dog and  large brown dog bite each other',\n",
              " '2008_008388': ' group of people sitting outside at  picnic table under  canopy',\n",
              " '2008_006720': ' view over  cliff with  big sailboat in the distance',\n",
              " '2008_005891': ' yellow taxi passing two school buses',\n",
              " '2008_008247': ' blue airplane beside the blue water',\n",
              " '2008_003182': ' man holding  green bottle in left hand and petting horse with the other',\n",
              " '2008_004445': ' grey house with  red door',\n",
              " '2008_006072': ' blurry photo of  bottle of water',\n",
              " '2008_003373': ' coach bus parked near another in  parking lot',\n",
              " '2008_003691': ' bus drives down  busy road',\n",
              " '2008_008567': ' girl sits on the couch with her arms crossed',\n",
              " '2008_008527': ' yellow and white train and one orange train on the opposite sides of  small train station',\n",
              " '2008_000987': ' group of friends pose with furry hats',\n",
              " '2008_004679': ' yellow school bus is stopped on the street with its door open',\n",
              " '2008_004968': ' city street with buses in the distance',\n",
              " '2008_001837': 'four people are behind  table',\n",
              " '2008_005563': ' man in camouflage clothing is crouching behind  bush while  white dog looks on',\n",
              " '2008_002926': 'an orange moped',\n",
              " '2008_002430': ' dog chasing its prey through  field of grass',\n",
              " '2008_008203': ' red and cream colored train with graffiti on it at  small open air train station',\n",
              " '2008_000272': ' kitchen area',\n",
              " '2008_004610': ' long train is on train tracks',\n",
              " '2008_005823': ' black and white dog sniffing at  closed door',\n",
              " '2008_001625': ' boxcar with graffiti on it',\n",
              " '2008_005447': 'an old man with sheep in the background',\n",
              " '2008_001836': ' ginger cat laying on black plastic',\n",
              " '2008_007076': ' green glass jar',\n",
              " '2008_000982': ' large green bus on the street',\n",
              " '2008_002674': ' darkskinned woman sits in  rocking chair holding  tiny baby wrapped in  blanket',\n",
              " '2008_002882': ' man woman and teenage boy pose together inside',\n",
              " '2008_008725': ' cyclist riding along  waterside path',\n",
              " '2008_007589': ' small white cat with glowing eyes standing underneath  chair',\n",
              " '2008_007806': ' black and white lamb with other lambs in the background',\n",
              " '2008_003060': ' yellow bus has  face and ears like  cat',\n",
              " '2008_007361': 'an apartment scene showing  small fridge  table with stools  desk and  chair with  towel over the back',\n",
              " '2008_001895': ' scruffy dog looks up at someone',\n",
              " '2008_007205': ' baby penguin eats out of its mothers mouth',\n",
              " '2008_007003': ' bluegreen hummingbird sits upon  twig',\n",
              " '2008_001563': ' boy in  tux and  girl in  blue dress sit at  wedding',\n",
              " '2008_007612': ' blurry picture of  man on  white horse',\n",
              " '2008_001460': 'an indoor plant in  yellow pot by  window',\n",
              " '2008_006999': ' cat sitting on sand looking up at the camera',\n",
              " '2008_000916': 'green train arriving at station',\n",
              " '2008_005279': ' blue and green hummingbird hovers near  pink flower',\n",
              " '2008_000976': ' group of women posing for  picture',\n",
              " '2008_005635': ' person covered from head to toe tending six sheep in the pasture',\n",
              " '2008_007779': ' black coal train passes many overhead wires',\n",
              " '2008_003244': ' cat laying on  red cushion looking at the camera',\n",
              " '2008_006289': ' sail boat with two people',\n",
              " '2008_000716': 'one jet lands at an airport while another takes off next to it',\n",
              " '2008_003068': ' green steam engine traveling on the railroad tracks',\n",
              " '2008_004740': ' woman in  black bikini top and jeans',\n",
              " '2008_004776': ' kitchendiner with papers laying on the blue clothed dining table',\n",
              " '2008_007375': ' red double decker bus is picking up more passengers in  city',\n",
              " '2008_002922': ' couple posing for  picture on  couch',\n",
              " '2008_008453': ' group of horses grazing in  field',\n",
              " '2008_001723': ' dining room containing two tables',\n",
              " '2008_007742': ' boy and  girl smile while standing by some folding chairs',\n",
              " '2008_007955': 'several people riding dirt bikes with number plates on the bikes',\n",
              " '2008_008169': ' brown cow on  farm',\n",
              " '2008_006130': ' dog napping under  small table',\n",
              " '2008_007916': ' darkened desk with  desktop pc and  lamp',\n",
              " '2008_007997': ' doubledecker bus passes  row of flags',\n",
              " '2008_000196': ' calico cat seated on the doorstep surrounded by bikes and junk',\n",
              " '2008_008446': ' plane maneuvers at low altitude over the river',\n",
              " '2008_005863': ' large boat in the water at the marina',\n",
              " '2008_005111': ' girl holding  black white dog with  blue dog chain',\n",
              " '2008_001235': ' black and white photo of  woman showing  horse',\n",
              " '2008_006068': ' black and white cat along with  purple african violet plant atop  windowsill',\n",
              " '2008_004614': ' beautiful day to visit the cathedral',\n",
              " '2008_006969': ' busy restaurant with four people looking at the camera',\n",
              " '2008_006401': ' small plane grounded in  field of grass',\n",
              " '2008_008044': ' gray jet parked near the building',\n",
              " '2008_003232': ' close up head of an ostrich',\n",
              " '2008_005494': ' boy feeding  sheep hay',\n",
              " '2008_003073': ' plaid patterned bedspread in  room with plaid patterned wall paper',\n",
              " '2008_007004': ' bay quarter horse with  white blaze is trotting in  field',\n",
              " '2008_004303': ' cat lying down attacking  straw broom with its mouth and front paw',\n",
              " '2008_008096': ' fighter jet on display',\n",
              " '2008_002613': ' closeup of  woman posing with  lotion bottle',\n",
              " '2008_007247': ' black train engine is facing me on the tracks with its light on in the woods during the day',\n",
              " '2008_003461': ' man and woman with helmets on brown horses at  farm',\n",
              " '2008_005905': ' blue airplane in  tailspin at an airshow',\n",
              " '2008_006477': ' black and white baby goat looks off to the side',\n",
              " '2008_001227': 'two gentleman talking in front of propeller plane',\n",
              " '2008_007222': ' bundled up child rides  bicycle with training wheels in the snow',\n",
              " '2008_008354': ' green and orange lovebird with its feet vertically on its cage',\n",
              " '2008_001451': ' blond woman mingles with guests at  party',\n",
              " '2008_001226': ' biker in  helmet holds  phone up to their ear',\n",
              " '2008_003689': ' girl sitting in  living chair',\n",
              " '2008_001035': ' woman and child push strollers down the sidewalk',\n",
              " '2008_007011': ' multicolored train on  track',\n",
              " '2008_004100': ' boac boeing 747 sitting on the airport tarmac',\n",
              " '2008_000437': ' beautiful lake surrounded by trees with two small boats on the beach',\n",
              " '2008_007324': ' computer on  desk',\n",
              " '2008_004020': ' closeup of the back of  red car',\n",
              " '2008_000227': ' gray cat laying on  brown table',\n",
              " '2008_008362': ' group of men sitting around  table drinking while  man behind stands pointing',\n",
              " '2008_000897': ' black dog is chasing an object',\n",
              " '2008_007470': ' guy with headphones midair on  bike under an overpass painted with graffiti',\n",
              " '2008_001468': ' blue grounded fighter jet is parked on grass in front of  glass building',\n",
              " '2008_000641': ' cat and  dog laying on  rug in the sunshine',\n",
              " '2008_008487': ' father and  daughter looking at  pony through  chain link fence',\n",
              " '2008_001083': ' group of elderly people pose around  dining table',\n",
              " '2008_007567': 'an elderly woman poses beside  small child dressed as  bumblebee on halloween',\n",
              " '2008_006924': ' hand holding bird seed and  small bird',\n",
              " '2008_006397': ' jockey races on the number  gray horse',\n",
              " '2008_003995': 'college students finally get the answer theyve been looking for',\n",
              " '2008_000704': ' man in shorts and  blue polo shirt sits on the redcushioned wicker couch',\n",
              " '2008_002804': ' motorcycle and rider in  large field',\n",
              " '2008_004301': ' boy looking at  computer screen',\n",
              " '2008_006948': ' living room with  green sofa table and tv',\n",
              " '2008_002467': ' blue and green bottle on the sides of an empty bottle',\n",
              " '2008_004969': ' boat with four sails is sailing on water',\n",
              " '2008_008338': ' white jeep at  dealership',\n",
              " '2008_000043': ' wooden table sits in the green dining room on  shiny wooden floor',\n",
              " '2008_005003': ' grey and white tabby cat is sleeping on purple fabric',\n",
              " '2008_005882': ' black and white cat and dog on  striped couch',\n",
              " '2008_008200': 'an electric streetcar is on train tracks',\n",
              " '2008_008368': ' man fixing the back tire of his bicycle',\n",
              " '2008_002752': ' family preparing to ride dirt bikes',\n",
              " '2008_007625': ' man in  black uniform on  white horse',\n",
              " '2008_008344': ' fighter jet parked on the tarmac with its canopy open',\n",
              " '2008_008048': 'formation of stunt planes flying through the air',\n",
              " '2008_005360': 'tourists are ready to aboard the bus',\n",
              " '2008_005329': ' desk in  corner of  room with  computer and  laptop',\n",
              " '2008_007882': ' happy man in  blue shirt is standing in front of  fountain',\n",
              " '2008_006623': 'another successful take off for csa',\n",
              " '2008_004991': ' boy and  girl are sitting on  deck and fishing',\n",
              " '2008_005761': 'an elderly woman catches  ride on the back of the bicycle',\n",
              " '2008_006553': ' black steam train traveling on the railroad tracks',\n",
              " '2008_008347': ' red bird and four other birds sitting in the snow',\n",
              " '2008_005107': ' child sits in  large black leather chair',\n",
              " '2008_003224': 'several people holding glasses of wine at table',\n",
              " '2008_007356': ' green bus drives down  road',\n",
              " '2008_008232': 'people riding horses in  fenced area',\n",
              " '2008_007291': ' family of four raising their glasses for  toast',\n",
              " '2008_005276': ' woman posing in front of an apartment building in the snow',\n",
              " '2008_002929': 'teenagers hanging out in their room',\n",
              " '2008_000053': ' black and white dog looking at the camera',\n",
              " '2008_008618': ' man posing in front of  passenger train',\n",
              " '2008_005231': ' guy playing  giant intent in  game store with  blue wall',\n",
              " '2008_008043': ' car on  snow covered runway next to an isreali airplane',\n",
              " '2008_008552': ' dirt bike rider riding around  track',\n",
              " '2008_004292': ' sheep beside  road and  lake',\n",
              " '2008_003472': ' man poses on  maroon chair near  sofa with  bright pillow',\n",
              " '2008_002071': ' garden set in  small court',\n",
              " '2008_000128': ' middle aged lady with brown hair holding  newborn baby',\n",
              " '2008_004044': ' brown and white dog laying on the bed while  woman looks on',\n",
              " '2008_001230': ' couple sitting at table opening  bottle of wine',\n",
              " '2008_006194': ' closeup headshot of  sleeping cat',\n",
              " '2008_007719': ' brown street bicycle',\n",
              " '2008_007442': 'two biplanes are flying side by side emitting contrails',\n",
              " '2008_004328': 'an elderly woman stands in  kitchen with two cats at her feet',\n",
              " '2008_000795': 'three balding men pose together',\n",
              " '2008_000422': ' baby is sitting in the grass',\n",
              " '2008_008365': ' bright lovely dining room is shown decorated with clean rich antique furniture',\n",
              " '2008_005234': ' yellow car is painted like  cartoon mouse',\n",
              " '2008_007043': 'two smiling young ladies sitting on  couch',\n",
              " '2008_006547': 'several cows grazing on grass in field',\n",
              " '2008_002294': ' closeup of  small white cat resting its head on  rock near  window',\n",
              " '2008_008546': ' red and white plane flying on  sunny day',\n",
              " '2008_002150': ' blonde girl sits on the side of  mountain next to  sheep',\n",
              " '2008_005254': ' blank screen with two remotes on the table',\n",
              " '2008_007069': 'field of sheep and lambs under fluffy clouds',\n",
              " '2008_006154': ' man looks on at  bicycle race',\n",
              " '2008_002504': 'an empty boat begs to be used',\n",
              " '2008_008002': 'two birds fly by  fencepost',\n",
              " '2008_004632': ' dark living room with  white couch and  fireplace',\n",
              " '2008_006136': ' computer and monitor on  desk',\n",
              " '2008_004387': ' city street with  bus stop sign',\n",
              " '2008_007352': ' double decker bus drives on  city street',\n",
              " '2008_004931': ' black dog looking at the camera',\n",
              " '2008_006904': 'black and brown cows sit on  field',\n",
              " '2008_006818': 'an old passenger train in blue and white sits in sheffield station',\n",
              " '2008_007281': ' man sits on the couch and uses his laptop in  living room',\n",
              " '2008_000725': ' cyclist relaxes on  bench and gazes toward the ocean',\n",
              " '2008_006892': 'sheep being shaved on wooden floor',\n",
              " '2008_004581': ' messy car',\n",
              " '2008_005560': ' white cat looking out of  kitchen window',\n",
              " '2008_007752': ' bird standing on top of  wooden fencepost',\n",
              " '2008_003329': ' bicyclist explaining arm pain to  fellow rider wearing yellow',\n",
              " '2008_007694': ' dog in the kitchen drinking water from  bowl',\n",
              " '2008_004175': ' brown horse grazing in  field of green grass',\n",
              " '2008_004621': ' little white lamb resting',\n",
              " '2008_003849': ' big white ship is docked',\n",
              " '2008_008428': ' black and white horned cow standing in  field',\n",
              " '2008_001592': ' brown and white fat cat looking out of an iron gate',\n",
              " '2008_000825': ' man is smiling in  garden',\n",
              " '2008_004653': ' black dog',\n",
              " '2008_007691': 'an intricately carved brown chair is empty',\n",
              " '2008_004532': 'an airliner has taken off behind one which is on the ground',\n",
              " '2008_001486': ' girl in  black desktop holds up an open box of corn flakes and  carton of milk',\n",
              " '2008_006281': ' white bird flying up onto  tree',\n",
              " '2008_003905': 'an aeromexico jet taxing along  runway',\n",
              " '2008_006384': ' black and white cat is high up on tree branches',\n",
              " '2008_007841': ' man and two women are posing for the camera on  boat in the water',\n",
              " '2008_003992': ' long american freight train near  station',\n",
              " '2008_006616': ' man in glasses holding  small dog',\n",
              " '2008_002270': ' goat grazing by the water',\n",
              " '2008_004084': ' crowded street with people on motorcycles',\n",
              " '2008_005321': ' boat is docked in water',\n",
              " '2008_003726': ' black cat looking at image in  mirror',\n",
              " '2008_000648': ' grown man wears  baby bib and sits on the couch',\n",
              " '2008_004603': 'people riding tandem bicycle',\n",
              " '2008_003320': ' girl wearing shorts and  tank top on  red and gray moped',\n",
              " '2008_008393': ' close up of  horse wearing  blue halter',\n",
              " '2008_002325': ' man gets off the peruvian train for  photo opportunity',\n",
              " '2008_004470': ' child in  green shirt and riding gear riding  tan horse',\n",
              " '2008_000960': 'two blue macaws sit on  perch in  lush green garden',\n",
              " '2008_004656': ' man on  mountain bike going down an incline',\n",
              " '2008_002894': ' bicycle racer on  road in  rural area',\n",
              " '2008_008583': ' canadian train with the flag of canada on the tracks',\n",
              " '2008_007587': ' humming bird feeding',\n",
              " '2008_005907': 'an old style plane awaits to be loaded with cargo',\n",
              " '2008_000917': ' female child in  pink skirt and pink and white shirt is riding  toy that looks like  duck',\n",
              " '2008_001202': ' family on  boat with  cross on  river',\n",
              " '2008_002368': ' fourwheeldrive vehicle is crossing  stream',\n",
              " '2008_005469': ' kitten looking at the camera',\n",
              " '2008_004979': ' woman at  dinner table writing on her notebook',\n",
              " '2008_008685': ' black calf and  smaller brown calf standing next to  fence in front of  red barn',\n",
              " '2008_004764': ' jockey in  blue jacket riding  brown horse',\n",
              " '2008_003484': 'two bald eagles perched on  branch',\n",
              " '2008_000343': ' backpack standing beside  train',\n",
              " '2008_000112': ' small white cat sitting in  sink',\n",
              " '2008_000915': ' sheep stands alone in an empty bus stop',\n",
              " '2008_000203': ' black and white photo of  man driving  car and someone with  motorcycle',\n",
              " '2008_007056': ' bus parked by  harbor',\n",
              " '2008_005208': ' large bird is flying through the air',\n",
              " '2008_000857': ' bedroom decorated in beige and brown colors with  large bed sofa and rug',\n",
              " '2008_006434': ' brown on in the field on  sunny day',\n",
              " '2008_006750': ' group of friends gathered in  restaurant eating',\n",
              " '2008_005616': ' black  white photo of an older woman and  middle age woman sitting in chairs underneath  tree and talking',\n",
              " '2008_000636': ' brown haired woman with  crying baby on her knee sitting on  couch',\n",
              " '2008_005680': ' comical preying mantis sits with other plants on the table',\n",
              " '2008_004701': ' black bull is confined by metal fencing',\n",
              " '2008_002454': ' small plane parked at an airfield with  cloudy sky overhead',\n",
              " '2008_005139': ' heavy traffic scene with many cars and motorcycles',\n",
              " '2008_001641': ' desk with  computer in  room',\n",
              " '2008_006163': ' sailboat at sea',\n",
              " '2008_007814': ' closeup of  lamb with its ear tagged standing on grass',\n",
              " '2008_008641': ' man in  striped shirt standing in front of  train in  large station',\n",
              " '2008_000457': 'back of stickercovered street signs',\n",
              " '2008_003858': ' cruise ship called the carnival triumph is moving through the water',\n",
              " '2008_000237': ' red car sits atop  semi on the set of  stunt show',\n",
              " '2008_008391': ' motorcycle rider rides splashes mud',\n",
              " '2008_001841': ' baby secured in  chair',\n",
              " '2008_001073': ' man is posing in front of his computer',\n",
              " '2008_004551': ' bird holding on to  metal gate',\n",
              " '2008_007147': ' man and woman posing on  field with  bottle of wine',\n",
              " '2008_007461': ' dog laying down',\n",
              " '2008_007048': ' dining room is in  house with brown carpet  table and  fan',\n",
              " '2008_007923': ' balding man in glasses and  yellow shirt behind two empty beverage bottles',\n",
              " '2008_000465': ' living room with  birdcage in the left corner and two lit lamps',\n",
              " '2008_006220': ' black and white image of  dog out of  truck',\n",
              " '2008_007990': 'three dark haired young women in white red and black sweaters',\n",
              " '2008_001799': ' view from shore of docks boats and  body of water with trees all around',\n",
              " '2008_003665': ' black dog',\n",
              " '2008_006511': ' brown dog laying on  carpeted floor next to  table',\n",
              " '2008_005412': ' man is pushing his bike up  snowy incline',\n",
              " '2008_001070': ' small gray dog on  leash',\n",
              " '2008_005714': ' black and white cow in  grassy field stares at the camera',\n",
              " '2008_002508': ' livingdining room with  large dining table on the right hand side',\n",
              " '2008_004307': ' holds closed the trunk of an orange car',\n",
              " '2008_003442': 'two women in  clothing store',\n",
              " '2008_006436': ' furry black dog and  small white dog lying down next to  brown leather couch',\n",
              " '2008_006059': ' sheep is being sheared by two young ladies',\n",
              " '2008_008237': ' courtyard with  small pagoda in the center',\n",
              " '2008_006438': ' black car with no hood',\n",
              " '2008_003271': ' baby is being played with',\n",
              " '2008_007525': ' group of four people walking past  giant mushroom',\n",
              " '2008_003378': ' bus stop in front of  red brick building',\n",
              " '2008_004487': ' cluttered desk has  red and white tablecloth',\n",
              " '2008_007097': 'two people are sitting in  small antique shop',\n",
              " '2008_002283': 'an indian family of four stands on the shoreline',\n",
              " '2008_007941': ' black and white cat is sitting on  brown chair looking up',\n",
              " '2008_007009': ' brown and white calf laying down on the hay in  barn',\n",
              " '2008_008185': ' man and  boy take  serene walk on the beach',\n",
              " '2008_000876': ' closeup of  cream animal with big ears and  black nose',\n",
              " '2008_003504': ' cubicle with  large black office chair and  telephone on the desk',\n",
              " '2008_000418': ' middleaged women in cap pants and sandals stands in her home',\n",
              " '2008_001926': ' blue and yellow locomotive alongside  station platform',\n",
              " '2008_004613': ' double decker red united bus on  city street',\n",
              " '2008_003133': 'black adult dog with black puppy lying down on the carpet',\n",
              " '2008_003094': ' man in  straw hat with three calves in front and  cliff face behind him',\n",
              " '2008_008052': ' black horse with  red bridle is running with its mane flowing behind it',\n",
              " '2008_005347': ' closet door stands open next to  marbletop counter',\n",
              " '2008_007025': ' black cow and  brown bull eat hay and graze on  remote farm',\n",
              " '2008_002328': ' group of men sitting in  classroom',\n",
              " '2008_000953': 'the curious boys look in the shed',\n",
              " '2008_004812': ' cruise liner docked at  port',\n",
              " '2008_008439': ' hotel room with  scenic view contains  modern wooden desk  flatscreen tv and simple yet welldesigned furniture',\n",
              " '2008_006345': ' red moped is parked by  building with graffiti',\n",
              " '2008_000541': 'four asian young people sitting in  den or living room',\n",
              " '2008_000491': ' close up of  small cactus in  pot',\n",
              " '2008_007596': ' black and white photo of  cow under  tree',\n",
              " '2008_002158': ' trail car on the tracks at  station',\n",
              " '2008_007430': ' closeup of  large white sheep',\n",
              " '2008_002067': ' couple posing in  picture with  cat in hand',\n",
              " '2008_006827': 'cows are crossing  rural highway and blocking the way of  cars and  truck',\n",
              " '2008_004002': 'an asian woman sitting in  chair on her balcony',\n",
              " '2008_005874': ' potted plant with only  few sprouting',\n",
              " '2008_007737': ' female in  pink tank top and jeans clutches  bottle of beer in each hand',\n",
              " '2008_002079': ' family poses for  picture while out at  restaurant',\n",
              " '2008_007070': 'adult and young lambs stand on grass',\n",
              " '2008_002412': ' black and white bus is parked with the door open',\n",
              " '2008_006936': ' two story building on  street with  white car parked in front',\n",
              " '2008_008525': ' black motorbike parked in front of  city wall painting',\n",
              " '2008_003061': ' man in  cowboy hat check approaches  small red sports car',\n",
              " '2008_000495': 'an office cube has  desktop computer  cluttered desk and  blue office chair',\n",
              " '2008_005857': ' cat looks away while laying down in an office chair',\n",
              " '2008_007421': ' cyclist is riding through the woods',\n",
              " '2008_006621': 'an air canada airplane flying in the sky',\n",
              " '2008_005720': ' cruise ship in harbor with rain clouds overhead',\n",
              " '2008_004948': ' group of people sit around  table with food and beer',\n",
              " '2008_000182': ' car sits by  window with  curtain pulled most of the way across',\n",
              " '2008_007277': ' person on horseback rides in sand near  canyon',\n",
              " '2008_001074': ' woman in  tshirt chops mushrooms',\n",
              " '2008_008024': 'herbs grow in terra cotta plants on  balcony',\n",
              " '2008_008121': ' cow stands at  milking machine',\n",
              " '2008_008152': ' blue train in  mountainous area',\n",
              " '2008_000885': ' family sitting down for dinner',\n",
              " '2008_007993': ' girl on  chopper bicycle',\n",
              " '2008_004087': ' bunch of parakeets in  cage',\n",
              " '2008_003534': ' group of four people in  dinner having cake',\n",
              " '2008_003140': 'two bicyclists and  pedestrian are waiting to cross the road',\n",
              " '2008_002972': ' black jacket is lying on the ground in front of  yellow motorcycle',\n",
              " '2008_008545': ' coal train traveling down the tracks',\n",
              " '2008_008719': ' yellow school bus in front of  house',\n",
              " '2008_004216': ' closeup of  head table set with gray napkins in stemmed water glasses',\n",
              " '2008_001910': ' man adding ingredients to  large streaming bowl',\n",
              " '2008_003881': 'two smiling women holding  baby',\n",
              " '2008_005747': ' closeup view of the headlights of  blue oldfashioned car',\n",
              " '2008_001467': ' child eating  cookie at  lemonade stand',\n",
              " '2008_003222': ' large stock standing next to  pond',\n",
              " '2008_005959': ' red boat in the middle of  lake with trees in the distance',\n",
              " '2008_004841': ' child on  pink stool milking  black and white cow',\n",
              " '2008_002481': ' computer monitor is turned on in  room with  chest of drawers and  terrier lamp',\n",
              " '2008_008471': 'an airplane is flying over  tree in the blue sky',\n",
              " '2008_007922': ' chandelier over  dining room table',\n",
              " '2008_008330': 'art items on  table',\n",
              " '2008_001966': ' bird perched on  flowerpot',\n",
              " '2008_001359': ' girl with glasses and  brown cow',\n",
              " '2008_007935': ' child holding large bags stands next to  tall bicycle beside the road',\n",
              " '2008_005240': ' small dog running',\n",
              " '2008_004362': ' yellow and black bird eats from  bird feeder',\n",
              " '2008_005196': ' bus at night in town',\n",
              " '2008_004659': ' black and white photo of  glass bottle of coca cola',\n",
              " '2008_006933': ' gray jet on  tarmac',\n",
              " '2008_004416': ' blue red and white couch against  wall with accent tables',\n",
              " '2008_007729': ' father is introducing his daughter to  cow on  remote beach',\n",
              " '2008_006602': ' dog is lying at the bottom of  staircase next to another standing dog',\n",
              " '2008_004559': ' firehouse with firetruck out front',\n",
              " '2008_007169': 'two women and  black dog are near  sofa and chair',\n",
              " '2008_006037': 'an esso gas station with trees in the background',\n",
              " '2008_006619': 'an air canada airplane is ascending against  blue sky',\n",
              " '2008_006337': ' back porch in the rain',\n",
              " '2008_002859': ' brown dog curled up in its bed',\n",
              " '2008_003160': ' family of hens walking down  dirt road',\n",
              " '2008_004592': ' bicycle in  dining room',\n",
              " '2008_002441': ' man holds  ball in  puppies mouth',\n",
              " '2008_001626': ' bike painted pink sitting on  sidewalk outside  building',\n",
              " '2008_008318': ' closeup of  brown horses head',\n",
              " '2008_004783': ' lifeguard tower and  yellow lifeguard truck on  beach',\n",
              " '2008_008751': ' grey and red train coming out of  tunnel',\n",
              " '2008_008501': ' large passenger plane on  landing strip',\n",
              " '2008_006496': 'two black ox with goods on their back',\n",
              " '2008_001885': ' cat is looking out the window',\n",
              " '2008_004321': ' group of people gets ready to enjoy  meal around the table',\n",
              " '2008_002709': ' black and white cow grazing near water',\n",
              " '2008_006635': ' local bus makes  stop on  quiet afternoon',\n",
              " '2008_001349': ' lady and two children look at papers',\n",
              " '2008_008262': ' black and white photo of three horses their handlers and three onlookers',\n",
              " '2008_007166': ' modern open plan living room and kitchen',\n",
              " '2008_007031': ' brown and white cow in  snow covered field',\n",
              " '2008_004426': ' girl wears  dark sweater and  statement necklace',\n",
              " '2008_005505': ' large sheep standing on  hill',\n",
              " '2008_005683': 'boats anchor off  short distance from the shore',\n",
              " '2008_004914': ' modern train in the snow',\n",
              " '2008_001781': ' cramped and cluttered living room contains  plaid couch many houseplants and assorted knickknacks',\n",
              " '2008_000090': ' child standing on  dusty street looks at adults with large metal containers',\n",
              " '2008_002395': ' black and brown dog lays on the top step of  wooden deck',\n",
              " '2008_005939': ' man dressed in  pale scarf with  stick',\n",
              " '2008_004090': ' baby holds  ketchup packet',\n",
              " '2008_005984': ' closeup of  yellow school bus',\n",
              " '2008_002343': ' ewe standing guard over her two newborn lambs',\n",
              " '2008_004910': ' living room with tv books vacuum and accessories',\n",
              " '2008_008012': ' bay foal is walking next to its mother in  grassy field',\n",
              " '2008_005614': ' cat rests on  crumpled brown tarp',\n",
              " '2008_003418': ' female child with dark brown hair is smiling at the camera',\n",
              " '2008_000905': 'an ox stands in  field',\n",
              " '2008_001444': ' man dressed for  race relaxes',\n",
              " '2008_006100': ' black and white photo of two rams in  pen',\n",
              " '2008_005498': ' jockey riding  horse in  pen',\n",
              " '2008_008482': ' black cow in  field with some snow in it',\n",
              " '2008_007398': 'cows look out of place as they walk down  street',\n",
              " '2008_008524': ' group of people in  living room',\n",
              " '2008_001274': ' black ferrari parked in front of trees',\n",
              " '2008_004985': 'an empty hallway leading into  room with brown furniture',\n",
              " '2008_001691': ' parked yellow motorbike',\n",
              " '2008_002758': ' large pile of scrap wood',\n",
              " '2008_001820': 'two buses with their doors open parked side by side',\n",
              " '2008_007323': ' large wooded expanse with  city in the background',\n",
              " '2008_002459': ' woman equestrian riding  horse',\n",
              " '2008_001249': ' person in  red cap standing next to  brick support beam',\n",
              " '2008_007519': ' brown dog lying on the grass',\n",
              " '2008_008623': ' sheep eats grass',\n",
              " '2008_006282': ' row of beer bottles on the floor',\n",
              " '2008_006331': ' man and woman are posing for the camera',\n",
              " '2008_003796': ' group of people having  drink',\n",
              " '2008_007692': 'an indian woman sits at  wooden table in front of  framed basketball poster',\n",
              " '2008_005960': ' black car is parked on gravel near  fence',\n",
              " '2008_005890': ' black cat on  pillow and  grey dog on  sofa',\n",
              " '2008_006991': ' jockey rides  brown and white horse in  dirt corral',\n",
              " '2008_002482': ' man in  canoe on  sunny day',\n",
              " '2008_004506': ' home office with three computer monitors and other equipment on  desk',\n",
              " '2008_001737': ' smiling woman with  beer sitting outside with another smiling woman',\n",
              " '2008_007537': ' man walking  dog on the beach near large waves',\n",
              " '2008_007119': ' car is painted with bright colors and designs',\n",
              " '2008_007344': ' blue moped parked near  graffiti covered while alongside  dog laying down',\n",
              " '2008_000808': ' dog is wearing  gray jacket',\n",
              " '2008_004498': 'the caged dogs are spread from the others',\n",
              " '2008_008376': ' brown duck and white duck stand on the grass',\n",
              " '2008_003609': 'girls and one guy playingtwister',\n",
              " '2008_003144': ' group of people stand by  body of water looking at  building',\n",
              " '2008_001676': ' close up picture of  saint bernard',\n",
              " '2008_006925': 'an ocean liner at sea',\n",
              " '2008_000711': 'the large cows hover over the young calf',\n",
              " '2008_004165': ' black and white photo of the right side of  small propeller driven airplane',\n",
              " '2008_002900': ' black and white photo of an empty train station',\n",
              " '2008_008440': ' group of people standing and sitting around  large circular table in  restaurant',\n",
              " '2008_003772': 'two baby kittens are sitting inside  cowschemed furcovered dome',\n",
              " '2008_007496': ' black and white image of  cat laying on  rug',\n",
              " '2008_004080': ' white minivan parked in  garage with city skyline in the background',\n",
              " '2008_007504': ' blue and orange airplane flying with its landing gear down',\n",
              " '2008_008642': ' black and white photo of  love seat',\n",
              " '2008_005642': ' white horse is looking at the camera from inside its pen',\n",
              " '2008_006691': ' car parked in front of  small saloon',\n",
              " '2008_006708': ' man on  dirt bike jumping very high',\n",
              " '2008_000620': ' pet hopes for  new owner',\n",
              " '2008_007021': 'the two dogs blend in with the stuff animals',\n",
              " '2008_003369': ' passenger aircraft with landing gear down',\n",
              " '2008_006730': 'guys in  boat fishing one of them holding  large fish',\n",
              " '2008_005664': ' boat with two people on blue water in front of  fort',\n",
              " '2008_007816': ' heads of  horse eating clover',\n",
              " '2008_002399': ' black and white bird on  body of water with grass in the background',\n",
              " '2008_007986': ' man with  bottle and  man in  hawaiian shirt are posing for  picture',\n",
              " '2008_005046': ' small boy laying on  sofa with  dog',\n",
              " '2008_001461': ' woman and her dog watch the cameraman in their living with wooden floors',\n",
              " '2008_005252': ' small cat laying on  wooden beam looking up at the camera',\n",
              " '2008_006404': ' male and female in  moving sail boat on  lake',\n",
              " '2008_001338': 'elderly man in an orange vest looking at  golf cart with another elderly man',\n",
              " '2008_008075': 'horse outfitted with riding gear',\n",
              " '2008_008679': ' bus goes down  street with parked cars',\n",
              " '2008_000144': ' man on  motorcycle performing  wheelie',\n",
              " '2008_006548': ' blue and yellow plan flies against  blue sky',\n",
              " '2008_003489': ' double decker bus is driving by big ben in london',\n",
              " '2008_004670': 'an empty college common space with empty chairs  couch and  ping pong table',\n",
              " '2008_008424': 'airplane on runway in front of buildings',\n",
              " '2008_000405': ' group of river barges with trees in the background',\n",
              " '2008_000328': ' man riding  dirt bike over  ridge',\n",
              " '2008_003072': ' bicycle is parked on  trail among trees',\n",
              " '2008_004539': ' team of dappled white carriage horses',\n",
              " '2008_007985': ' group of lambs in the grass',\n",
              " '2008_002536': ' black dog and two sheep running through the grass',\n",
              " '2008_003892': ' man is riding  red motorcycle on the road',\n",
              " '2008_008154': ' motocross rider about to get back on his stunt bike',\n",
              " '2008_008275': ' black and white image of an old fashioned train in  station',\n",
              " '2008_008321': 'an amtrack train coming towards the camera on  set of tracks with tracks next to it',\n",
              " '2008_005168': ' man standing near  street with  horse drawn carriage behind him',\n",
              " '2008_004497': ' black leather couch with  chew lounge and  coffee table with light candles in glasses',\n",
              " '2008_002576': ' girl in  plaid coat takes  photo of herself in  mirror by  staircase holding  red bag',\n",
              " '2008_006700': 'an airplane facing the camera',\n",
              " '2008_008601': ' black faced sheep',\n",
              " '2008_002129': ' little girl with  bike helmet posing by her bicycle',\n",
              " '2008_000919': ' cows ass and some buildings',\n",
              " '2008_004122': ' bulldog is sitting on  yellow chair which is next to  plant and  dumpster',\n",
              " '2008_001858': ' boat moving in  river',\n",
              " '2008_006004': ' closeup of an open refrigerator with food in it',\n",
              " '2008_006159': ' comfortable entertainment center in an apartment',\n",
              " '2008_004348': ' camouflaged plane sitting on the green grass',\n",
              " '2008_001829': ' bird is flapping its wings in the water',\n",
              " '2008_006403': ' brown cat wearing  shiny collar with  blue pendant sits on the floor',\n",
              " '2008_004868': ' bald man smiling with  black whitehaired horse',\n",
              " '2008_008343': ' brown double decker tour bus on  street with  ferris wheel behind it',\n",
              " '2008_008320': ' main holds two bikes near  beach',\n",
              " '2008_006857': ' helmet wearing motorcycle stuntman performs for  crowd',\n",
              " '2008_007332': ' closeup of  computer sitting on  desk with  modem keyboard and large speakers',\n",
              " '2008_000084': ' lone sheep walking through the woods',\n",
              " '2008_008608': ' living room with  beige sofa and love seat television and coffee table',\n",
              " '2008_006158': ' passenger train coming into  station',\n",
              " '2008_004805': ' goldfinch is eating thistle seed from  bird feeder hanging in  tree',\n",
              " '2008_004881': ' man and small child in  living room posing for the camera',\n",
              " '2008_001801': 'an airplane sitting on the tarmac at an airport with another plane in the background',\n",
              " '2008_001285': ' black dog standing in  grassy area',\n",
              " '2008_008470': ' living room decorated with contemporary furnishings',\n",
              " '2008_005798': ' brindle dog lying on  cushion next to  plant',\n",
              " '2008_005449': ' black and white cat laying on the ground in the sun',\n",
              " '2008_003342': ' closeup of two women posing with their thumbs up',\n",
              " '2008_007677': ' brown sheep and black lamb stand sidebyside behind  fence',\n",
              " '2008_002471': ' bird carrying  branch over the water',\n",
              " '2008_008319': 'children looking  sheep',\n",
              " '2008_007588': ' brown and white pony facing the camera',\n",
              " '2008_007201': ' red train',\n",
              " '2008_001402': ' bicyclist sticking his tongue out at the camera',\n",
              " '2008_004293': ' pug dog and pup play with  bone on the floor',\n",
              " '2008_000095': ' large bird wades in the water while the turtles climb the log',\n",
              " '2008_003275': ' boat is in the water and  small airplane is on the dock',\n",
              " '2008_007133': ' view of  street filled with vehicles people and  large brick building',\n",
              " '2008_008020': ' moving train in  suburban area',\n",
              " '2008_005538': 'an old airplane with yellow wings and  blue tail flying on  beautiful day',\n",
              " '2008_003146': 'two girls in pink and blue outfits',\n",
              " '2008_003701': ' docked fishing boat on  clear day',\n",
              " '2008_003703': 'an ocean airlines airplane is on  runway',\n",
              " '2008_004564': ' girl has  meal and sips  drink by the water',\n",
              " '2008_004634': ' wild garden with two potted flowers',\n",
              " '2008_005736': 'animals stand near plants and  wire fence',\n",
              " '2008_007101': 'couple sailing in  small sailboat',\n",
              " '2008_005676': ' school bus driving down  road with green trees and grass in the background',\n",
              " '2008_001031': ' girl in  red shirt is riding  brown horse',\n",
              " '2008_007319': ' white horse and  white and brown horse stand together at  red fence',\n",
              " '2008_004851': ' man holding  baby and  woman eating at  table',\n",
              " '2008_004833': ' small black and tan dog is wearing  pink jacket while laying on the pavement',\n",
              " '2008_000116': ' black and grey striped cay lying on  comforter looking toward the camera',\n",
              " '2008_005213': 'four bikers are riding on  dirt hill',\n",
              " '2008_006024': ' couple of gals chat over  bottle of wine'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 173
        }
      ]
    },
    {
      "metadata": {
        "id": "oUwZa88YQEaE",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b3f272d2-0303-4fea-bdbb-9a740132b44a",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530270967279,
          "user_tz": -120,
          "elapsed": 665,
          "user": {
            "displayName": "Guillermo Pedernal",
            "photoUrl": "//lh4.googleusercontent.com/-c67Vnm1lekk/AAAAAAAAAAI/AAAAAAAAAD4/_p61UmeZ47E/s50-c-k-no/photo.jpg",
            "userId": "101927487601652154517"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "descriptions['2008_003607']"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' blonde dog and  black and gray dog sitting on opposite ends of  beige sofa with  gray cat sleeping between them'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "metadata": {
        "id": "kGNMqupK26y_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Con esto quedan preparadas las descripciones en un diccionario, una sola por imagen y sin palabras de un solo caracter.\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "wezelKrrQw9q",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c6756c5c-6fff-4626-8921-9b101aeaef35",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530440389617,
          "user_tz": -120,
          "elapsed": 8402,
          "user": {
            "displayName": "Guillermo Pedernal",
            "photoUrl": "//lh4.googleusercontent.com/-c67Vnm1lekk/AAAAAAAAAAI/AAAAAAAAAD4/_p61UmeZ47E/s50-c-k-no/photo.jpg",
            "userId": "101927487601652154517"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from os import listdir\n",
        "from pickle import load, dump\n",
        "from tqdm import tqdm\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from pandas import DataFrame\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Flatten, LSTM, RepeatVector, TimeDistributed, Embedding\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.layers.pooling import GlobalMaxPooling2D"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "2Vm_ieSg6Ws-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Utilizamos una VGG16 sin la capa de clasificacion (solo queremos las caracteristicas). Este modelo es el mas utilizado para la extraccion de caracteristicas en este tipo de problemas."
      ]
    },
    {
      "metadata": {
        "id": "oNKbNAjDQj9G",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "8387af4e-53de-43e0-a16c-f43815bca4ce",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530271154366,
          "user_tz": -120,
          "elapsed": 37913,
          "user": {
            "displayName": "Guillermo Pedernal",
            "photoUrl": "//lh4.googleusercontent.com/-c67Vnm1lekk/AAAAAAAAAAI/AAAAAAAAAD4/_p61UmeZ47E/s50-c-k-no/photo.jpg",
            "userId": "101927487601652154517"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# extract features from each photo in the directory\n",
        "def extract_features(directory):\n",
        "  # load the model\n",
        "  in_layer = Input(shape=(224, 224, 3))\n",
        "  model = VGG16(include_top=False, input_tensor=in_layer)\n",
        "  print(model.summary())\n",
        "  # extract features from each photo\n",
        "  features = dict()\n",
        "\n",
        "  files_in_directory = listdir(directory)\n",
        "  n_images = len(files_in_directory)\n",
        "  for i, name in tqdm(enumerate(files_in_directory)):\n",
        "    # load an image from file\n",
        "    filename = directory + '/' + name\n",
        "    image = load_img(filename, target_size=(224, 224))\n",
        "    # convert the image pixels to a numpy array\n",
        "    image = img_to_array(image)\n",
        "    # reshape data for the model\n",
        "    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "    # prepare the image for the VGG model\n",
        "    image = preprocess_input(image)\n",
        "    # get features\n",
        "    feature = model.predict(image, verbose=0)\n",
        "    # get image id\n",
        "    image_id = name.split('.')[0]\n",
        "    # store feature\n",
        "    features[image_id] = feature\n",
        "    # print('{} / {} > {}'.format(i, n_images, name))\n",
        "  return features\n",
        "\n",
        "# extract features from all images\n",
        "directory = 'PascalSentenceDataSetOutput'\n",
        "features = extract_features(directory)\n",
        "print('Extracted Features: %d' % len(features))\n",
        "# save to file\n",
        "dump(features, open('features.pkl', 'wb'))"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000it [00:34, 29.39it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracted Features: 1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "D--q_QfL60fp",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 1462
        },
        "outputId": "9dec276a-c873-4922-a357-4a79d829d01f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530282103261,
          "user_tz": -120,
          "elapsed": 479,
          "user": {
            "displayName": "Guillermo Pedernal",
            "photoUrl": "//lh4.googleusercontent.com/-c67Vnm1lekk/AAAAAAAAAAI/AAAAAAAAAD4/_p61UmeZ47E/s50-c-k-no/photo.jpg",
            "userId": "101927487601652154517"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "features['2008_004416']"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "           0.        ,  0.        ],\n",
              "         [ 1.5902635 ,  0.        ,  0.        , ...,  0.        ,\n",
              "           0.        ,  0.        ],\n",
              "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "           1.7550225 ,  0.        ],\n",
              "         ...,\n",
              "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "           0.        ,  0.        ],\n",
              "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "           0.        ,  0.        ],\n",
              "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "           0.        ,  0.        ]],\n",
              "\n",
              "        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "           0.        ,  0.        ],\n",
              "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "           0.        ,  0.        ],\n",
              "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "           3.4605947 ,  0.        ],\n",
              "         ...,\n",
              "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "           0.        ,  0.        ],\n",
              "         [ 4.469969  ,  0.        ,  0.        , ...,  0.        ,\n",
              "           0.        ,  0.        ],\n",
              "         [ 5.0076323 ,  0.        ,  0.        , ...,  0.        ,\n",
              "           0.        ,  0.        ]],\n",
              "\n",
              "        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "           0.        ,  0.        ],\n",
              "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "           0.        ,  0.        ],\n",
              "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "           0.        ,  4.7937875 ],\n",
              "         ...,\n",
              "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "           0.        ,  0.        ],\n",
              "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "           0.        ,  0.        ],\n",
              "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "           0.        ,  0.        ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "           0.8243939 ,  0.        ],\n",
              "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "           0.        ,  0.        ],\n",
              "         [ 0.        ,  0.        ,  0.        , ..., 16.299294  ,\n",
              "           0.        ,  0.        ],\n",
              "         ...,\n",
              "         [38.727985  ,  0.        ,  0.        , ...,  0.        ,\n",
              "           0.        ,  0.        ],\n",
              "         [32.98472   ,  0.        ,  0.        , ...,  0.        ,\n",
              "           0.        ,  0.        ],\n",
              "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "           0.        ,  0.        ]],\n",
              "\n",
              "        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "           0.        ,  0.        ],\n",
              "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "           0.        ,  0.        ],\n",
              "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "          23.416044  ,  0.        ],\n",
              "         ...,\n",
              "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "          20.073278  ,  0.        ],\n",
              "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "           0.        ,  0.        ],\n",
              "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "           0.        ,  0.        ]],\n",
              "\n",
              "        [[ 0.        ,  3.6475737 ,  0.        , ...,  0.        ,\n",
              "           0.        ,  0.        ],\n",
              "         [ 0.        ,  0.        ,  0.        , ..., 25.106642  ,\n",
              "           0.        ,  0.        ],\n",
              "         [ 0.        ,  0.        ,  0.        , ...,  4.39852   ,\n",
              "           5.74495   ,  0.        ],\n",
              "         ...,\n",
              "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "           0.        ,  0.        ],\n",
              "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "           0.22856867,  0.        ],\n",
              "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "          13.792054  ,  0.        ]]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 176
        }
      ]
    },
    {
      "metadata": {
        "id": "X-2eB2YKLAJn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ya tenemos un archivo features.pkl con las caracteristicas de las imagenes. "
      ]
    },
    {
      "metadata": {
        "id": "c2sjcif5waDj",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "1216b323-b652-41e4-86f7-7cc09265a02c",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530271803282,
          "user_tz": -120,
          "elapsed": 811,
          "user": {
            "displayName": "Guillermo Pedernal",
            "photoUrl": "//lh4.googleusercontent.com/-c67Vnm1lekk/AAAAAAAAAAI/AAAAAAAAAD4/_p61UmeZ47E/s50-c-k-no/photo.jpg",
            "userId": "101927487601652154517"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from pickle import load\n",
        "\n",
        "# load doc into memory\n",
        "def load_doc(filename):\n",
        "\t# open the file as read only\n",
        "\tfile = open(filename, 'r')\n",
        "\t# read all text\n",
        "\ttext = file.read()\n",
        "\t# close the file\n",
        "\tfile.close()\n",
        "\treturn text\n",
        "\n",
        "# load a pre-defined list of photo identifiers\n",
        "def load_set(filename):\n",
        "\tdoc = load_doc(filename)\n",
        "\tdataset = list()\n",
        "\t# process line by line\n",
        "\tfor line in doc.split('\\n'):\n",
        "\t\t# skip empty lines\n",
        "\t\tif len(line) < 1:\n",
        "\t\t\tcontinue\n",
        "\t\t# get the image identifier\n",
        "\t\tidentifier = line.split('.')[0]\n",
        "\t\tdataset.append(identifier)\n",
        "\treturn set(dataset)\n",
        "\n",
        "# split a dataset into train/test elements\n",
        "def train_test_split(dataset):\n",
        "\t# order keys so the split is consistent\n",
        "\tordered = sorted(dataset)\n",
        "\t# return split dataset as two new sets\n",
        "\treturn set(ordered[:400]), set(ordered[400:500])\n",
        "\n",
        "# load clean descriptions into memory\n",
        "def load_clean_descriptions(filename, dataset):\n",
        "\t# load document\n",
        "\tdoc = load_doc(filename)\n",
        "\tdescriptions = dict()\n",
        "\tfor line in doc.split('\\n'):\n",
        "\t\t# split line by white space\n",
        "\t\ttokens = line.split(' ')\n",
        "\t\t# split id from description\n",
        "\t\timage_id, image_desc = tokens[0], tokens[1:]\n",
        "\t\t# skip images not in the set\n",
        "\t\tif image_id in dataset:\n",
        "\t\t\t# store\n",
        "\t\t\tdescriptions[image_id] = 'startseq ' + ' '.join(image_desc) + ' endseq'\n",
        "\treturn descriptions\n",
        "\n",
        "# load photo features\n",
        "def load_photo_features(filename, dataset):\n",
        "\t# load all features\n",
        "\tall_features = load(open(filename, 'rb'))\n",
        "\t# filter features\n",
        "\tfeatures = {k: all_features[k] for k in dataset}\n",
        "\treturn features\n",
        "\n",
        "# load dev set\n",
        "filename = 'titles.txt'\n",
        "dataset = load_set(filename)\n",
        "print('Dataset: %d' % len(dataset))\n",
        "# train-test split\n",
        "train, test = train_test_split(dataset)\n",
        "print('Train=%d, Test=%d' % (len(train), len(test)))\n",
        "# descriptions\n",
        "train_descriptions = load_clean_descriptions('descriptions.txt', train)\n",
        "test_descriptions = load_clean_descriptions('descriptions.txt', test)\n",
        "print('Descriptions: train=%d, test=%d' % (len(train_descriptions), len(test_descriptions)))\n",
        "# photo features\n",
        "train_features = load_photo_features('features.pkl', train)\n",
        "test_features = load_photo_features('features.pkl', test)\n",
        "print('Photos: train=%d, test=%d' % (len(train_features), len(test_features)))"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset: 1000\n",
            "Train=400, Test=100\n",
            "Descriptions: train=400, test=100\n",
            "Photos: train=400, test=100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-NTwisBRS_qX",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "11888805-ffaf-42ea-d73d-ad80364551eb",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530271848454,
          "user_tz": -120,
          "elapsed": 634,
          "user": {
            "displayName": "Guillermo Pedernal",
            "photoUrl": "//lh4.googleusercontent.com/-c67Vnm1lekk/AAAAAAAAAAI/AAAAAAAAAD4/_p61UmeZ47E/s50-c-k-no/photo.jpg",
            "userId": "101927487601652154517"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Ahora codificamos nuestras descripciones a números\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# fit a tokenizer given caption descriptions\n",
        "def create_tokenizer(descriptions):\n",
        "\tlines = list(descriptions.values())\n",
        "\ttokenizer = Tokenizer()\n",
        "\ttokenizer.fit_on_texts(lines)\n",
        "\treturn tokenizer\n",
        " \n",
        "# prepare tokenizer\n",
        "tokenizer = create_tokenizer(descriptions)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print('Vocabulary Size: %d' % vocab_size)"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary Size: 1530\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Zw1t0pK3T1Un",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Y creamos las secuencias:\n",
        "\n",
        "# create sequences of images, input sequences and output words for an image\n",
        "def create_sequences(tokenizer, desc, image, max_length):\n",
        "\tXimages, XSeq, y = list(), list(),list()\n",
        "\tvocab_size = len(tokenizer.word_index) + 1\n",
        "\t# integer encode the description\n",
        "\tseq = tokenizer.texts_to_sequences([desc])[0]\n",
        "\t# split one sequence into multiple X,y pairs\n",
        "\tfor i in range(1, len(seq)):\n",
        "\t\t# select\n",
        "\t\tin_seq, out_seq = seq[:i], seq[i]\n",
        "\t\t# pad input sequence\n",
        "\t\tin_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
        "\t\t# encode output sequence\n",
        "\t\tout_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
        "\t\t# store\n",
        "\t\tXimages.append(image)\n",
        "\t\tXSeq.append(in_seq)\n",
        "\t\ty.append(out_seq)\n",
        "\t# Ximages, XSeq, y = array(Ximages), array(XSeq), array(y)\n",
        "\treturn [Ximages, XSeq, y]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1c12VQPmT6Od",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# define the captioning model\n",
        "def define_model(vocab_size, max_length):\n",
        "\t# feature extractor (encoder)\n",
        "\tinputs1 = Input(shape=(7, 7, 512))\n",
        "\tfe1 = GlobalMaxPooling2D()(inputs1)\n",
        "\tfe2 = Dense(128, activation='relu')(fe1)\n",
        "\tfe3 = RepeatVector(max_length)(fe2)\n",
        "\t# embedding\n",
        "\tinputs2 = Input(shape=(max_length,))\n",
        "\temb2 = Embedding(vocab_size, 50, mask_zero=True)(inputs2)\n",
        "\temb3 = LSTM(256, return_sequences=True)(emb2)\n",
        "\temb4 = TimeDistributed(Dense(128, activation='relu'))(emb3)\n",
        "\t# merge inputs\n",
        "\tmerged = concatenate([fe3, emb4])\n",
        "\t# language model (decoder)\n",
        "\tlm2 = LSTM(500)(merged)\n",
        "\tlm3 = Dense(500, activation='relu')(lm2)\n",
        "\toutputs = Dense(vocab_size, activation='softmax')(lm3)\n",
        "\t# tie it together [image, seq] [word]\n",
        "\tmodel = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\tprint(model.summary())\n",
        "\treturn model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UxpY5gCKT-AA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# data generator, intended to be used in a call to model.fit_generator()\n",
        "def data_generator(descriptions, features, tokenizer, max_length, n_step):\n",
        "\t# loop until we finish training\n",
        "\twhile 1:\n",
        "\t\t# loop over photo identifiers in the dataset\n",
        "\t\tkeys = list(descriptions.keys())\n",
        "\t\tfor i in range(0, len(keys), n_step):\n",
        "\t\t\tXimages, XSeq, y = list(), list(),list()\n",
        "\t\t\tfor j in range(i, min(len(keys), i+n_step)):\n",
        "\t\t\t\timage_id = keys[j]\n",
        "\t\t\t\t# retrieve photo feature input\n",
        "\t\t\t\timage = features[image_id][0]\n",
        "\t\t\t\t# retrieve text input\n",
        "\t\t\t\tdesc = descriptions[image_id]\n",
        "\t\t\t\t# generate input-output pairs\n",
        "\t\t\t\tin_img, in_seq, out_word = create_sequences(tokenizer, desc, image, max_length)\n",
        "\t\t\t\tfor k in range(len(in_img)):\n",
        "\t\t\t\t\tXimages.append(in_img[k])\n",
        "\t\t\t\t\tXSeq.append(in_seq[k])\n",
        "\t\t\t\t\ty.append(out_word[k])\n",
        "\t\t\t# yield this batch of samples to the model\n",
        "\t\t\tyield [[array(Ximages), array(XSeq)], array(y)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g1vix_5sUAjY",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# map an integer to a word\n",
        "def word_for_id(integer, tokenizer):\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == integer:\n",
        "\t\t\treturn word\n",
        "\treturn None\n",
        " \n",
        "# generate a description for an image\n",
        "def generate_desc(model, tokenizer, photo, max_length):\n",
        "\t# seed the generation process\n",
        "\tin_text = 'startseq'\n",
        "\t# iterate over the whole length of the sequence\n",
        "\tfor i in range(max_length):\n",
        "\t\t# integer encode input sequence\n",
        "\t\tsequence = tokenizer.texts_to_sequences([in_text])[0]\n",
        "\t\t# pad input\n",
        "\t\tsequence = pad_sequences([sequence], maxlen=max_length)\n",
        "\t\t# predict next word\n",
        "\t\tyhat = model.predict([photo,sequence], verbose=0)\n",
        "\t\t# convert probability to integer\n",
        "\t\tyhat = argmax(yhat)\n",
        "\t\t# map integer to word\n",
        "\t\tword = word_for_id(yhat, tokenizer)\n",
        "\t\t# stop if we cannot map the word\n",
        "\t\tif word is None:\n",
        "\t\t\tbreak\n",
        "\t\t# append as input for generating the next word\n",
        "\t\tin_text += ' ' + word\n",
        "\t\t# stop if we predict the end of the sequence\n",
        "\t\tif word == 'endseq':\n",
        "\t\t\tbreak\n",
        "\treturn in_text\n",
        " \n",
        "# evaluate the skill of the model\n",
        "def evaluate_model(model, descriptions, photos, tokenizer, max_length):\n",
        "\tactual, predicted = list(), list()\n",
        "\t# step over the whole set\n",
        "\tfor key, desc in descriptions.items():\n",
        "\t\t# generate description\n",
        "\t\tyhat = generate_desc(model, tokenizer, photos[key], max_length)\n",
        "\t\t# store actual and predicted\n",
        "\t\tactual.append([desc.split()])\n",
        "\t\tpredicted.append(yhat.split())\n",
        "\t# calculate BLEU score\n",
        "\tbleu = corpus_bleu(actual, predicted)\n",
        "\treturn bleu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S8pkuHQ2UFVF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# load dev set\n",
        "filename = 'titles.txt'\n",
        "dataset = load_set(filename)\n",
        "print('Dataset: %d' % len(dataset))\n",
        "# train-test split\n",
        "train, test = train_test_split(dataset)\n",
        "# descriptions\n",
        "train_descriptions = load_clean_descriptions('descriptions.txt', train)\n",
        "test_descriptions = load_clean_descriptions('descriptions.txt', test)\n",
        "print('Descriptions: train=%d, test=%d' % (len(train_descriptions), len(test_descriptions)))\n",
        "# photo features\n",
        "train_features = load_photo_features('features.pkl', train)\n",
        "test_features = load_photo_features('features.pkl', test)\n",
        "print('Photos: train=%d, test=%d' % (len(train_features), len(test_features)))\n",
        "# prepare tokenizer\n",
        "tokenizer = create_tokenizer(train_descriptions)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print('Vocabulary Size: %d' % vocab_size)\n",
        "# determine the maximum sequence length\n",
        "max_length = max(len(s.split()) for s in list(train_descriptions.values()))\n",
        "print('Description Length: %d' % max_length)\n",
        " \n",
        "# define experiment\n",
        "model_name = 'baseline1'\n",
        "verbose = 1\n",
        "n_epochs = 50\n",
        "n_photos_per_update = 2\n",
        "n_batches_per_epoch = int(len(train) / n_photos_per_update)\n",
        "n_repeats = 3\n",
        " \n",
        "# run experiment\n",
        "train_results, test_results = list(), list()\n",
        "for i in range(n_repeats):\n",
        "\t# define the model\n",
        "\tmodel = define_model(vocab_size, max_length)\n",
        "\t# fit model\n",
        "\tmodel.fit_generator(data_generator(train_descriptions, train_features, tokenizer, max_length, n_photos_per_update), steps_per_epoch=n_batches_per_epoch, epochs=n_epochs, verbose=verbose)\n",
        "\t# evaluate model on training data\n",
        "\ttrain_score = evaluate_model(model, train_descriptions, train_features, tokenizer, max_length)\n",
        "\ttest_score = evaluate_model(model, test_descriptions, test_features, tokenizer, max_length)\n",
        "\t# store\n",
        "\ttrain_results.append(train_score)\n",
        "\ttest_results.append(test_score)\n",
        "\tprint('>%d: train=%f test=%f' % ((i+1), train_score, test_score))\n",
        "# save results to file\n",
        "df = DataFrame()\n",
        "df['train'] = train_results\n",
        "df['test'] = test_results\n",
        "print(df.describe())\n",
        "df.to_csv(model_name+'.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BAYazpeTnhkl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Se obtienen los siguierntes resultados (se ha borrado el resultado de la celda, que descuadraba el notebook):\n",
        "\n",
        "         train      test\n",
        "         \n",
        "count  3.000000  3.000000\n",
        "\n",
        "mean   0.014560  0.023810\n",
        "\n",
        "std    0.019196  0.013661\n",
        "\n",
        "min    0.003477  0.015923\n",
        "\n",
        "25%    0.003477  0.015923\n",
        "\n",
        "50%    0.003477  0.015923\n",
        "\n",
        "75%    0.020101  0.027754\n",
        "\n",
        "max    0.036726  0.039585"
      ]
    },
    {
      "metadata": {
        "id": "4OTnYY06n0lF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "El resultado es de 0,015 de puntuacion en train y 0,024 en test,  resultados mas bajos que los obtenidos en el ejemplo de clase."
      ]
    },
    {
      "metadata": {
        "id": "FmxgGXKqoHXO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Vamos a ver un ejemplo de las predicciones igual que en clase:"
      ]
    },
    {
      "metadata": {
        "id": "vmkVlOfgoGsP",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 8092
        },
        "outputId": "66460f63-7f99-4c77-e3f0-e245164c272c",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530281526020,
          "user_tz": -120,
          "elapsed": 4337059,
          "user": {
            "displayName": "Guillermo Pedernal",
            "photoUrl": "//lh4.googleusercontent.com/-c67Vnm1lekk/AAAAAAAAAAI/AAAAAAAAAD4/_p61UmeZ47E/s50-c-k-no/photo.jpg",
            "userId": "101927487601652154517"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# evaluate the skill of the model\n",
        "def evaluate_model(model, descriptions, photos, tokenizer, max_length):\n",
        "\tactual, predicted = list(), list()\n",
        "\t# step over the whole set\n",
        "\tfor key, desc in descriptions.items():\n",
        "\t\t# generate description\n",
        "\t\tyhat = generate_desc(model, tokenizer, photos[key], max_length)\n",
        "\t\t# store actual and predicted\n",
        "\t\tactual.append([desc.split()])\n",
        "\t\tpredicted.append(yhat.split())\n",
        "\t\tprint('Actual:    %s' % desc)\n",
        "\t\tprint('Predicted: %s' % yhat)\n",
        "\t\tif len(actual) >= 5:\n",
        "\t\t\tbreak\n",
        "\t# calculate BLEU score\n",
        "\tbleu = corpus_bleu(actual, predicted)\n",
        "\treturn bleu\n",
        "\n",
        "# define experiment\n",
        "model_name = 'baseline1'\n",
        "verbose = 2\n",
        "n_epochs = 50\n",
        "n_photos_per_update = 2\n",
        "n_batches_per_epoch = int(len(train) / n_photos_per_update)\n",
        "n_repeats = 3\n",
        " \n",
        "# run experiment\n",
        "train_results, test_results = list(), list()\n",
        "for i in range(n_repeats):\n",
        "\t# define the model\n",
        "\tmodel = define_model(vocab_size, max_length)\n",
        "\t# fit model\n",
        "\tmodel.fit_generator(data_generator(train_descriptions, train_features, tokenizer, max_length, n_photos_per_update), steps_per_epoch=n_batches_per_epoch, epochs=n_epochs, verbose=verbose)\n",
        "\t# evaluate model on training data\n",
        "\ttrain_score = evaluate_model(model, train_descriptions, train_features, tokenizer, max_length)\n",
        "\ttest_score = evaluate_model(model, test_descriptions, test_features, tokenizer, max_length)\n",
        "\t# store\n",
        "\ttrain_results.append(train_score)\n",
        "\ttest_results.append(test_score)\n",
        "\tprint('>%d: train=%f test=%f' % ((i+1), train_score, test_score))\n",
        "# save results to file\n",
        "df = DataFrame()\n",
        "df['train'] = train_results\n",
        "df['test'] = test_results\n",
        "print(df.describe())\n",
        "df.to_csv(model_name+'.csv', index=False)"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_8 (InputLayer)            (None, 7, 7, 512)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_9 (InputLayer)            (None, 22)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling2d_4 (GlobalM (None, 512)          0           input_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_4 (Embedding)         (None, 22, 50)       46400       input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_13 (Dense)                (None, 128)          65664       global_max_pooling2d_4[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_7 (LSTM)                   (None, 22, 256)      314368      embedding_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "repeat_vector_4 (RepeatVector)  (None, 22, 128)      0           dense_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_4 (TimeDistrib (None, 22, 128)      32896       lstm_7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 22, 256)      0           repeat_vector_4[0][0]            \n",
            "                                                                 time_distributed_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "lstm_8 (LSTM)                   (None, 500)          1514000     concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_15 (Dense)                (None, 500)          250500      lstm_8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_16 (Dense)                (None, 928)          464928      dense_15[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 2,688,756\n",
            "Trainable params: 2,688,756\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            " - 31s - loss: 5.8151 - acc: 0.1104\n",
            "Epoch 2/50\n",
            " - 29s - loss: 5.4955 - acc: 0.1138\n",
            "Epoch 3/50\n",
            " - 29s - loss: 5.5805 - acc: 0.1138\n",
            "Epoch 4/50\n",
            " - 29s - loss: 5.6212 - acc: 0.1138\n",
            "Epoch 5/50\n",
            " - 29s - loss: 5.5964 - acc: 0.1138\n",
            "Epoch 6/50\n",
            " - 29s - loss: 5.5160 - acc: 0.1138\n",
            "Epoch 7/50\n",
            " - 29s - loss: 5.5085 - acc: 0.1138\n",
            "Epoch 8/50\n",
            " - 29s - loss: 5.4953 - acc: 0.1138\n",
            "Epoch 9/50\n",
            " - 29s - loss: 5.4894 - acc: 0.1138\n",
            "Epoch 10/50\n",
            " - 29s - loss: 5.4861 - acc: 0.1138\n",
            "Epoch 11/50\n",
            " - 29s - loss: 5.4776 - acc: 0.1138\n",
            "Epoch 12/50\n",
            " - 29s - loss: 5.4803 - acc: 0.1138\n",
            "Epoch 13/50\n",
            " - 29s - loss: 5.4827 - acc: 0.1138\n",
            "Epoch 14/50\n",
            " - 29s - loss: 5.4755 - acc: 0.1138\n",
            "Epoch 15/50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " - 29s - loss: 5.4808 - acc: 0.1138\n",
            "Epoch 16/50\n",
            " - 28s - loss: 5.4791 - acc: 0.1138\n",
            "Epoch 17/50\n",
            " - 29s - loss: 5.4791 - acc: 0.1138\n",
            "Epoch 18/50\n",
            " - 29s - loss: 5.4847 - acc: 0.1138\n",
            "Epoch 19/50\n",
            " - 29s - loss: 5.4769 - acc: 0.1138\n",
            "Epoch 20/50\n",
            " - 29s - loss: 5.4760 - acc: 0.1138\n",
            "Epoch 21/50\n",
            " - 28s - loss: 5.4752 - acc: 0.1138\n",
            "Epoch 22/50\n",
            " - 29s - loss: 5.4765 - acc: 0.1138\n",
            "Epoch 23/50\n",
            " - 29s - loss: 5.4754 - acc: 0.1138\n",
            "Epoch 24/50\n",
            " - 29s - loss: 5.4745 - acc: 0.1138\n",
            "Epoch 25/50\n",
            " - 29s - loss: 5.4765 - acc: 0.1138\n",
            "Epoch 26/50\n",
            " - 29s - loss: 5.4703 - acc: 0.1138\n",
            "Epoch 27/50\n",
            " - 29s - loss: 5.4760 - acc: 0.1138\n",
            "Epoch 28/50\n",
            " - 28s - loss: 5.4744 - acc: 0.1138\n",
            "Epoch 29/50\n",
            " - 29s - loss: 5.4569 - acc: 0.1138\n",
            "Epoch 30/50\n",
            " - 29s - loss: 5.4741 - acc: 0.1138\n",
            "Epoch 31/50\n",
            " - 28s - loss: 5.4736 - acc: 0.1138\n",
            "Epoch 32/50\n",
            " - 29s - loss: 5.4731 - acc: 0.1138\n",
            "Epoch 33/50\n",
            " - 28s - loss: 5.4732 - acc: 0.1138\n",
            "Epoch 34/50\n",
            " - 29s - loss: 5.4722 - acc: 0.1138\n",
            "Epoch 35/50\n",
            " - 29s - loss: 5.4718 - acc: 0.1138\n",
            "Epoch 36/50\n",
            " - 28s - loss: 5.4714 - acc: 0.1138\n",
            "Epoch 37/50\n",
            " - 29s - loss: 5.4710 - acc: 0.1138\n",
            "Epoch 38/50\n",
            " - 29s - loss: 5.4707 - acc: 0.1138\n",
            "Epoch 39/50\n",
            " - 29s - loss: 5.4703 - acc: 0.1138\n",
            "Epoch 40/50\n",
            " - 29s - loss: 5.4700 - acc: 0.1138\n",
            "Epoch 41/50\n",
            " - 29s - loss: 5.4697 - acc: 0.1138\n",
            "Epoch 42/50\n",
            " - 28s - loss: 5.4694 - acc: 0.1138\n",
            "Epoch 43/50\n",
            " - 28s - loss: 5.4690 - acc: 0.1138\n",
            "Epoch 44/50\n",
            " - 29s - loss: 5.4687 - acc: 0.1138\n",
            "Epoch 45/50\n",
            " - 28s - loss: 5.4684 - acc: 0.1138\n",
            "Epoch 46/50\n",
            " - 28s - loss: 5.4681 - acc: 0.1138\n",
            "Epoch 47/50\n",
            " - 29s - loss: 5.4678 - acc: 0.1138\n",
            "Epoch 48/50\n",
            " - 29s - loss: 5.4675 - acc: 0.1138\n",
            "Epoch 49/50\n",
            " - 29s - loss: 5.4671 - acc: 0.1138\n",
            "Epoch 50/50\n",
            " - 29s - loss: 5.4668 - acc: 0.1138\n",
            "Actual:    startseq  blonde dog and  black and gray dog sitting on opposite ends of  beige sofa with  gray cat sleeping between them endseq\n",
            "Predicted: startseq endseq\n",
            "Actual:    startseq  brown dachshund beside the door endseq\n",
            "Predicted: startseq endseq\n",
            "Actual:    startseq  kitchen dinette set sits on  backyard deck endseq\n",
            "Predicted: startseq endseq\n",
            "Actual:    startseq  brown race horse jockey in green and handler endseq\n",
            "Predicted: startseq endseq\n",
            "Actual:    startseq  group of girls are posing with two endseq\n",
            "Predicted: startseq endseq\n",
            "Actual:    startseq  bicycle is parked by  shop endseq\n",
            "Predicted: startseq endseq\n",
            "Actual:    startseq  bicycle on display with  shade attached endseq\n",
            "Predicted: startseq endseq\n",
            "Actual:    startseq  bus at  bus stop endseq\n",
            "Predicted: startseq endseq\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Actual:    startseq  couple enjoying  sunny day on the top deck of  cruise ship endseq\n",
            "Predicted: startseq endseq\n",
            "Actual:    startseq the lamb is looking at the camera endseq\n",
            "Predicted: startseq endseq\n",
            ">1: train=0.009095 test=0.036883\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_10 (InputLayer)           (None, 7, 7, 512)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_11 (InputLayer)           (None, 22)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling2d_5 (GlobalM (None, 512)          0           input_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "embedding_5 (Embedding)         (None, 22, 50)       46400       input_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_17 (Dense)                (None, 128)          65664       global_max_pooling2d_5[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_9 (LSTM)                   (None, 22, 256)      314368      embedding_5[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "repeat_vector_5 (RepeatVector)  (None, 22, 128)      0           dense_17[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_5 (TimeDistrib (None, 22, 128)      32896       lstm_9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 22, 256)      0           repeat_vector_5[0][0]            \n",
            "                                                                 time_distributed_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "lstm_10 (LSTM)                  (None, 500)          1514000     concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_19 (Dense)                (None, 500)          250500      lstm_10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_20 (Dense)                (None, 928)          464928      dense_19[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 2,688,756\n",
            "Trainable params: 2,688,756\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            " - 31s - loss: 5.8039 - acc: 0.1081\n",
            "Epoch 2/50\n",
            " - 29s - loss: 5.5302 - acc: 0.1138\n",
            "Epoch 3/50\n",
            " - 29s - loss: 5.6406 - acc: 0.1138\n",
            "Epoch 4/50\n",
            " - 29s - loss: 5.5036 - acc: 0.1138\n",
            "Epoch 5/50\n",
            " - 29s - loss: 5.5173 - acc: 0.1138\n",
            "Epoch 6/50\n",
            " - 29s - loss: 5.5109 - acc: 0.1138\n",
            "Epoch 7/50\n",
            " - 29s - loss: 5.4992 - acc: 0.1138\n",
            "Epoch 8/50\n",
            " - 29s - loss: 5.4935 - acc: 0.1138\n",
            "Epoch 9/50\n",
            " - 29s - loss: 5.4900 - acc: 0.1138\n",
            "Epoch 10/50\n",
            " - 29s - loss: 5.4877 - acc: 0.1138\n",
            "Epoch 11/50\n",
            " - 29s - loss: 5.4860 - acc: 0.1138\n",
            "Epoch 12/50\n",
            " - 29s - loss: 5.4848 - acc: 0.1138\n",
            "Epoch 13/50\n",
            " - 29s - loss: 5.4471 - acc: 0.1138\n",
            "Epoch 14/50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " - 29s - loss: 5.4730 - acc: 0.1138\n",
            "Epoch 15/50\n",
            " - 29s - loss: 5.4895 - acc: 0.1138\n",
            "Epoch 16/50\n",
            " - 29s - loss: 5.4846 - acc: 0.1138\n",
            "Epoch 17/50\n",
            " - 29s - loss: 5.4734 - acc: 0.1138\n",
            "Epoch 18/50\n",
            " - 29s - loss: 5.4850 - acc: 0.1138\n",
            "Epoch 19/50\n",
            " - 29s - loss: 5.4818 - acc: 0.1138\n",
            "Epoch 20/50\n",
            " - 29s - loss: 5.4807 - acc: 0.1138\n",
            "Epoch 21/50\n",
            " - 29s - loss: 5.4799 - acc: 0.1138\n",
            "Epoch 22/50\n",
            " - 29s - loss: 5.4790 - acc: 0.1138\n",
            "Epoch 23/50\n",
            " - 29s - loss: 5.4784 - acc: 0.1138\n",
            "Epoch 24/50\n",
            " - 29s - loss: 5.4778 - acc: 0.1138\n",
            "Epoch 25/50\n",
            " - 28s - loss: 5.4773 - acc: 0.1138\n",
            "Epoch 26/50\n",
            " - 28s - loss: 5.4768 - acc: 0.1138\n",
            "Epoch 27/50\n",
            " - 29s - loss: 5.4764 - acc: 0.1138\n",
            "Epoch 28/50\n",
            " - 29s - loss: 5.4759 - acc: 0.1138\n",
            "Epoch 29/50\n",
            " - 29s - loss: 5.4755 - acc: 0.1138\n",
            "Epoch 30/50\n",
            " - 29s - loss: 5.4751 - acc: 0.1138\n",
            "Epoch 31/50\n",
            " - 29s - loss: 5.4747 - acc: 0.1138\n",
            "Epoch 32/50\n",
            " - 29s - loss: 5.4743 - acc: 0.1138\n",
            "Epoch 33/50\n",
            " - 29s - loss: 5.4739 - acc: 0.1138\n",
            "Epoch 34/50\n",
            " - 29s - loss: 5.4736 - acc: 0.1138\n",
            "Epoch 35/50\n",
            " - 29s - loss: 5.4732 - acc: 0.1138\n",
            "Epoch 36/50\n",
            " - 29s - loss: 5.4728 - acc: 0.1138\n",
            "Epoch 37/50\n",
            " - 29s - loss: 5.4724 - acc: 0.1138\n",
            "Epoch 38/50\n",
            " - 29s - loss: 5.4721 - acc: 0.1138\n",
            "Epoch 39/50\n",
            " - 29s - loss: 5.4717 - acc: 0.1138\n",
            "Epoch 40/50\n",
            " - 29s - loss: 5.4713 - acc: 0.1138\n",
            "Epoch 41/50\n",
            " - 29s - loss: 5.4709 - acc: 0.1138\n",
            "Epoch 42/50\n",
            " - 29s - loss: 5.4705 - acc: 0.1138\n",
            "Epoch 43/50\n",
            " - 29s - loss: 5.4701 - acc: 0.1138\n",
            "Epoch 44/50\n",
            " - 29s - loss: 5.4697 - acc: 0.1138\n",
            "Epoch 45/50\n",
            " - 29s - loss: 5.4693 - acc: 0.1138\n",
            "Epoch 46/50\n",
            " - 29s - loss: 5.4689 - acc: 0.1138\n",
            "Epoch 47/50\n",
            " - 29s - loss: 5.4684 - acc: 0.1138\n",
            "Epoch 48/50\n",
            " - 29s - loss: 5.4680 - acc: 0.1138\n",
            "Epoch 49/50\n",
            " - 29s - loss: 5.4675 - acc: 0.1138\n",
            "Epoch 50/50\n",
            " - 29s - loss: 5.4670 - acc: 0.1138\n",
            "Actual:    startseq  blonde dog and  black and gray dog sitting on opposite ends of  beige sofa with  gray cat sleeping between them endseq\n",
            "Predicted: startseq endseq\n",
            "Actual:    startseq  brown dachshund beside the door endseq\n",
            "Predicted: startseq endseq\n",
            "Actual:    startseq  kitchen dinette set sits on  backyard deck endseq\n",
            "Predicted: startseq endseq\n",
            "Actual:    startseq  brown race horse jockey in green and handler endseq\n",
            "Predicted: startseq endseq\n",
            "Actual:    startseq  group of girls are posing with two endseq\n",
            "Predicted: startseq endseq\n",
            "Actual:    startseq  bicycle is parked by  shop endseq\n",
            "Predicted: startseq endseq\n",
            "Actual:    startseq  bicycle on display with  shade attached endseq\n",
            "Predicted: startseq endseq\n",
            "Actual:    startseq  bus at  bus stop endseq\n",
            "Predicted: startseq endseq\n",
            "Actual:    startseq  couple enjoying  sunny day on the top deck of  cruise ship endseq\n",
            "Predicted: startseq endseq\n",
            "Actual:    startseq the lamb is looking at the camera endseq\n",
            "Predicted: startseq endseq\n",
            ">2: train=0.009095 test=0.036883\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_12 (InputLayer)           (None, 7, 7, 512)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_13 (InputLayer)           (None, 22)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling2d_6 (GlobalM (None, 512)          0           input_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "embedding_6 (Embedding)         (None, 22, 50)       46400       input_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_21 (Dense)                (None, 128)          65664       global_max_pooling2d_6[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_11 (LSTM)                  (None, 22, 256)      314368      embedding_6[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "repeat_vector_6 (RepeatVector)  (None, 22, 128)      0           dense_21[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_6 (TimeDistrib (None, 22, 128)      32896       lstm_11[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 22, 256)      0           repeat_vector_6[0][0]            \n",
            "                                                                 time_distributed_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "lstm_12 (LSTM)                  (None, 500)          1514000     concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_23 (Dense)                (None, 500)          250500      lstm_12[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_24 (Dense)                (None, 928)          464928      dense_23[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 2,688,756\n",
            "Trainable params: 2,688,756\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            " - 32s - loss: 5.7944 - acc: 0.1109\n",
            "Epoch 2/50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " - 29s - loss: 5.5239 - acc: 0.1138\n",
            "Epoch 3/50\n",
            " - 29s - loss: 5.5977 - acc: 0.1138\n",
            "Epoch 4/50\n",
            " - 29s - loss: 5.5199 - acc: 0.1138\n",
            "Epoch 5/50\n",
            " - 29s - loss: 5.5134 - acc: 0.1138\n",
            "Epoch 6/50\n",
            " - 29s - loss: 5.5123 - acc: 0.1138\n",
            "Epoch 7/50\n",
            " - 29s - loss: 5.4857 - acc: 0.1138\n",
            "Epoch 8/50\n",
            " - 29s - loss: 5.5021 - acc: 0.1138\n",
            "Epoch 9/50\n",
            " - 29s - loss: 5.4981 - acc: 0.1138\n",
            "Epoch 10/50\n",
            " - 29s - loss: 5.4942 - acc: 0.1138\n",
            "Epoch 11/50\n",
            " - 29s - loss: 5.4917 - acc: 0.1138\n",
            "Epoch 12/50\n",
            " - 29s - loss: 5.4896 - acc: 0.1138\n",
            "Epoch 13/50\n",
            " - 29s - loss: 5.4880 - acc: 0.1138\n",
            "Epoch 14/50\n",
            " - 29s - loss: 5.4866 - acc: 0.1138\n",
            "Epoch 15/50\n",
            " - 29s - loss: 5.4854 - acc: 0.1138\n",
            "Epoch 16/50\n",
            " - 29s - loss: 5.4842 - acc: 0.1138\n",
            "Epoch 17/50\n",
            " - 29s - loss: 5.4832 - acc: 0.1138\n",
            "Epoch 18/50\n",
            " - 29s - loss: 5.4823 - acc: 0.1138\n",
            "Epoch 19/50\n",
            " - 29s - loss: 5.4813 - acc: 0.1138\n",
            "Epoch 20/50\n",
            " - 29s - loss: 5.4804 - acc: 0.1138\n",
            "Epoch 21/50\n",
            " - 29s - loss: 5.4795 - acc: 0.1138\n",
            "Epoch 22/50\n",
            " - 29s - loss: 5.4786 - acc: 0.1138\n",
            "Epoch 23/50\n",
            " - 29s - loss: 5.4776 - acc: 0.1138\n",
            "Epoch 24/50\n",
            " - 29s - loss: 5.4766 - acc: 0.1138\n",
            "Epoch 25/50\n",
            " - 29s - loss: 5.4755 - acc: 0.1138\n",
            "Epoch 26/50\n",
            " - 29s - loss: 5.4743 - acc: 0.1138\n",
            "Epoch 27/50\n",
            " - 29s - loss: 5.4730 - acc: 0.1138\n",
            "Epoch 28/50\n",
            " - 29s - loss: 5.4717 - acc: 0.1138\n",
            "Epoch 29/50\n",
            " - 29s - loss: 5.4702 - acc: 0.1138\n",
            "Epoch 30/50\n",
            " - 29s - loss: 5.4685 - acc: 0.1138\n",
            "Epoch 31/50\n",
            " - 29s - loss: 5.4665 - acc: 0.1138\n",
            "Epoch 32/50\n",
            " - 29s - loss: 5.4642 - acc: 0.1138\n",
            "Epoch 33/50\n",
            " - 29s - loss: 5.4614 - acc: 0.1138\n",
            "Epoch 34/50\n",
            " - 29s - loss: 5.4537 - acc: 0.1138\n",
            "Epoch 35/50\n",
            " - 29s - loss: 5.4150 - acc: 0.1111\n",
            "Epoch 36/50\n",
            " - 29s - loss: 5.4418 - acc: 0.1138\n",
            "Epoch 37/50\n",
            " - 29s - loss: 5.4705 - acc: 0.1138\n",
            "Epoch 38/50\n",
            " - 29s - loss: 5.4639 - acc: 0.1138\n",
            "Epoch 39/50\n",
            " - 29s - loss: 5.4583 - acc: 0.1138\n",
            "Epoch 40/50\n",
            " - 29s - loss: 5.4530 - acc: 0.1138\n",
            "Epoch 41/50\n",
            " - 29s - loss: 5.4474 - acc: 0.1138\n",
            "Epoch 42/50\n",
            " - 29s - loss: 5.4414 - acc: 0.1138\n",
            "Epoch 43/50\n",
            " - 29s - loss: 5.4348 - acc: 0.1138\n",
            "Epoch 44/50\n",
            " - 29s - loss: 5.4273 - acc: 0.1157\n",
            "Epoch 45/50\n",
            " - 29s - loss: 5.4191 - acc: 0.1182\n",
            "Epoch 46/50\n",
            " - 29s - loss: 5.4109 - acc: 0.1202\n",
            "Epoch 47/50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " - 29s - loss: 5.4025 - acc: 0.1212\n",
            "Epoch 48/50\n",
            " - 29s - loss: 5.3938 - acc: 0.1228\n",
            "Epoch 49/50\n",
            " - 29s - loss: 5.3849 - acc: 0.1228\n",
            "Epoch 50/50\n",
            " - 29s - loss: 5.3765 - acc: 0.1228\n",
            "Actual:    startseq  blonde dog and  black and gray dog sitting on opposite ends of  beige sofa with  gray cat sleeping between them endseq\n",
            "Predicted: startseq black endseq\n",
            "Actual:    startseq  brown dachshund beside the door endseq\n",
            "Predicted: startseq black endseq\n",
            "Actual:    startseq  kitchen dinette set sits on  backyard deck endseq\n",
            "Predicted: startseq black endseq\n",
            "Actual:    startseq  brown race horse jockey in green and handler endseq\n",
            "Predicted: startseq black endseq\n",
            "Actual:    startseq  group of girls are posing with two endseq\n",
            "Predicted: startseq black endseq\n",
            "Actual:    startseq  bicycle is parked by  shop endseq\n",
            "Predicted: startseq black endseq\n",
            "Actual:    startseq  bicycle on display with  shade attached endseq\n",
            "Predicted: startseq black endseq\n",
            "Actual:    startseq  bus at  bus stop endseq\n",
            "Predicted: startseq black endseq\n",
            "Actual:    startseq  couple enjoying  sunny day on the top deck of  cruise ship endseq\n",
            "Predicted: startseq black endseq\n",
            "Actual:    startseq the lamb is looking at the camera endseq\n",
            "Predicted: startseq black endseq\n",
            ">3: train=0.056273 test=0.139731\n",
            "          train      test\n",
            "count  3.000000  3.000000\n",
            "mean   0.024821  0.071166\n",
            "std    0.027238  0.059379\n",
            "min    0.009095  0.036883\n",
            "25%    0.009095  0.036883\n",
            "50%    0.009095  0.036883\n",
            "75%    0.032684  0.088307\n",
            "max    0.056273  0.139731\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EGIJ46hr54qv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Al final hemos conseguido algo mejor que \"startseq -> endseq\" y ya predice la palabra \"black\" en todos los casos probados. Una pequeña mejoría pero sigue siendo un intento fallido."
      ]
    },
    {
      "metadata": {
        "id": "gqL_dR206Fp7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "3.Vamos por ultimo a replicar el ejemplo de clase con flickr8k. Una vez que este funcionando trataremos de conseguir un mejor resultado. Lo que intentaremos es:\n",
        "\n",
        "    -Ampliar la muestra de train, tal y como hemos hecho en el ejemplo anterior. \n",
        "    \n",
        "    -Al margen de esto no vamos a tocar la VGG para extraer las caracteristicas [Entiendo que inicializar los pesos con transfer learning o fine tuning no ayuda ya que en cualquier caso no estamos utilizando la capa clasificadora de la CNN]. \n",
        "    \n",
        "    -Centramos nuestros esfuerzos en el modelo que predice las descripciones de las fotografias. Este modelo consta de un encoder (capa densa), un procesador de secuencias (capa LSTM) y un interprete de lenguaje (capas LSTM y densa).\n",
        "    \n",
        "    -Actuaremos por lo tanto en los parametros del modelo. Para ello intentaremos optimizarlos implementando hyper-opt."
      ]
    },
    {
      "metadata": {
        "id": "_FVkxiX8nyEE",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "92996d6d-16e2-4fb9-bff9-ecc6adc221e3",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530440423115,
          "user_tz": -120,
          "elapsed": 3312,
          "user": {
            "displayName": "Guillermo Pedernal",
            "photoUrl": "//lh4.googleusercontent.com/-c67Vnm1lekk/AAAAAAAAAAI/AAAAAAAAAD4/_p61UmeZ47E/s50-c-k-no/photo.jpg",
            "userId": "101927487601652154517"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!wget http://nlp.cs.illinois.edu/HockenmaierGroup/Framing_Image_Description/Flickr8k_text.zip\n",
        "!unzip -o Flickr8k_text.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-07-01 10:20:20--  http://nlp.cs.illinois.edu/HockenmaierGroup/Framing_Image_Description/Flickr8k_text.zip\n",
            "Resolving nlp.cs.illinois.edu (nlp.cs.illinois.edu)... 192.17.58.132\n",
            "Connecting to nlp.cs.illinois.edu (nlp.cs.illinois.edu)|192.17.58.132|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2340801 (2.2M) [application/zip]\n",
            "Saving to: ‘Flickr8k_text.zip’\n",
            "\n",
            "Flickr8k_text.zip   100%[===================>]   2.23M  4.90MB/s    in 0.5s    \n",
            "\n",
            "2018-07-01 10:20:21 (4.90 MB/s) - ‘Flickr8k_text.zip’ saved [2340801/2340801]\n",
            "\n",
            "Archive:  Flickr8k_text.zip\n",
            "  inflating: CrowdFlowerAnnotations.txt  \n",
            "  inflating: ExpertAnnotations.txt   \n",
            "  inflating: Flickr8k.lemma.token.txt  \n",
            "   creating: __MACOSX/\n",
            "  inflating: __MACOSX/._Flickr8k.lemma.token.txt  \n",
            "  inflating: Flickr8k.token.txt      \n",
            "  inflating: Flickr_8k.devImages.txt  \n",
            "  inflating: Flickr_8k.testImages.txt  \n",
            "  inflating: Flickr_8k.trainImages.txt  \n",
            "  inflating: readme.txt              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Xxm2PIXXUKaA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def load_doc(filename):\n",
        "\t# open the file as read only\n",
        "\tfile = open(filename, 'r')\n",
        "\t# read all text\n",
        "\ttext = file.read()\n",
        "\t# close the file\n",
        "\tfile.close()\n",
        "\treturn text\n",
        " \n",
        "filename = 'Flickr8k.token.txt'\n",
        "# load descriptions\n",
        "doc = load_doc(filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x7sZ1lVW7n6N",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "65492333-e39a-4d4e-8807-a71f179fdfe0",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530440428539,
          "user_tz": -120,
          "elapsed": 568,
          "user": {
            "displayName": "Guillermo Pedernal",
            "photoUrl": "//lh4.googleusercontent.com/-c67Vnm1lekk/AAAAAAAAAAI/AAAAAAAAAD4/_p61UmeZ47E/s50-c-k-no/photo.jpg",
            "userId": "101927487601652154517"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "len(doc)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3395237"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "i9I9E3cL7pqT",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "26034da0-6f43-439b-d4e0-d81501d835a6",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530440429767,
          "user_tz": -120,
          "elapsed": 611,
          "user": {
            "displayName": "Guillermo Pedernal",
            "photoUrl": "//lh4.googleusercontent.com/-c67Vnm1lekk/AAAAAAAAAAI/AAAAAAAAAD4/_p61UmeZ47E/s50-c-k-no/photo.jpg",
            "userId": "101927487601652154517"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# extract descriptions for images\n",
        "def load_descriptions(doc):\n",
        "\tmapping = dict()\n",
        "\t# process lines\n",
        "\tfor line in doc.split('\\n'):\n",
        "\t\t# split line by white space\n",
        "\t\ttokens = line.split()\n",
        "\t\tif len(line) < 2:\n",
        "\t\t\tcontinue\n",
        "\t\t# take the first token as the image id, the rest as the description\n",
        "\t\timage_id, image_desc = tokens[0], tokens[1:]\n",
        "\t\t# remove filename from image id\n",
        "\t\timage_id = image_id.split('.')[0]\n",
        "\t\t# convert description tokens back to string\n",
        "\t\timage_desc = ' '.join(image_desc)\n",
        "\t\t# store the first description for each image\n",
        "\t\tif image_id not in mapping:\n",
        "\t\t\tmapping[image_id] = image_desc\n",
        "\treturn mapping\n",
        " \n",
        "# parse descriptions\n",
        "descriptions = load_descriptions(doc)\n",
        "print('Loaded: %d ' % len(descriptions))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded: 8092 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1lZ-2KW97wwU",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6b9d216f-e12f-45c4-e5f4-c9d144eadcc6",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530440431607,
          "user_tz": -120,
          "elapsed": 641,
          "user": {
            "displayName": "Guillermo Pedernal",
            "photoUrl": "//lh4.googleusercontent.com/-c67Vnm1lekk/AAAAAAAAAAI/AAAAAAAAAD4/_p61UmeZ47E/s50-c-k-no/photo.jpg",
            "userId": "101927487601652154517"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "def clean_descriptions(descriptions):\n",
        "\t# prepare translation table for removing punctuation\n",
        "\ttable = str.maketrans('', '', string.punctuation)\n",
        "\tfor key, desc in descriptions.items():\n",
        "\t\t# tokenize\n",
        "\t\tdesc = desc.split()\n",
        "\t\t# convert to lower case\n",
        "\t\tdesc = [word.lower() for word in desc]\n",
        "\t\t# remove punctuation from each token\n",
        "\t\tdesc = [w.translate(table) for w in desc]\n",
        "\t\t# remove hanging 's' and 'a'\n",
        "\t\tdesc = [word for word in desc if len(word)>1]\n",
        "\t\t# store as string\n",
        "\t\tdescriptions[key] =  ' '.join(desc)\n",
        "\n",
        "# clean descriptions\n",
        "clean_descriptions(descriptions)\n",
        "# summarize vocabulary\n",
        "all_tokens = ' '.join(descriptions.values()).split()\n",
        "vocabulary = set(all_tokens)\n",
        "print('Vocabulary Size: %d' % len(vocabulary))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary Size: 4484\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Cqb9NO7xUZzg",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!rm -rf descriptions.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v0fSvg0I77Vo",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# save descriptions to file, one per line\n",
        "def save_doc(descriptions, filename):\n",
        "\tlines = list()\n",
        "\tfor key, desc in descriptions.items():\n",
        "\t\tlines.append(key + ' ' + desc)\n",
        "\tdata = '\\n'.join(lines)\n",
        "\tfile = open(filename, 'w')\n",
        "\tfile.write(data)\n",
        "\tfile.close()\n",
        "\n",
        "# save descriptions\n",
        "save_doc(descriptions, 'descriptions.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_kESJg9F8Aif",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a9e8439b-a4fb-4e05-dc35-31a2cb298e16",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530440466009,
          "user_tz": -120,
          "elapsed": 26139,
          "user": {
            "displayName": "Guillermo Pedernal",
            "photoUrl": "//lh4.googleusercontent.com/-c67Vnm1lekk/AAAAAAAAAAI/AAAAAAAAAD4/_p61UmeZ47E/s50-c-k-no/photo.jpg",
            "userId": "101927487601652154517"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!wget http://nlp.cs.illinois.edu/HockenmaierGroup/Framing_Image_Description/Flickr8k_Dataset.zip\n",
        "!unzip -q Flickr8k_Dataset.zip"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-07-01 10:20:41--  http://nlp.cs.illinois.edu/HockenmaierGroup/Framing_Image_Description/Flickr8k_Dataset.zip\r\n",
            "Resolving nlp.cs.illinois.edu (nlp.cs.illinois.edu)... 192.17.58.132\r\n",
            "Connecting to nlp.cs.illinois.edu (nlp.cs.illinois.edu)|192.17.58.132|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115419746 (1.0G) [application/zip]\n",
            "Saving to: ‘Flickr8k_Dataset.zip’\n",
            "\n",
            "Flickr8k_Dataset.zi 100%[===================>]   1.04G  82.3MB/s    in 14s     \n",
            "\n",
            "2018-07-01 10:20:54 (78.3 MB/s) - ‘Flickr8k_Dataset.zip’ saved [1115419746/1115419746]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "u34SRtOe8Fyi",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "e8a060b8-e7f2-4d27-b45a-26ce580e6cd4",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530440470412,
          "user_tz": -120,
          "elapsed": 1539,
          "user": {
            "displayName": "Guillermo Pedernal",
            "photoUrl": "//lh4.googleusercontent.com/-c67Vnm1lekk/AAAAAAAAAAI/AAAAAAAAAD4/_p61UmeZ47E/s50-c-k-no/photo.jpg",
            "userId": "101927487601652154517"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls -la"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 1102512\r\n",
            "drwxr-xr-x 1 root root       4096 Jul  1 10:20 .\r\n",
            "drwxr-xr-x 1 root root       4096 Jul  1 10:14 ..\r\n",
            "drwx------ 4 root root       4096 Jul  1 10:17 .cache\r\n",
            "drwxr-xr-x 3 root root       4096 Jul  1 10:17 .config\r\n",
            "-rw-r--r-- 1 root root    2918552 Oct 14  2013 CrowdFlowerAnnotations.txt\r\n",
            "drwxr-xr-x 3 root root       4096 Jun 28 16:55 datalab\r\n",
            "-rw-r--r-- 1 root root     587144 Jul  1 10:20 descriptions.txt\r\n",
            "-rw-r--r-- 1 root root     346674 Oct 14  2013 ExpertAnnotations.txt\r\n",
            "drwxr-xr-x 2 root root     430080 Oct  3  2012 Flicker8k_Dataset\r\n",
            "-rw-r--r-- 1 root root 1115419746 Oct 24  2013 Flickr8k_Dataset.zip\r\n",
            "-rw-r--r-- 1 root root      25801 Oct 10  2013 Flickr_8k.devImages.txt\r\n",
            "-rw-r--r-- 1 root root    3244761 Feb 16  2012 Flickr8k.lemma.token.txt\r\n",
            "-rw-r--r-- 1 root root      25775 Oct 10  2013 Flickr_8k.testImages.txt\r\n",
            "-rw-r--r-- 1 root root    2340801 Oct 28  2013 Flickr8k_text.zip\r\n",
            "-rw-r--r-- 1 root root    3395237 Oct 14  2013 Flickr8k.token.txt\r\n",
            "-rw-r--r-- 1 root root     154678 Oct 10  2013 Flickr_8k.trainImages.txt\r\n",
            "drwxr-xr-x 4 root root       4096 Jul  1 10:15 .forever\r\n",
            "drwxr-xr-x 5 root root       4096 Jul  1 10:17 .ipython\r\n",
            "drwxr-xr-x 2 root root       4096 Jul  1 10:19 .keras\r\n",
            "drwx------ 3 root root       4096 Jul  1 10:15 .local\r\n",
            "drwxrwxr-x 3 root root       4096 Jul  1 10:21 __MACOSX\r\n",
            "-rw-r--r-- 1 root root       1821 Oct 14  2013 readme.txt\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uOXCi7h68rJI",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "36e269c6-80be-45fa-dbd6-acb3c46c6915",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530440803622,
          "user_tz": -120,
          "elapsed": 274779,
          "user": {
            "displayName": "Guillermo Pedernal",
            "photoUrl": "//lh4.googleusercontent.com/-c67Vnm1lekk/AAAAAAAAAAI/AAAAAAAAAD4/_p61UmeZ47E/s50-c-k-no/photo.jpg",
            "userId": "101927487601652154517"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# extract features from each photo in the directory\n",
        "def extract_features(directory):\n",
        "  # load the model\n",
        "  in_layer = Input(shape=(224, 224, 3))\n",
        "  model = VGG16(include_top=False, input_tensor=in_layer)\n",
        "  print(model.summary())\n",
        "  # extract features from each photo\n",
        "  features = dict()\n",
        "\n",
        "  files_in_directory = listdir(directory)\n",
        "  n_images = len(files_in_directory)\n",
        "  for i, name in tqdm(enumerate(files_in_directory)):\n",
        "    # load an image from file\n",
        "    filename = directory + '/' + name\n",
        "    image = load_img(filename, target_size=(224, 224))\n",
        "    # convert the image pixels to a numpy array\n",
        "    image = img_to_array(image)\n",
        "    # reshape data for the model\n",
        "    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "    # prepare the image for the VGG model\n",
        "    image = preprocess_input(image)\n",
        "    # get features\n",
        "    feature = model.predict(image, verbose=0)\n",
        "    # get image id\n",
        "    image_id = name.split('.')[0]\n",
        "    # store feature\n",
        "    features[image_id] = feature\n",
        "    # print('{} / {} > {}'.format(i, n_images, name))\n",
        "  return features\n",
        "\n",
        "# extract features from all images\n",
        "directory = 'Flicker8k_Dataset'\n",
        "features = extract_features(directory)\n",
        "print('Extracted Features: %d' % len(features))\n",
        "# save to file\n",
        "dump(features, open('features.pkl', 'wb'))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8091it [04:24, 30.56it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracted Features: 8091\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pgtgJ3ucJkN6",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "4185a010-2925-4c25-9f8b-69a5473439e0",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530440805378,
          "user_tz": -120,
          "elapsed": 1712,
          "user": {
            "displayName": "Guillermo Pedernal",
            "photoUrl": "//lh4.googleusercontent.com/-c67Vnm1lekk/AAAAAAAAAAI/AAAAAAAAAD4/_p61UmeZ47E/s50-c-k-no/photo.jpg",
            "userId": "101927487601652154517"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from pickle import load\n",
        "\n",
        "# load doc into memory\n",
        "def load_doc(filename):\n",
        "\t# open the file as read only\n",
        "\tfile = open(filename, 'r')\n",
        "\t# read all text\n",
        "\ttext = file.read()\n",
        "\t# close the file\n",
        "\tfile.close()\n",
        "\treturn text\n",
        "\n",
        "# load a pre-defined list of photo identifiers\n",
        "def load_set(filename):\n",
        "\tdoc = load_doc(filename)\n",
        "\tdataset = list()\n",
        "\t# process line by line\n",
        "\tfor line in doc.split('\\n'):\n",
        "\t\t# skip empty lines\n",
        "\t\tif len(line) < 1:\n",
        "\t\t\tcontinue\n",
        "\t\t# get the image identifier\n",
        "\t\tidentifier = line.split('.')[0]\n",
        "\t\tdataset.append(identifier)\n",
        "\treturn set(dataset)\n",
        "\n",
        "# split a dataset into train/test elements\n",
        "def train_test_split(dataset):\n",
        "\t# order keys so the split is consistent\n",
        "\tordered = sorted(dataset)\n",
        "\t# return split dataset as two new sets\n",
        "\treturn set(ordered[:400]), set(ordered[400:500])\n",
        "\n",
        "# load clean descriptions into memory\n",
        "def load_clean_descriptions(filename, dataset):\n",
        "\t# load document\n",
        "\tdoc = load_doc(filename)\n",
        "\tdescriptions = dict()\n",
        "\tfor line in doc.split('\\n'):\n",
        "\t\t# split line by white space\n",
        "\t\ttokens = line.split()\n",
        "\t\t# split id from description\n",
        "\t\timage_id, image_desc = tokens[0], tokens[1:]\n",
        "\t\t# skip images not in the set\n",
        "\t\tif image_id in dataset:\n",
        "\t\t\t# store\n",
        "\t\t\tdescriptions[image_id] = 'startseq ' + ' '.join(image_desc) + ' endseq'\n",
        "\treturn descriptions\n",
        "\n",
        "# load photo features\n",
        "def load_photo_features(filename, dataset):\n",
        "\t# load all features\n",
        "\tall_features = load(open(filename, 'rb'))\n",
        "\t# filter features\n",
        "\tfeatures = {k: all_features[k] for k in dataset}\n",
        "\treturn features\n",
        "\n",
        "# load dev set\n",
        "filename = 'Flickr_8k.devImages.txt'\n",
        "dataset = load_set(filename)\n",
        "print('Dataset: %d' % len(dataset))\n",
        "# train-test split\n",
        "train, test = train_test_split(dataset)\n",
        "print('Train=%d, Test=%d' % (len(train), len(test)))\n",
        "# descriptions\n",
        "train_descriptions = load_clean_descriptions('descriptions.txt', train)\n",
        "test_descriptions = load_clean_descriptions('descriptions.txt', test)\n",
        "print('Descriptions: train=%d, test=%d' % (len(train_descriptions), len(test_descriptions)))\n",
        "# photo features\n",
        "train_features = load_photo_features('features.pkl', train)\n",
        "test_features = load_photo_features('features.pkl', test)\n",
        "print('Photos: train=%d, test=%d' % (len(train_features), len(test_features)))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset: 1000\n",
            "Train=400, Test=100\n",
            "Descriptions: train=400, test=100\n",
            "Photos: train=400, test=100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Z7gwlXtm_SFX",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8bdd0252-6128-45b1-ebbd-2c996f61cefe",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530440808850,
          "user_tz": -120,
          "elapsed": 582,
          "user": {
            "displayName": "Guillermo Pedernal",
            "photoUrl": "//lh4.googleusercontent.com/-c67Vnm1lekk/AAAAAAAAAAI/AAAAAAAAAD4/_p61UmeZ47E/s50-c-k-no/photo.jpg",
            "userId": "101927487601652154517"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Ahora codificamos nuestras descripciones a números\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# fit a tokenizer given caption descriptions\n",
        "def create_tokenizer(descriptions):\n",
        "\tlines = list(descriptions.values())\n",
        "\ttokenizer = Tokenizer()\n",
        "\ttokenizer.fit_on_texts(lines)\n",
        "\treturn tokenizer\n",
        " \n",
        "# prepare tokenizer\n",
        "tokenizer = create_tokenizer(descriptions)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print('Vocabulary Size: %d' % vocab_size)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary Size: 4485\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aUW3A4U_CzTF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Y creamos las secuencias:\n",
        "\n",
        "# create sequences of images, input sequences and output words for an image\n",
        "def create_sequences(tokenizer, desc, image, max_length):\n",
        "\tXimages, XSeq, y = list(), list(),list()\n",
        "\tvocab_size = len(tokenizer.word_index) + 1\n",
        "\t# integer encode the description\n",
        "\tseq = tokenizer.texts_to_sequences([desc])[0]\n",
        "\t# split one sequence into multiple X,y pairs\n",
        "\tfor i in range(1, len(seq)):\n",
        "\t\t# select\n",
        "\t\tin_seq, out_seq = seq[:i], seq[i]\n",
        "\t\t# pad input sequence\n",
        "\t\tin_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
        "\t\t# encode output sequence\n",
        "\t\tout_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
        "\t\t# store\n",
        "\t\tXimages.append(image)\n",
        "\t\tXSeq.append(in_seq)\n",
        "\t\ty.append(out_seq)\n",
        "\t# Ximages, XSeq, y = array(Ximages), array(XSeq), array(y)\n",
        "\treturn [Ximages, XSeq, y]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZZATO9tyC8av",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# define the captioning model\n",
        "def define_model(vocab_size, max_length):\n",
        "\t# feature extractor (encoder)\n",
        "\tinputs1 = Input(shape=(7, 7, 512))\n",
        "\tfe1 = GlobalMaxPooling2D()(inputs1)\n",
        "\tfe2 = Dense(128, activation='relu')(fe1)\n",
        "\tfe3 = RepeatVector(max_length)(fe2)\n",
        "\t# embedding\n",
        "\tinputs2 = Input(shape=(max_length,))\n",
        "\temb2 = Embedding(vocab_size, 50, mask_zero=True)(inputs2)\n",
        "\temb3 = LSTM(256, return_sequences=True)(emb2)\n",
        "\temb4 = TimeDistributed(Dense(128, activation='relu'))(emb3)\n",
        "\t# merge inputs\n",
        "\tmerged = concatenate([fe3, emb4])\n",
        "\t# language model (decoder)\n",
        "\tlm2 = LSTM(500)(merged)\n",
        "\tlm3 = Dense(500, activation='relu')(lm2)\n",
        "\toutputs = Dense(vocab_size, activation='softmax')(lm3)\n",
        "\t# tie it together [image, seq] [word]\n",
        "\tmodel = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\tprint(model.summary())\n",
        "\treturn model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ENsqkfuZDKVg",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# data generator, intended to be used in a call to model.fit_generator()\n",
        "def data_generator(descriptions, features, tokenizer, max_length, n_step):\n",
        "\t# loop until we finish training\n",
        "\twhile 1:\n",
        "\t\t# loop over photo identifiers in the dataset\n",
        "\t\tkeys = list(descriptions.keys())\n",
        "\t\tfor i in range(0, len(keys), n_step):\n",
        "\t\t\tXimages, XSeq, y = list(), list(),list()\n",
        "\t\t\tfor j in range(i, min(len(keys), i+n_step)):\n",
        "\t\t\t\timage_id = keys[j]\n",
        "\t\t\t\t# retrieve photo feature input\n",
        "\t\t\t\timage = features[image_id][0]\n",
        "\t\t\t\t# retrieve text input\n",
        "\t\t\t\tdesc = descriptions[image_id]\n",
        "\t\t\t\t# generate input-output pairs\n",
        "\t\t\t\tin_img, in_seq, out_word = create_sequences(tokenizer, desc, image, max_length)\n",
        "\t\t\t\tfor k in range(len(in_img)):\n",
        "\t\t\t\t\tXimages.append(in_img[k])\n",
        "\t\t\t\t\tXSeq.append(in_seq[k])\n",
        "\t\t\t\t\ty.append(out_word[k])\n",
        "\t\t\t# yield this batch of samples to the model\n",
        "\t\t\tyield [[array(Ximages), array(XSeq)], array(y)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zn3jEMBjDP4c",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# map an integer to a word\n",
        "def word_for_id(integer, tokenizer):\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == integer:\n",
        "\t\t\treturn word\n",
        "\treturn None\n",
        " \n",
        "# generate a description for an image\n",
        "def generate_desc(model, tokenizer, photo, max_length):\n",
        "\t# seed the generation process\n",
        "\tin_text = 'startseq'\n",
        "\t# iterate over the whole length of the sequence\n",
        "\tfor i in range(max_length):\n",
        "\t\t# integer encode input sequence\n",
        "\t\tsequence = tokenizer.texts_to_sequences([in_text])[0]\n",
        "\t\t# pad input\n",
        "\t\tsequence = pad_sequences([sequence], maxlen=max_length)\n",
        "\t\t# predict next word\n",
        "\t\tyhat = model.predict([photo,sequence], verbose=0)\n",
        "\t\t# convert probability to integer\n",
        "\t\tyhat = argmax(yhat)\n",
        "\t\t# map integer to word\n",
        "\t\tword = word_for_id(yhat, tokenizer)\n",
        "\t\t# stop if we cannot map the word\n",
        "\t\tif word is None:\n",
        "\t\t\tbreak\n",
        "\t\t# append as input for generating the next word\n",
        "\t\tin_text += ' ' + word\n",
        "\t\t# stop if we predict the end of the sequence\n",
        "\t\tif word == 'endseq':\n",
        "\t\t\tbreak\n",
        "\treturn in_text\n",
        " \n",
        "# evaluate the skill of the model\n",
        "def evaluate_model(model, descriptions, photos, tokenizer, max_length):\n",
        "\tactual, predicted = list(), list()\n",
        "\t# step over the whole set\n",
        "\tfor key, desc in descriptions.items():\n",
        "\t\t# generate description\n",
        "\t\tyhat = generate_desc(model, tokenizer, photos[key], max_length)\n",
        "\t\t# store actual and predicted\n",
        "\t\tactual.append([desc.split()])\n",
        "\t\tpredicted.append(yhat.split())\n",
        "\t# calculate BLEU score\n",
        "\tbleu = corpus_bleu(actual, predicted)\n",
        "\treturn bleu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9007zBv2Dd-9",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# load dev set\n",
        "filename = 'Flickr_8k.devImages.txt'\n",
        "dataset = load_set(filename)\n",
        "print('Dataset: %d' % len(dataset))\n",
        "# train-test split\n",
        "train, test = train_test_split(dataset)\n",
        "# descriptions\n",
        "train_descriptions = load_clean_descriptions('descriptions.txt', train)\n",
        "test_descriptions = load_clean_descriptions('descriptions.txt', test)\n",
        "print('Descriptions: train=%d, test=%d' % (len(train_descriptions), len(test_descriptions)))\n",
        "# photo features\n",
        "train_features = load_photo_features('features.pkl', train)\n",
        "test_features = load_photo_features('features.pkl', test)\n",
        "print('Photos: train=%d, test=%d' % (len(train_features), len(test_features)))\n",
        "# prepare tokenizer\n",
        "tokenizer = create_tokenizer(train_descriptions)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print('Vocabulary Size: %d' % vocab_size)\n",
        "# determine the maximum sequence length\n",
        "max_length = max(len(s.split()) for s in list(train_descriptions.values()))\n",
        "print('Description Length: %d' % max_length)\n",
        " \n",
        "# define experiment\n",
        "model_name = 'baseline1'\n",
        "verbose = 1\n",
        "n_epochs = 50\n",
        "n_photos_per_update = 2\n",
        "n_batches_per_epoch = int(len(train) / n_photos_per_update)\n",
        "n_repeats = 3\n",
        " \n",
        "# run experiment\n",
        "train_results, test_results = list(), list()\n",
        "for i in range(n_repeats):\n",
        "\t# define the model\n",
        "\tmodel = define_model(vocab_size, max_length)\n",
        "\t# fit model\n",
        "\tmodel.fit_generator(data_generator(train_descriptions, train_features, tokenizer, max_length, n_photos_per_update), steps_per_epoch=n_batches_per_epoch, epochs=n_epochs, verbose=verbose)\n",
        "\t# evaluate model on training data\n",
        "\ttrain_score = evaluate_model(model, train_descriptions, train_features, tokenizer, max_length)\n",
        "\ttest_score = evaluate_model(model, test_descriptions, test_features, tokenizer, max_length)\n",
        "\t# store\n",
        "\ttrain_results.append(train_score)\n",
        "\ttest_results.append(test_score)\n",
        "\tprint('>%d: train=%f test=%f' % ((i+1), train_score, test_score))\n",
        "# save results to file\n",
        "df = DataFrame()\n",
        "df['train'] = train_results\n",
        "df['test'] = test_results\n",
        "print(df.describe())\n",
        "df.to_csv(model_name+'.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kii4cmZIps_Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Conseguimos unas puntuaciones de 0,015 y 0,020, inferiores a las que se obtuvieron en clase.\n",
        "\n",
        "          train      test\n",
        "          \n",
        "count  3.000000  3.000000\n",
        "\n",
        "mean   0.015949  0.020083\n",
        "\n",
        "std    0.010898  0.015056\n",
        "\n",
        "min    0.009658  0.011390\n",
        "\n",
        "25%    0.009658  0.011390\n",
        "\n",
        "50%    0.009658  0.011390\n",
        "\n",
        "75%    0.019095  0.024429\n",
        "\n",
        "max    0.028533  0.037468\n"
      ]
    },
    {
      "metadata": {
        "id": "AZva7Z5Jpsq_",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 8341
        },
        "outputId": "b20449fb-f36b-4ff9-8b5f-8fe63d0c7d13",
        "executionInfo": {
          "status": "error",
          "timestamp": 1530451396150,
          "user_tz": -120,
          "elapsed": 4989038,
          "user": {
            "displayName": "Guillermo Pedernal",
            "photoUrl": "//lh4.googleusercontent.com/-c67Vnm1lekk/AAAAAAAAAAI/AAAAAAAAAD4/_p61UmeZ47E/s50-c-k-no/photo.jpg",
            "userId": "101927487601652154517"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# evaluate the skill of the model\n",
        "def evaluate_model(model, descriptions, photos, tokenizer, max_length):\n",
        "\tactual, predicted = list(), list()\n",
        "\t# step over the whole set\n",
        "\tfor key, desc in descriptions.items():\n",
        "\t\t# generate description\n",
        "\t\tyhat = generate_desc(model, tokenizer, photos[key], max_length)\n",
        "\t\t# store actual and predicted\n",
        "\t\tactual.append([desc.split()])\n",
        "\t\tpredicted.append(yhat.split())\n",
        "\t\tprint('Actual:    %s' % desc)\n",
        "\t\tprint('Predicted: %s' % yhat)\n",
        "\t\tif len(actual) >= 5:\n",
        "\t\t\tbreak\n",
        "\t# calculate BLEU score\n",
        "\tbleu = corpus_bleu(actual, predicted)\n",
        "\treturn bleu\n",
        "\n",
        "# define experiment\n",
        "model_name = 'baseline1'\n",
        "verbose = 2\n",
        "n_epochs = 50\n",
        "n_photos_per_update = 2\n",
        "n_batches_per_epoch = int(len(train) / n_photos_per_update)\n",
        "n_repeats = 3\n",
        " \n",
        "# run experiment\n",
        "train_results, test_results = list(), list()\n",
        "for i in range(n_repeats):\n",
        "\t# define the model\n",
        "\tmodel = define_model(vocab_size, max_length)\n",
        "\t# fit model\n",
        "\tmodel.fit_generator(data_generator(train_descriptions, train_features, tokenizer, max_length, n_photos_per_update), steps_per_epoch=n_batches_per_epoch, epochs=n_epochs, verbose=verbose)\n",
        "\t# evaluate model on training data\n",
        "\ttrain_score = evaluate_model(model, train_descriptions, train_features, tokenizer, max_length)\n",
        "\ttest_score = evaluate_model(model, test_descriptions, test_features, tokenizer, max_length)\n",
        "\t# store\n",
        "\ttrain_results.append(train_score)\n",
        "\ttest_results.append(test_score)\n",
        "\tprint('>%d: train=%f test=%f' % ((i+1), train_score, test_score))\n",
        "# save results to file\n",
        "df = DataFrame()\n",
        "df['train'] = train_results\n",
        "df['test'] = test_results\n",
        "print(df.describe())\n",
        "pdf.to_csv(model_name+'.csv', index=False)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_10 (InputLayer)           (None, 7, 7, 512)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_11 (InputLayer)           (None, 25)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling2d_5 (GlobalM (None, 512)          0           input_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "embedding_5 (Embedding)         (None, 25, 50)       45050       input_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_17 (Dense)                (None, 128)          65664       global_max_pooling2d_5[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_9 (LSTM)                   (None, 25, 256)      314368      embedding_5[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "repeat_vector_5 (RepeatVector)  (None, 25, 128)      0           dense_17[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_5 (TimeDistrib (None, 25, 128)      32896       lstm_9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 25, 256)      0           repeat_vector_5[0][0]            \n",
            "                                                                 time_distributed_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "lstm_10 (LSTM)                  (None, 500)          1514000     concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_19 (Dense)                (None, 500)          250500      lstm_10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_20 (Dense)                (None, 901)          451401      dense_19[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 2,673,879\n",
            "Trainable params: 2,673,879\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            " - 36s - loss: 5.7103 - acc: 0.0986\n",
            "Epoch 2/50\n",
            " - 33s - loss: 5.4506 - acc: 0.1031\n",
            "Epoch 3/50\n",
            " - 33s - loss: 5.4059 - acc: 0.1031\n",
            "Epoch 4/50\n",
            " - 33s - loss: 5.4925 - acc: 0.1031\n",
            "Epoch 5/50\n",
            " - 33s - loss: 5.3383 - acc: 0.1031\n",
            "Epoch 6/50\n",
            " - 33s - loss: 5.4305 - acc: 0.1031\n",
            "Epoch 7/50\n",
            " - 33s - loss: 5.4454 - acc: 0.1031\n",
            "Epoch 8/50\n",
            " - 33s - loss: 5.4086 - acc: 0.1031\n",
            "Epoch 9/50\n",
            " - 33s - loss: 5.3478 - acc: 0.1031\n",
            "Epoch 10/50\n",
            " - 33s - loss: 5.3628 - acc: 0.1023\n",
            "Epoch 11/50\n",
            " - 33s - loss: 5.2996 - acc: 0.1029\n",
            "Epoch 12/50\n",
            " - 33s - loss: 5.3153 - acc: 0.1027\n",
            "Epoch 13/50\n",
            " - 33s - loss: 5.3088 - acc: 0.1039\n",
            "Epoch 14/50\n",
            " - 33s - loss: 5.2632 - acc: 0.1041\n",
            "Epoch 15/50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " - 33s - loss: 5.2352 - acc: 0.1048\n",
            "Epoch 16/50\n",
            " - 33s - loss: 5.2584 - acc: 0.1038\n",
            "Epoch 17/50\n",
            " - 33s - loss: 5.2400 - acc: 0.1039\n",
            "Epoch 18/50\n",
            " - 33s - loss: 5.2511 - acc: 0.1026\n",
            "Epoch 19/50\n",
            " - 33s - loss: 5.2342 - acc: 0.1032\n",
            "Epoch 20/50\n",
            " - 33s - loss: 5.2363 - acc: 0.1036\n",
            "Epoch 21/50\n",
            " - 33s - loss: 5.2345 - acc: 0.1016\n",
            "Epoch 22/50\n",
            " - 33s - loss: 5.2307 - acc: 0.1052\n",
            "Epoch 23/50\n",
            " - 33s - loss: 5.2241 - acc: 0.1054\n",
            "Epoch 24/50\n",
            " - 33s - loss: 5.2199 - acc: 0.1036\n",
            "Epoch 25/50\n",
            " - 33s - loss: 5.2072 - acc: 0.1039\n",
            "Epoch 26/50\n",
            " - 33s - loss: 5.1992 - acc: 0.1036\n",
            "Epoch 27/50\n",
            " - 33s - loss: 5.2026 - acc: 0.1062\n",
            "Epoch 28/50\n",
            " - 33s - loss: 5.1883 - acc: 0.1046\n",
            "Epoch 29/50\n",
            " - 33s - loss: 5.1809 - acc: 0.1033\n",
            "Epoch 30/50\n",
            " - 33s - loss: 5.1828 - acc: 0.1037\n",
            "Epoch 31/50\n",
            " - 33s - loss: 5.1710 - acc: 0.1049\n",
            "Epoch 32/50\n",
            " - 33s - loss: 5.1696 - acc: 0.1033\n",
            "Epoch 33/50\n",
            " - 33s - loss: 5.1808 - acc: 0.1030\n",
            "Epoch 34/50\n",
            " - 33s - loss: 5.1715 - acc: 0.1061\n",
            "Epoch 35/50\n",
            " - 33s - loss: 5.1600 - acc: 0.1062\n",
            "Epoch 36/50\n",
            " - 33s - loss: 5.1570 - acc: 0.1052\n",
            "Epoch 37/50\n",
            " - 33s - loss: 5.1516 - acc: 0.1067\n",
            "Epoch 38/50\n",
            " - 33s - loss: 5.1473 - acc: 0.1050\n",
            "Epoch 39/50\n",
            " - 33s - loss: 5.1531 - acc: 0.1063\n",
            "Epoch 40/50\n",
            " - 33s - loss: 5.1517 - acc: 0.1080\n",
            "Epoch 41/50\n",
            " - 33s - loss: 5.1374 - acc: 0.1079\n",
            "Epoch 42/50\n",
            " - 33s - loss: 5.1280 - acc: 0.1095\n",
            "Epoch 43/50\n",
            " - 33s - loss: 5.1307 - acc: 0.1089\n",
            "Epoch 44/50\n",
            " - 33s - loss: 5.1178 - acc: 0.1085\n",
            "Epoch 45/50\n",
            " - 33s - loss: 5.1213 - acc: 0.1117\n",
            "Epoch 46/50\n",
            " - 33s - loss: 5.1181 - acc: 0.1137\n",
            "Epoch 47/50\n",
            " - 33s - loss: 5.1209 - acc: 0.1145\n",
            "Epoch 48/50\n",
            " - 33s - loss: 5.1096 - acc: 0.1168\n",
            "Epoch 49/50\n",
            " - 33s - loss: 5.0975 - acc: 0.1142\n",
            "Epoch 50/50\n",
            " - 33s - loss: 5.0986 - acc: 0.1186\n",
            "Actual:    startseq child and woman are at waters edge in big city endseq\n",
            "Predicted: startseq endseq\n",
            "Actual:    startseq boy with stick kneeling in front of goalie net endseq\n",
            "Predicted: startseq endseq\n",
            "Actual:    startseq woman crouches near three dogs in field endseq\n",
            "Predicted: startseq dog dog dog dog endseq\n",
            "Actual:    startseq boy bites hard into treat while he sits outside endseq\n",
            "Predicted: startseq endseq\n",
            "Actual:    startseq person eats takeout while watching small television endseq\n",
            "Predicted: startseq endseq\n",
            "Actual:    startseq two dogs are peeing at red fire hydrant endseq\n",
            "Predicted: startseq endseq\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Actual:    startseq child leaping toward red bed endseq\n",
            "Predicted: startseq endseq\n",
            "Actual:    startseq airplane controller is outside white airplane endseq\n",
            "Predicted: startseq endseq\n",
            "Actual:    startseq four kayakers and canoers near rock wall endseq\n",
            "Predicted: startseq endseq\n",
            "Actual:    startseq biker jumping extremely high endseq\n",
            "Predicted: startseq endseq\n",
            ">1: train=0.060907 test=0.049787\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_12 (InputLayer)           (None, 7, 7, 512)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_13 (InputLayer)           (None, 25)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling2d_6 (GlobalM (None, 512)          0           input_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "embedding_6 (Embedding)         (None, 25, 50)       45050       input_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_21 (Dense)                (None, 128)          65664       global_max_pooling2d_6[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_11 (LSTM)                  (None, 25, 256)      314368      embedding_6[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "repeat_vector_6 (RepeatVector)  (None, 25, 128)      0           dense_21[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_6 (TimeDistrib (None, 25, 128)      32896       lstm_11[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 25, 256)      0           repeat_vector_6[0][0]            \n",
            "                                                                 time_distributed_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "lstm_12 (LSTM)                  (None, 500)          1514000     concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_23 (Dense)                (None, 500)          250500      lstm_12[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_24 (Dense)                (None, 901)          451401      dense_23[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 2,673,879\n",
            "Trainable params: 2,673,879\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            " - 35s - loss: 5.7120 - acc: 0.1006\n",
            "Epoch 2/50\n",
            " - 33s - loss: 5.3881 - acc: 0.1031\n",
            "Epoch 3/50\n",
            " - 33s - loss: 5.4082 - acc: 0.1031\n",
            "Epoch 4/50\n",
            " - 33s - loss: 5.3771 - acc: 0.1042\n",
            "Epoch 5/50\n",
            " - 33s - loss: 5.2743 - acc: 0.1037\n",
            "Epoch 6/50\n",
            " - 33s - loss: 5.3005 - acc: 0.1040\n",
            "Epoch 7/50\n",
            " - 33s - loss: 5.3006 - acc: 0.1043\n",
            "Epoch 8/50\n",
            " - 33s - loss: 5.3209 - acc: 0.1050\n",
            "Epoch 9/50\n",
            " - 33s - loss: 5.2611 - acc: 0.1047\n",
            "Epoch 10/50\n",
            " - 33s - loss: 5.2234 - acc: 0.1035\n",
            "Epoch 11/50\n",
            " - 33s - loss: 5.2651 - acc: 0.1035\n",
            "Epoch 12/50\n",
            " - 33s - loss: 5.2522 - acc: 0.1048\n",
            "Epoch 13/50\n",
            " - 33s - loss: 5.2105 - acc: 0.1037\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 14/50\n",
            " - 33s - loss: 5.2336 - acc: 0.1042\n",
            "Epoch 15/50\n",
            " - 33s - loss: 5.2220 - acc: 0.1030\n",
            "Epoch 16/50\n",
            " - 34s - loss: 5.2128 - acc: 0.1025\n",
            "Epoch 17/50\n",
            " - 33s - loss: 5.2045 - acc: 0.1033\n",
            "Epoch 18/50\n",
            " - 33s - loss: 5.2208 - acc: 0.1037\n",
            "Epoch 19/50\n",
            " - 33s - loss: 5.1983 - acc: 0.1031\n",
            "Epoch 20/50\n",
            " - 33s - loss: 5.2039 - acc: 0.1027\n",
            "Epoch 21/50\n",
            " - 33s - loss: 5.2143 - acc: 0.1026\n",
            "Epoch 22/50\n",
            " - 33s - loss: 5.2033 - acc: 0.1047\n",
            "Epoch 23/50\n",
            " - 33s - loss: 5.1879 - acc: 0.1034\n",
            "Epoch 24/50\n",
            " - 33s - loss: 5.2054 - acc: 0.1036\n",
            "Epoch 25/50\n",
            " - 33s - loss: 5.1784 - acc: 0.1031\n",
            "Epoch 26/50\n",
            " - 33s - loss: 5.1701 - acc: 0.1016\n",
            "Epoch 27/50\n",
            " - 33s - loss: 5.2029 - acc: 0.1040\n",
            "Epoch 28/50\n",
            " - 33s - loss: 5.1740 - acc: 0.1036\n",
            "Epoch 29/50\n",
            " - 33s - loss: 5.1906 - acc: 0.1031\n",
            "Epoch 30/50\n",
            " - 33s - loss: 5.1879 - acc: 0.1044\n",
            "Epoch 31/50\n",
            " - 33s - loss: 5.1776 - acc: 0.1054\n",
            "Epoch 32/50\n",
            " - 33s - loss: 5.1838 - acc: 0.1033\n",
            "Epoch 33/50\n",
            " - 33s - loss: 5.1701 - acc: 0.1040\n",
            "Epoch 34/50\n",
            " - 33s - loss: 5.1738 - acc: 0.1040\n",
            "Epoch 35/50\n",
            " - 33s - loss: 5.1648 - acc: 0.1022\n",
            "Epoch 36/50\n",
            " - 33s - loss: 5.1766 - acc: 0.1029\n",
            "Epoch 37/50\n",
            " - 33s - loss: 5.1702 - acc: 0.1041\n",
            "Epoch 38/50\n",
            " - 33s - loss: 5.1714 - acc: 0.1043\n",
            "Epoch 39/50\n",
            " - 33s - loss: 5.1813 - acc: 0.1043\n",
            "Epoch 40/50\n",
            " - 33s - loss: 5.1621 - acc: 0.1030\n",
            "Epoch 41/50\n",
            " - 33s - loss: 5.1723 - acc: 0.1040\n",
            "Epoch 42/50\n",
            " - 33s - loss: 5.1595 - acc: 0.1048\n",
            "Epoch 43/50\n",
            " - 33s - loss: 5.1630 - acc: 0.1033\n",
            "Epoch 44/50\n",
            " - 33s - loss: 5.1483 - acc: 0.1036\n",
            "Epoch 45/50\n",
            " - 33s - loss: 5.1364 - acc: 0.1040\n",
            "Epoch 46/50\n",
            " - 33s - loss: 5.1306 - acc: 0.1040\n",
            "Epoch 47/50\n",
            " - 33s - loss: 5.1245 - acc: 0.1045\n",
            "Epoch 48/50\n",
            " - 33s - loss: 5.1263 - acc: 0.1026\n",
            "Epoch 49/50\n",
            " - 33s - loss: 5.1062 - acc: 0.1043\n",
            "Epoch 50/50\n",
            " - 33s - loss: 5.1135 - acc: 0.1036\n",
            "Actual:    startseq child and woman are at waters edge in big city endseq\n",
            "Predicted: startseq endseq\n",
            "Actual:    startseq boy with stick kneeling in front of goalie net endseq\n",
            "Predicted: startseq endseq\n",
            "Actual:    startseq woman crouches near three dogs in field endseq\n",
            "Predicted: startseq endseq\n",
            "Actual:    startseq boy bites hard into treat while he sits outside endseq\n",
            "Predicted: startseq endseq\n",
            "Actual:    startseq person eats takeout while watching small television endseq\n",
            "Predicted: startseq endseq\n",
            "Actual:    startseq two dogs are peeing at red fire hydrant endseq\n",
            "Predicted: startseq endseq\n",
            "Actual:    startseq child leaping toward red bed endseq\n",
            "Predicted: startseq endseq\n",
            "Actual:    startseq airplane controller is outside white airplane endseq\n",
            "Predicted: startseq endseq\n",
            "Actual:    startseq four kayakers and canoers near rock wall endseq\n",
            "Predicted: startseq endseq\n",
            "Actual:    startseq biker jumping extremely high endseq\n",
            "Predicted: startseq endseq\n",
            ">2: train=0.014996 test=0.049787\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_14 (InputLayer)           (None, 7, 7, 512)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_15 (InputLayer)           (None, 25)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling2d_7 (GlobalM (None, 512)          0           input_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "embedding_7 (Embedding)         (None, 25, 50)       45050       input_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_25 (Dense)                (None, 128)          65664       global_max_pooling2d_7[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_13 (LSTM)                  (None, 25, 256)      314368      embedding_7[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "repeat_vector_7 (RepeatVector)  (None, 25, 128)      0           dense_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_7 (TimeDistrib (None, 25, 128)      32896       lstm_13[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 25, 256)      0           repeat_vector_7[0][0]            \n",
            "                                                                 time_distributed_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "lstm_14 (LSTM)                  (None, 500)          1514000     concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_27 (Dense)                (None, 500)          250500      lstm_14[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_28 (Dense)                (None, 901)          451401      dense_27[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 2,673,879\n",
            "Trainable params: 2,673,879\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            " - 36s - loss: 5.7119 - acc: 0.0996\n",
            "Epoch 2/50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " - 33s - loss: 5.4622 - acc: 0.1031\n",
            "Epoch 3/50\n",
            " - 33s - loss: 5.4675 - acc: 0.1031\n",
            "Epoch 4/50\n",
            " - 33s - loss: 5.4742 - acc: 0.1031\n",
            "Epoch 5/50\n",
            " - 33s - loss: 5.4648 - acc: 0.1031\n",
            "Epoch 6/50\n",
            " - 33s - loss: 5.4373 - acc: 0.1031\n",
            "Epoch 7/50\n",
            " - 33s - loss: 5.4262 - acc: 0.1031\n",
            "Epoch 8/50\n",
            " - 33s - loss: 5.4202 - acc: 0.1031\n",
            "Epoch 9/50\n",
            " - 33s - loss: 5.4164 - acc: 0.1031\n",
            "Epoch 10/50\n",
            " - 33s - loss: 5.4165 - acc: 0.1031\n",
            "Epoch 11/50\n",
            " - 33s - loss: 5.4137 - acc: 0.1031\n",
            "Epoch 12/50\n",
            " - 33s - loss: 5.4126 - acc: 0.1031\n",
            "Epoch 13/50\n",
            " - 33s - loss: 5.4120 - acc: 0.1031\n",
            "Epoch 14/50\n",
            " - 33s - loss: 5.4081 - acc: 0.1031\n",
            "Epoch 15/50\n",
            " - 33s - loss: 5.4098 - acc: 0.1031\n",
            "Epoch 16/50\n",
            " - 33s - loss: 5.4087 - acc: 0.1031\n",
            "Epoch 17/50\n",
            " - 33s - loss: 5.4079 - acc: 0.1031\n",
            "Epoch 18/50\n",
            " - 33s - loss: 5.4072 - acc: 0.1031\n",
            "Epoch 19/50\n",
            " - 33s - loss: 5.4065 - acc: 0.1031\n",
            "Epoch 20/50\n",
            " - 33s - loss: 5.4059 - acc: 0.1031\n",
            "Epoch 21/50\n",
            " - 33s - loss: 5.4053 - acc: 0.1031\n",
            "Epoch 22/50\n",
            " - 33s - loss: 5.4047 - acc: 0.1031\n",
            "Epoch 23/50\n",
            " - 33s - loss: 5.4041 - acc: 0.1031\n",
            "Epoch 24/50\n",
            " - 33s - loss: 5.4034 - acc: 0.1031\n",
            "Epoch 25/50\n",
            " - 33s - loss: 5.4025 - acc: 0.1031\n",
            "Epoch 26/50\n",
            " - 33s - loss: 5.4016 - acc: 0.1031\n",
            "Epoch 27/50\n",
            " - 34s - loss: 5.4004 - acc: 0.1031\n",
            "Epoch 28/50\n",
            " - 34s - loss: 5.3989 - acc: 0.1031\n",
            "Epoch 29/50\n",
            " - 34s - loss: 5.3971 - acc: 0.1031\n",
            "Epoch 30/50\n",
            " - 34s - loss: 5.3950 - acc: 0.1031\n",
            "Epoch 31/50\n",
            " - 33s - loss: 5.3923 - acc: 0.1031\n",
            "Epoch 32/50\n",
            " - 33s - loss: 5.3890 - acc: 0.1031\n",
            "Epoch 33/50\n",
            " - 33s - loss: 5.3849 - acc: 0.1031\n",
            "Epoch 34/50\n",
            " - 33s - loss: 5.3801 - acc: 0.1031\n",
            "Epoch 35/50\n",
            " - 33s - loss: 5.3739 - acc: 0.1031\n",
            "Epoch 36/50\n",
            " - 33s - loss: 5.3666 - acc: 0.1031\n",
            "Epoch 37/50\n",
            " - 33s - loss: 5.3584 - acc: 0.1031\n",
            "Epoch 38/50\n",
            " - 33s - loss: 5.3492 - acc: 0.1031\n",
            "Epoch 39/50\n",
            " - 33s - loss: 5.3390 - acc: 0.1080\n",
            "Epoch 40/50\n",
            " - 33s - loss: 5.3279 - acc: 0.1096\n",
            "Epoch 41/50\n",
            " - 33s - loss: 5.3161 - acc: 0.1118\n",
            "Epoch 42/50\n",
            " - 33s - loss: 5.3041 - acc: 0.1123\n",
            "Epoch 43/50\n",
            " - 33s - loss: 5.2922 - acc: 0.1149\n",
            "Epoch 44/50\n",
            " - 33s - loss: 5.2809 - acc: 0.1161\n",
            "Epoch 45/50\n",
            " - 33s - loss: 5.2703 - acc: 0.1161\n",
            "Epoch 46/50\n",
            " - 33s - loss: 5.2604 - acc: 0.1161\n",
            "Epoch 47/50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " - 33s - loss: 5.2518 - acc: 0.1161\n",
            "Epoch 48/50\n",
            " - 33s - loss: 5.2438 - acc: 0.1161\n",
            "Epoch 49/50\n",
            " - 33s - loss: 5.2367 - acc: 0.1161\n",
            "Epoch 50/50\n",
            " - 33s - loss: 5.2303 - acc: 0.1161\n",
            "Actual:    startseq child and woman are at waters edge in big city endseq\n",
            "Predicted: startseq boy endseq\n",
            "Actual:    startseq boy with stick kneeling in front of goalie net endseq\n",
            "Predicted: startseq boy endseq\n",
            "Actual:    startseq woman crouches near three dogs in field endseq\n",
            "Predicted: startseq boy endseq\n",
            "Actual:    startseq boy bites hard into treat while he sits outside endseq\n",
            "Predicted: startseq boy endseq\n",
            "Actual:    startseq person eats takeout while watching small television endseq\n",
            "Predicted: startseq boy endseq\n",
            "Actual:    startseq two dogs are peeing at red fire hydrant endseq\n",
            "Predicted: startseq boy endseq\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Actual:    startseq child leaping toward red bed endseq\n",
            "Predicted: startseq boy endseq\n",
            "Actual:    startseq airplane controller is outside white airplane endseq\n",
            "Predicted: startseq boy endseq\n",
            "Actual:    startseq four kayakers and canoers near rock wall endseq\n",
            "Predicted: startseq boy endseq\n",
            "Actual:    startseq biker jumping extremely high endseq\n",
            "Predicted: startseq boy endseq\n",
            ">3: train=0.053675 test=0.170668\n",
            "          train      test\n",
            "count  3.000000  3.000000\n",
            "mean   0.043193  0.090081\n",
            "std    0.024686  0.069791\n",
            "min    0.014996  0.049787\n",
            "25%    0.034335  0.049787\n",
            "50%    0.053675  0.049787\n",
            "75%    0.057291  0.110228\n",
            "max    0.060907  0.170668\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-eb86fd24b8c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mpdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'pdf' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "ZSGGfT709MjL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Con esto queda replicado el ejemplo de clase, aunque los resultados son mucho peores. Tan sólo en una de las iteraciones hemos conseguido una predicción que no sea directamente \"startseq -> endseq\", que en cualquier caso asignaba \"boy\" a todas las fotos. \n",
        "\n",
        "Con esto parece que la precision obtenida es muy similar a la que conseguimos previamente para el dataset de Pascal. \n",
        "\n",
        "Tambien llama la atencion que replicandio el ejemplo de clase se obtengan resultados mucho peores, entiendo que puede ser debido a la aleatoriedad de la iniciacion de los pesos de las redes."
      ]
    },
    {
      "metadata": {
        "id": "NtRFd4ij2bmE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Una vez llegados a este punto vamos aintentar mejorar el resultado obtenido en este ultimo caso. Para ello vamos a intentar implementar un hyper-opt sencillito para obtener los valores optimos de algun parametro de la red LSTM y conseguir unas mejores predicciones."
      ]
    },
    {
      "metadata": {
        "id": "MXCKYLvVDz1I",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "5aee3750-068b-4d42-f802-4774a9aed6ba",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530365416681,
          "user_tz": -120,
          "elapsed": 1622,
          "user": {
            "displayName": "Guillermo Pedernal",
            "photoUrl": "//lh4.googleusercontent.com/-c67Vnm1lekk/AAAAAAAAAAI/AAAAAAAAAD4/_p61UmeZ47E/s50-c-k-no/photo.jpg",
            "userId": "101927487601652154517"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from pickle import load\n",
        "\n",
        "# load doc into memory\n",
        "def load_doc(filename):\n",
        "\t# open the file as read only\n",
        "\tfile = open(filename, 'r')\n",
        "\t# read all text\n",
        "\ttext = file.read()\n",
        "\t# close the file\n",
        "\tfile.close()\n",
        "\treturn text\n",
        "\n",
        "# load a pre-defined list of photo identifiers\n",
        "def load_set(filename):\n",
        "\tdoc = load_doc(filename)\n",
        "\tdataset = list()\n",
        "\t# process line by line\n",
        "\tfor line in doc.split('\\n'):\n",
        "\t\t# skip empty lines\n",
        "\t\tif len(line) < 1:\n",
        "\t\t\tcontinue\n",
        "\t\t# get the image identifier\n",
        "\t\tidentifier = line.split('.')[0]\n",
        "\t\tdataset.append(identifier)\n",
        "\treturn set(dataset)\n",
        "\n",
        "# split a dataset into train/test elements\n",
        "def train_test_split(dataset):\n",
        "\t# order keys so the split is consistent\n",
        "\tordered = sorted(dataset)\n",
        "\t# return split dataset as two new sets\n",
        "\treturn set(ordered[:400]), set(ordered[400:500])\n",
        "\n",
        "# load clean descriptions into memory\n",
        "def load_clean_descriptions(filename, dataset):\n",
        "\t# load document\n",
        "\tdoc = load_doc(filename)\n",
        "\tdescriptions = dict()\n",
        "\tfor line in doc.split('\\n'):\n",
        "\t\t# split line by white space\n",
        "\t\ttokens = line.split()\n",
        "\t\t# split id from description\n",
        "\t\timage_id, image_desc = tokens[0], tokens[1:]\n",
        "\t\t# skip images not in the set\n",
        "\t\tif image_id in dataset:\n",
        "\t\t\t# store\n",
        "\t\t\tdescriptions[image_id] = 'startseq ' + ' '.join(image_desc) + ' endseq'\n",
        "\treturn descriptions\n",
        "\n",
        "# load photo features\n",
        "def load_photo_features(filename, dataset):\n",
        "\t# load all features\n",
        "\tall_features = load(open(filename, 'rb'))\n",
        "\t# filter features\n",
        "\tfeatures = {k: all_features[k] for k in dataset}\n",
        "\treturn features\n",
        "\n",
        "# load dev set\n",
        "filename = 'Flickr_8k.devImages.txt'\n",
        "dataset = load_set(filename)\n",
        "print('Dataset: %d' % len(dataset))\n",
        "# train-test split\n",
        "train, test = train_test_split(dataset)\n",
        "print('Train=%d, Test=%d' % (len(train), len(test)))\n",
        "# descriptions\n",
        "train_descriptions = load_clean_descriptions('descriptions.txt', train)\n",
        "test_descriptions = load_clean_descriptions('descriptions.txt', test)\n",
        "print('Descriptions: train=%d, test=%d' % (len(train_descriptions), len(test_descriptions)))\n",
        "# photo features\n",
        "train_features = load_photo_features('features.pkl', train)\n",
        "test_features = load_photo_features('features.pkl', test)\n",
        "print('Photos: train=%d, test=%d' % (len(train_features), len(test_features)))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset: 1000\n",
            "Train=400, Test=100\n",
            "Descriptions: train=400, test=100\n",
            "Photos: train=400, test=100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FF2-ZxPx4ih6",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a2d5694a-b7c8-4ce1-dfe8-f5f705db3e81",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530365419656,
          "user_tz": -120,
          "elapsed": 1145,
          "user": {
            "displayName": "Guillermo Pedernal",
            "photoUrl": "//lh4.googleusercontent.com/-c67Vnm1lekk/AAAAAAAAAAI/AAAAAAAAAD4/_p61UmeZ47E/s50-c-k-no/photo.jpg",
            "userId": "101927487601652154517"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Ahora codificamos nuestras descripciones a números\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# fit a tokenizer given caption descriptions\n",
        "def create_tokenizer(descriptions):\n",
        "\tlines = list(descriptions.values())\n",
        "\ttokenizer = Tokenizer()\n",
        "\ttokenizer.fit_on_texts(lines)\n",
        "\treturn tokenizer\n",
        " \n",
        "# prepare tokenizer\n",
        "tokenizer = create_tokenizer(descriptions)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print('Vocabulary Size: %d' % vocab_size)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary Size: 4485\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1C1K4MUP4ohf",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Y creamos las secuencias:\n",
        "\n",
        "# create sequences of images, input sequences and output words for an image\n",
        "def create_sequences(tokenizer, desc, image, max_length):\n",
        "\tXimages, XSeq, y = list(), list(),list()\n",
        "\tvocab_size = len(tokenizer.word_index) + 1\n",
        "\t# integer encode the description\n",
        "\tseq = tokenizer.texts_to_sequences([desc])[0]\n",
        "\t# split one sequence into multiple X,y pairs\n",
        "\tfor i in range(1, len(seq)):\n",
        "\t\t# select\n",
        "\t\tin_seq, out_seq = seq[:i], seq[i]\n",
        "\t\t# pad input sequence\n",
        "\t\tin_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
        "\t\t# encode output sequence\n",
        "\t\tout_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
        "\t\t# store\n",
        "\t\tXimages.append(image)\n",
        "\t\tXSeq.append(in_seq)\n",
        "\t\ty.append(out_seq)\n",
        "\t# Ximages, XSeq, y = array(Ximages), array(XSeq), array(y)\n",
        "\treturn [Ximages, XSeq, y]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RstrT7Yj_K5B",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 602
        },
        "outputId": "91fa6c04-8bb0-4904-821a-60c4f19976ed",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530446372778,
          "user_tz": -120,
          "elapsed": 13264,
          "user": {
            "displayName": "Guillermo Pedernal",
            "photoUrl": "//lh4.googleusercontent.com/-c67Vnm1lekk/AAAAAAAAAAI/AAAAAAAAAD4/_p61UmeZ47E/s50-c-k-no/photo.jpg",
            "userId": "101927487601652154517"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install networkx==1.11 # para instala hyperopt correctamente, si no, da errores\n",
        "!pip install hyperopt"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting networkx==1.11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/2c/e473e54afc9fae58dfa97066ef6709a7e35a1dd1c28c5a3842989322be00/networkx-1.11-py2.py3-none-any.whl (1.3MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.3MB 6.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from networkx==1.11) (4.3.0)\n",
            "Installing collected packages: networkx\n",
            "  Found existing installation: networkx 2.1\n",
            "    Uninstalling networkx-2.1:\n",
            "      Successfully uninstalled networkx-2.1\n",
            "Successfully installed networkx-1.11\n",
            "Collecting hyperopt\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/39/51/16e9edb51ffbf64bd80f41b7d30bc037aa8b157d430c276464c9b8768b67/hyperopt-0.1.tar.gz (98kB)\n",
            "\u001b[K    100% |████████████████████████████████| 102kB 2.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from hyperopt) (1.14.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from hyperopt) (0.19.1)\n",
            "Collecting nose (from hyperopt)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n",
            "\u001b[K    100% |████████████████████████████████| 163kB 4.9MB/s \n",
            "\u001b[?25hCollecting pymongo (from hyperopt)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/0f/03409241acedb5e27c5ddfef86e1e6b88c1a3864be83d59d796cc06a52b2/pymongo-3.7.0-cp36-cp36m-manylinux1_x86_64.whl (408kB)\n",
            "\u001b[K    100% |████████████████████████████████| 409kB 5.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from hyperopt) (1.11.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt) (1.11)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt) (0.16.0)\n",
            "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt) (4.3.0)\n",
            "Building wheels for collected packages: hyperopt\n",
            "  Running setup.py bdist_wheel for hyperopt ... \u001b[?25l-\b \b\\\b \b|\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/32/69/f5/3267146c22e76dbf8c5e13a535d3c00b9efabe58883a0da65d\n",
            "Successfully built hyperopt\n",
            "Installing collected packages: nose, pymongo, hyperopt\n",
            "Successfully installed hyperopt-0.1 nose-1.3.7 pymongo-3.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_sbWVGfZ4vfJ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 1646
        },
        "outputId": "562d3027-5300-4657-c8a4-260e72c5e8eb",
        "executionInfo": {
          "status": "error",
          "timestamp": 1530446378111,
          "user_tz": -120,
          "elapsed": 2833,
          "user": {
            "displayName": "Guillermo Pedernal",
            "photoUrl": "//lh4.googleusercontent.com/-c67Vnm1lekk/AAAAAAAAAAI/AAAAAAAAAD4/_p61UmeZ47E/s50-c-k-no/photo.jpg",
            "userId": "101927487601652154517"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# define the captioning model\n",
        "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials, rand\n",
        "from keras import optimizers\n",
        "\n",
        "space = {\n",
        "    'optimizer': hp.choice('optimizer', ['adadelta','adam','rmsprop']),\n",
        "    'neuronas_dense': hp.choice('neuronas_dense', [128, 512]),\n",
        "    'units_LSTM': hp.choice('units_LSTM', [256, 500]),\n",
        "}\n",
        "\n",
        "def prueba(a):\n",
        "  #feature extractor (encoder)\n",
        "  inputs1 = Input(shape=(7, 7, 512))\n",
        "  fe1 = GlobalMaxPooling2D()(inputs1)\n",
        "  #fe2 = Dense(128, activation='relu')(fe1)\n",
        "  fe2 = Dense(a['neuronas_dense'], activation='relu')(fe1)\n",
        "  fe3 = RepeatVector(max_length)(fe2)\n",
        "  # embedding\n",
        "  inputs2 = Input(shape=(max_length,))\n",
        "  emb2 = Embedding(vocab_size, 50, mask_zero=True)(inputs2)\n",
        "  #emb3 = LSTM(256, return_sequences=True)(emb2)\n",
        "  emb3 = LSTM(a['units_LSTM'], return_sequences=True)(emb2)\n",
        "  emb4 = TimeDistributed(Dense(128, activation='relu'))(emb3)\n",
        "  # merge inputs\n",
        "  merged = concatenate([fe3, emb4])\n",
        "  # language model (decoder)\n",
        "  #lm2 = LSTM(500)(merged)\n",
        "  #lm3 = Dense(500, activation='relu')(lm2)\n",
        "  lm2 = LSTM(a['units_LSTM'])(merged)\n",
        "  lm3 = Dense(a['neuronas_dense'], activation='relu')(lm2)\n",
        "  outputs = Dense(vocab_size, activation='softmax')(lm3)\n",
        "  # tie it together [image, seq] [word]\n",
        "  model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  print(model.summary())\n",
        "\n",
        "trials = Trials()\n",
        "best = fmin(prueba, space, algo=tpe.suggest, max_evals=10, trials=trials)\n",
        "print(best)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_8 (InputLayer)            (None, 7, 7, 512)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_9 (InputLayer)            (None, 25)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling2d_4 (GlobalM (None, 512)          0           input_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_4 (Embedding)         (None, 25, 50)       45050       input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_13 (Dense)                (None, 128)          65664       global_max_pooling2d_4[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_7 (LSTM)                   (None, 25, 500)      1102000     embedding_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "repeat_vector_4 (RepeatVector)  (None, 25, 128)      0           dense_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_4 (TimeDistrib (None, 25, 128)      64128       lstm_7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 25, 256)      0           repeat_vector_4[0][0]            \n",
            "                                                                 time_distributed_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "lstm_8 (LSTM)                   (None, 500)          1514000     concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_15 (Dense)                (None, 128)          64128       lstm_8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_16 (Dense)                (None, 901)          116229      dense_15[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 2,971,199\n",
            "Trainable params: 2,971,199\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-78798708f2fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mtrials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprueba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         )\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin)\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m             return_argmin=return_argmin)\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[1;32m    318\u001b[0m                     verbose=verbose)\n\u001b[1;32m    319\u001b[0m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstopped\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'job exception: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0mdict_rval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'status'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSTATUS_OK\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m             \u001b[0mdict_rval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    846\u001b[0m             \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_rval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'status'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mSTATUS_STRINGS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "l4m6ccewJhiv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Lamentablemente no he sido capaza de hacer funcionar las iteraciones para encontrar el optimo de los parametros. Una serie de pruebas y mirar la documentacion no me ha sido suficiente para conseguirlo y con el tiempo tan limitado del que disponia tengo que dejarlo aqui."
      ]
    },
    {
      "metadata": {
        "id": "qa8NnA5sJ7ur",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Dado que los resultados del programa no han sido buenos paso al menos a explicar en detalle la practica:"
      ]
    },
    {
      "metadata": {
        "id": "ZYo6JxHVK9I4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "El primer paso de la practica es seleccionar un dataset. Para ello he probado con 3 opciones.\n",
        "\n",
        "En primer lugar, flickr30k. Se trata de un dataset de imagenes de flickr con 5 descripciones cada una. Este dataset me parecia interesante ya que era diferente que el del ejemplo y requeria algo de trabajo extra, como crear un archivo con los titulos de las imagenes. Tuve que abandonarlo ya que tenia demasiadas imagenes y no fui capaz de extraer sus caracteristicas en google colab.\n",
        "\n",
        "En segundo lugar, visto ese problema, me decidi por un dataset distinto al del ejemplo y que tuviera menos imagenes: Pascal Sentence. Este dataset requeria bastante trabajo adicional dado que no cuenta con enlaces de descarga como los de flickr. Este problema lo aborde con un codigo de web scrapping para descargar por un lado las imagenes y por otro los textos. Los textos los almacene como clave-valor quedandome con solo la primera descripcion de cada imagen, como habiamos hecho en el ejemplo en clase. La preparacion de los datos fue bien y pude correr el modelo de clase hasta el final con minimos ajustes pero los resultados no fueron buenos asi que decidi como ultimo paso replicar el ejemplo de clase y tratar de mejorarlo.\n",
        "\n",
        "En ultimo lugar, por lo tanto, utilice flickr8k al igual que en clase. Ya vimos en el ejemplo como preparara los datos de modo que esta parte no supuso ningun problema. Tras este paso obtengo un total de 8092 fotos con una descripcion cada una, asociada a una clave que es el identificador de la foto y un vocabulario de 4484 palabras diferentes."
      ]
    },
    {
      "metadata": {
        "id": "EqsTJ5ISRD3T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "El siguiente paso de la practica es obtener las caracteristicas de las fotos con la funcion extract_features. La idea de este paso es \"separar\" esta primera parte del procesado de las fotos del modelo, guardando los resultados en un archivo, para que el propio modelo pueda computar mas rapido al no tener que examimar las fotos y poder cargar sus caracteristicas directamente desde el archivo.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "v36SXIHdRxNM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Para poder extraer las caracteristicas de las fotos, en vez de entrenar una red con miles de imagenes para que aprenda, utilizamos una de las arquitecturas ya entrenadas que vimos en clase el quinto dia. En el ejemplo usamos la VGG16 y por lo que he visto en algunos de los otros ejemplos de internet para problemas de este tipo parece que es la arquitectura mas comun en este caso.\n",
        "\n",
        "Una cosa importante es que al utilizar la arquitectura de la VGG16 lo hacemos sin las capas finales, que son las que toman el trabajo del resto de la red (en esencia, la extraccion de caracteristicas) y lo utilizan para clasificar la fotografia. En este caso la clasificacion no nos interesa y son precisamente las caracteristicas de cada una de las fotos lo que queremos, para poder introducirlas en el modelo que vamos a crear para describir las imagenes.\n",
        "\n",
        "Con esta funcion extract_features conseguimos un archivo features.pkl con un array opor cada una de las imagenes que contiene las caracteristicas que la red convolucional ha obtenido de ellas."
      ]
    },
    {
      "metadata": {
        "id": "DIIQGSU5Tbcm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "El siguiente paso en el ejemplo es elegir las muestras del dataset con las que vamos a trabajar. Para ello se carga un subconjunto del dataset de 1000 imagenes y de entre estas se seleccionan las 400 primeras como conjunto de train y las 100 siguientes como conjunto de test."
      ]
    },
    {
      "metadata": {
        "id": "H1uxFO-3URV6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A continuacion hay que preparar los conjuntos de train y test. Hemos elegido una serie de fotografias (400 y 100), lo siguiente es cargar del archivo de descripciones el texto que acompaña a cada una de esas fotos. Este texto es lo que el modelo va a tener que predecir por lo que tenemos que introducirlo de forma que la red pueda aprenderlo y reproducirlo.\n",
        "\n",
        "Para ello en el ejemplo de clase se introduce la descripcion como una secuencia de tokens o palabras, que siempre comienza con el token \"startseq\" y termina con \"endseq\". Ademas estas secuencias de palabras tienen que convertirse en enteros para que el modelo las entienda. Para ello se utiliza la funcion tokenizer que incorpora keras y que codifica cada palabra del vocabulario del que disponiamos presente en las descricpiones."
      ]
    },
    {
      "metadata": {
        "id": "pTIRZRIYWVoD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "La siguiente funcion importante del ejemplo es create_sequences. Esta funcion toma como parametros el tokenizer, la descripcion y las caracteristicas de una foto. Esta funcion sirve para entrenar el modelo, dando una palabra de la secuencia como output dada la entrada.\n",
        "\n",
        "Con esto solo queda definir el modelo."
      ]
    },
    {
      "metadata": {
        "id": "1nQC5D00adMd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "El model consta de 3 partes:\n",
        "\n",
        "Una primera de extraccion de caracteristicas y que ya separamos del modelo, utilizando una arquitectura VGG16.\n",
        "\n",
        "Una segunda que procesa la secuencia de texto mediante una red recurrente (capas: embedding>LSTM>dense).\n",
        "\n",
        "Una final que actua como interprete, recogiendo los resultados de las capas anteriores para dar una prediccion de la descripcion de la imagen. (capas: LSTM>dense).\n",
        "\n",
        "El modelo se compila con una funcion de activacion softmax y minimizando una funcion de perdidas categorical cross entropy, dado que las predicciones tienen que hacerse de entre las palabras definidas en el vocabulario. \n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "mfo_fshyeoxR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "El ultimo paso es evaluar el modelo. Para ello lo entrenamos con la muestra de train y se compara la descripcion real con la predecida, obteniendo una puntuacion segun la clasificacion BLEU (un indicador de 0 a 1 que representa lo parecidos que son dos textos).\n",
        "\n",
        "Para generar la descripcion predecida se llama al modelo recursivamente, de modo que genere la palabra siguiente de la secuencia hasta obtener endseq."
      ]
    },
    {
      "metadata": {
        "id": "jPyKhB-bjZuh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Eso es todo. Me sabe mal no haber conseguido una prediccion decente pero he invertido todo el tiempo que me ha sido posible esta semana y hasta aqui he podido llegar. \n",
        "\n",
        "En cualquier caso han sido unas sesiones muy interesantes y me quedo alucinado de lo que es capaz de hacer keras con unas pocas lineas de codigo y una arquitectura pre entrenada (y una gpu!)."
      ]
    },
    {
      "metadata": {
        "id": "XCUtHs2_QVo8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}